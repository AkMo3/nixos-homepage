<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">

<channel>
	<title>NixOS Planet</title>
	<link>https://planet.nixos.org</link>
	<language>en</language>
	<description>NixOS Planet - https://planet.nixos.org</description>
	<atom:link rel="self" href="https://planet.nixos.org/rss20.xml" type="application/rss+xml"/>

<item>
	<title>Sander van der Burg: Deploying mutable multi-process Docker containers with the Nix process management framework (or running Hydra in a Docker container)</title>
	<guid isPermaLink="false">tag:blogger.com,1999:blog-1397115249631682228.post-415569824438519089</guid>
	<link>http://sandervanderburg.blogspot.com/2021/02/deploying-mutable-multi-process-docker.html</link>
	<description>In a blog post written several months ago, I have shown that the &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/02/a-declarative-process-manager-agnostic.html&quot;&gt;Nix process management framework&lt;/a&gt; can also be used to conveniently &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/10/building-multi-process-docker-images.html&quot;&gt;construct multi-process Docker images&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Although Docker is primarily used for managing single root application process containers, multi-process containers can sometimes be useful to deploy systems that consist of multiple, tightly coupled, processes.&lt;br /&gt;&lt;br /&gt;The Docker manual has a section that describes &lt;a href=&quot;https://docs.docker.com/config/containers/multi-service_container&quot;&gt;how to construct images for multi-process containers&lt;/a&gt;, but IMO the configuration process is a bit tedious and cumbersome.&lt;br /&gt;&lt;br /&gt;To make this process more convenient, I have built a &lt;strong&gt;wrapper&lt;/strong&gt; function: &lt;i&gt;createMultiProcessImage&lt;/i&gt; around the &lt;i&gt;dockerTools.buildImage&lt;/i&gt; function (provided by Nixpkgs) that does the following:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;It constructs an image that runs a Linux and Docker compatible process manager as an entry point. Currently, it supports &lt;i&gt;supervisord&lt;/i&gt;, &lt;i&gt;sysvinit&lt;/i&gt;, &lt;i&gt;disnix&lt;/i&gt; and &lt;i&gt;s6-rc&lt;/i&gt;.&lt;/li&gt;&lt;li&gt;The Nix process management framework is used to build a configuration for a system that consists of multiple processes, that will be managed by any of the supported process managers.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Although the framework makes the construction of multi-process images convenient, a big drawback of multi-process Docker containers is &lt;strong&gt;upgrading&lt;/strong&gt; them -- for example, for Debian-based containers you can imperatively upgrade packages by connecting to the container:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker exec -it mycontainer /bin/bash&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and upgrade the desired packages, such as &lt;i&gt;file&lt;/i&gt;:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ apt install file&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The upgrade instruction above is &lt;strong&gt;not reproducible&lt;/strong&gt; -- &lt;i&gt;apt&lt;/i&gt; may install &lt;i&gt;file&lt;/i&gt; version 5.38 today, and 5.39 tomorrow.&lt;br /&gt;&lt;br /&gt;To cope with these kinds of side-effects, Docker works with &lt;strong&gt;images&lt;/strong&gt; that snapshot the outcomes of all the installation steps. Constructing a container from the same image will always provide the same versions of all dependencies.&lt;br /&gt;&lt;br /&gt;As a consequence, to perform a &lt;strong&gt;reproducible&lt;/strong&gt; container &lt;strong&gt;upgrade&lt;/strong&gt;, it is required to construct a new image, &lt;strong&gt;discard&lt;/strong&gt; the container and &lt;strong&gt;reconstruct&lt;/strong&gt; the container from the new image version, causing the system as a whole to be terminated, including the processes that have not changed.&lt;br /&gt;&lt;br /&gt;For a while, I have been thinking about this limitation and developed a solution that makes it possible to upgrade multi-process containers without stopping and discarding them. The only exception is the process manager.&lt;br /&gt;&lt;br /&gt;To make deployments reproducible, it combines the reproducibility properties of Docker and Nix.&lt;br /&gt;&lt;br /&gt;In this blog post, I will describe how this solution works and how it can be used.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Creating a function for building mutable Docker images&lt;/h2&gt;&lt;br /&gt;As explained in an earlier blog post, &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/07/on-using-nix-and-docker-as-deployment.html&quot;&gt;that compares the deployment properties of Nix and Docker&lt;/a&gt;, both solutions support reproducible deployment, albeit for different application domains.&lt;br /&gt;&lt;br /&gt;Moreover, their reproducibility properties are built around different concepts:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;Docker containers are reproducible, because they are constructed from &lt;strong&gt;images&lt;/strong&gt; that consist of immutable layers identified by hash codes derived from their contents.&lt;/li&gt;  &lt;li&gt;&lt;a href=&quot;https://sandervanderburg.blogspot.com/2012/11/an-alternative-explaination-of-nix.html&quot;&gt;Nix package builds are reproducible&lt;/a&gt;, because they are stored in &lt;strong&gt;isolation&lt;/strong&gt; in a Nix store and made immutable (the files' permissions are set read-only). In the construction process of the packages, many &lt;strong&gt;side effects&lt;/strong&gt; are &lt;strong&gt;mitigated&lt;/strong&gt;.&lt;br /&gt;    &lt;br /&gt;    As a result, when the hash code prefix of a package (derived from all build inputs) is the same, then the build output is also (nearly) bit-identical, regardless of the machine on which the package was built.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;By taking these reproducibilty properties into account, we can create a reproducible deployment process for upgradable containers by using a specific separation of responsibilities.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Deploying the base system&lt;/h3&gt;&lt;br /&gt;For the deployment of the &lt;strong&gt;base system&lt;/strong&gt; that includes the &lt;strong&gt;process manager&lt;/strong&gt;, we can stick ourselves to the traditional Docker deployment workflow based on images (the only unconventional aspect is that we use Nix to build a Docker image, instead of &lt;i&gt;Dockerfile&lt;/i&gt;s).&lt;br /&gt;&lt;br /&gt;The process manager that the image provides deploys its configuration from a dynamic configuration directory.&lt;br /&gt;&lt;br /&gt;To support supervisord, we can invoke the following command as the container's entry point:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;supervisord --nodaemon \&lt;br /&gt;  --configuration /etc/supervisor/supervisord.conf \&lt;br /&gt;  --logfile /var/log/supervisord.log \&lt;br /&gt;  --pidfile /var/run/supervisord.pid&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command starts the supervisord service (in foreground mode), using the &lt;i&gt;supervisord.conf&lt;/i&gt; configuration file stored in &lt;i&gt;/etc/supervisord&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;The &lt;i&gt;supervisord.conf&lt;/i&gt; configuration file has the following structure:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;[supervisord]&lt;br /&gt;&lt;br /&gt;[include]&lt;br /&gt;files=conf.d/*&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above configuration automatically loads all program definitions stored in the &lt;i&gt;conf.d&lt;/i&gt; directory. This directory is writable and initially empty. It can be populated with configuration files generated by the Nix process management framework.&lt;br /&gt;&lt;br /&gt;For the other process managers that the framework supports (&lt;i&gt;sysvinit&lt;/i&gt;, &lt;i&gt;disnix&lt;/i&gt; and &lt;i&gt;s6-rc&lt;/i&gt;), we follow a similar strategy -- we configure the process manager in such a way that the configuration is loaded from a source that can be dynamically updated.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Deploying process instances&lt;/h3&gt;&lt;br /&gt;Deployment of the &lt;strong&gt;process instances&lt;/strong&gt; is not done in the construction of the image, but by the Nix process management framework and the Nix package manager running in the container.&lt;br /&gt;&lt;br /&gt;To allow a processes model deployment to refer to packages in the Nixpkgs collection and install binary substitutes, we must configure a Nix channel, such as the unstable Nixpkgs channel:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-channel --add https://nixos.org/channels/nixpkgs-unstable&lt;br /&gt;$ nix-channel --update&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;(As a sidenote: it is also possible to subscribe to a stable Nixpkgs channel or a specific Git revision of Nixpkgs).&lt;br /&gt;&lt;br /&gt;The processes model (and relevant sub models, such as &lt;i&gt;ids.nix&lt;/i&gt; that contains &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/09/assigning-unique-ids-to-services-in.html&quot;&gt;numeric ID assignments&lt;/a&gt;) are copied into the Docker image.&lt;br /&gt;&lt;br /&gt;We can deploy the processes model for supervisord as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nixproc-supervisord-switch&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command will deploy the processes model in the &lt;i&gt;NIXPROC_PROCESSES&lt;/i&gt; environment variable, which defaults to: &lt;i&gt;/etc/nixproc/processes.nix&lt;/i&gt;:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;First, it builds supervisord configuration files from the processes model (this step also includes deploying all required packages and service configuration files)&lt;/li&gt;  &lt;li&gt;It creates symlinks for each configuration file belonging to a process instance in the writable &lt;i&gt;conf.d&lt;/i&gt; directory&lt;/li&gt;  &lt;li&gt;It instructs &lt;i&gt;supervisord&lt;/i&gt; to reload the configuration so that only obsolete processes get deactivated and new services activated, causing unchanged processes to remain untouched.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;(For the other process managers, we have equivalent tools: &lt;i&gt;nixproc-sysvinit-switch&lt;/i&gt;, &lt;i&gt;nixproc-disnix-switch&lt;/i&gt; and &lt;i&gt;nixproc-s6-rc-switch&lt;/i&gt;).&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Initial deployment of the system&lt;/h3&gt;&lt;br /&gt;Because only the process manager is deployed as part of the image (with an initially empty configuration), the system is not yet usable when we start a container.&lt;br /&gt;&lt;br /&gt;To solve this problem, we must perform an &lt;strong&gt;initial deployment&lt;/strong&gt; of the system on first startup.&lt;br /&gt;&lt;br /&gt;I used my lessons learned from the chainloading techniques in &lt;a href=&quot;https://skarnet.org/software/s6/&quot;&gt;s6&lt;/a&gt; (in the &lt;a href=&quot;https://sandervanderburg.blogspot.com/2021/02/developing-s6-rc-backend-for-nix.html&quot;&gt;previous blog post&lt;/a&gt;) and developed hacky generated &lt;strong&gt;bootstrap script&lt;/strong&gt; (&lt;i&gt;/bin/bootstrap&lt;/i&gt;) that serves as the container's entry point:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;cat &amp;gt; /bin/bootstrap &amp;lt;&amp;lt;EOF&lt;br /&gt;#! ${pkgs.stdenv.shell} -e&lt;br /&gt;&lt;br /&gt;# Configure Nix channels&lt;br /&gt;nix-channel --add ${channelURL}&lt;br /&gt;nix-channel --update&lt;br /&gt;&lt;br /&gt;# Deploy the processes model (in a child process)&lt;br /&gt;nixproc-${input.processManager}-switch &amp;amp;&lt;br /&gt;&lt;br /&gt;# Overwrite the bootstrap script, so that it simply just&lt;br /&gt;# starts the process manager the next time we start the&lt;br /&gt;# container&lt;br /&gt;cat &amp;gt; /bin/bootstrap &amp;lt;&amp;lt;EOR&lt;br /&gt;#! ${pkgs.stdenv.shell} -e&lt;br /&gt;exec ${cmd}&lt;br /&gt;EOR&lt;br /&gt;&lt;br /&gt;# Chain load the actual process manager&lt;br /&gt;exec ${cmd}&lt;br /&gt;EOF&lt;br /&gt;chmod 755 /bin/bootstrap&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The generated bootstrap script does the following:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;First, a Nix channel is configured and updated so that we can install packages from the Nixpkgs collection and obtain substitutes.&lt;/li&gt;  &lt;li&gt;The next step is deploying the processes model by running the &lt;i&gt;nixproc-*-switch&lt;/i&gt; tool for a supported process manager. This process is started in the background (as a child process) -- we can use this trick to force the managing bash shell to load our desired process supervisor as soon as possible.&lt;br /&gt;    &lt;br /&gt;    Ultimately, we want the process manager to become responsible for supervising any other process running in the container.&lt;/li&gt;  &lt;li&gt;After the deployment process is started in the background, the bootstrap script is overridden by a bootstrap script that becomes our real entry point -- the process manager that we want to use, such as &lt;i&gt;supervisord&lt;/i&gt;.&lt;br /&gt;    &lt;br /&gt;    Overriding the bootstrap script makes sure that the next time we start the container, it will start instantly without attempting to deploy the system again.&lt;/li&gt;  &lt;li&gt;Finally, the bootstrap script &quot;execs&quot; into the real process manager, becoming the new PID 1 process. When the deployment of the system is done (the &lt;i&gt;nixproc-*-switch&lt;/i&gt; process that still runs in the background), the process manager becomes responsible for reaping it.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;With the above script, the workflow of deploying an upgradable/mutable multi-process container is the same as deploying an ordinary container from a Docker image -- the only (minor) difference is that the first time that we start the container, it may take some time before the services become available, because the multi-process system needs to be deployed by Nix and the Nix process management framework.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;A simple usage scenario&lt;/h2&gt;&lt;br /&gt;Similar to my previous blog posts about the Nix process management framework, I will use the trivial web application system to demonstrate how the functionality of the framework can be used.&lt;br /&gt;&lt;br /&gt;The web application system consists of one or more &lt;i&gt;webapp&lt;/i&gt; processes (with an embedded HTTP server) that only return static HTML pages displaying their identities.&lt;br /&gt;&lt;br /&gt;An Nginx reverse proxy forwards incoming requests to the appropriate &lt;i&gt;webapp&lt;/i&gt; instance -- each &lt;i&gt;webapp&lt;/i&gt; service can be reached by using its unique virtual host value.&lt;br /&gt;&lt;br /&gt;To construct a mutable multi-process Docker image with Nix, we can write the following Nix expression (&lt;i&gt;default.nix&lt;/i&gt;):&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;let&lt;br /&gt;  pkgs = import &amp;lt;nixpkgs&amp;gt; {};&lt;br /&gt;&lt;br /&gt;  nix-processmgmt = builtins.fetchGit {&lt;br /&gt;    url = https://github.com/svanderburg/nix-processmgmt.git;&lt;br /&gt;    ref = &quot;master&quot;;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  createMutableMultiProcessImage = import &quot;${nix-processmgmt}/nixproc/create-image-from-steps/create-mutable-multi-process-image-universal.nix&quot; {&lt;br /&gt;    inherit pkgs;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;createMutableMultiProcessImage {&lt;br /&gt;  name = &quot;multiprocess&quot;;&lt;br /&gt;  tag = &quot;test&quot;;&lt;br /&gt;  contents = [ pkgs.mc ];&lt;br /&gt;  exprFile = ./processes.nix;&lt;br /&gt;  idResourcesFile = ./idresources.nix;&lt;br /&gt;  idsFile = ./ids.nix;&lt;br /&gt;  processManager = &quot;supervisord&quot;; # sysvinit, disnix, s6-rc are also valid options&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above Nix expression invokes the &lt;i&gt;createMutableMultiProcessImage&lt;/i&gt; function that constructs a Docker image that provides a base system with a process manager, and a bootstrap script that deploys the multi-process system:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The &lt;i&gt;name&lt;/i&gt;, &lt;i&gt;tag&lt;/i&gt;, and &lt;i&gt;contents&lt;/i&gt; parameters specify the image name, tag and the packages that need to be included in the image.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;exprFile&lt;/i&gt; parameter refers to a &lt;strong&gt;processes model&lt;/strong&gt; that captures the configurations of the process instances that need to be deployed.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;idResources&lt;/i&gt; parameter refers to an &lt;strong&gt;ID resources&lt;/strong&gt; model that specifies from which resource pools unique IDs need to be selected.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;idsFile&lt;/i&gt; parameter refers to an &lt;strong&gt;IDs model&lt;/strong&gt; that contains the unique ID assignments for each process instance. Unique IDs resemble TCP/UDP port assignments, user IDs (UIDs) and group IDs (GIDs).&lt;/li&gt;  &lt;li&gt;We can use the &lt;i&gt;processManager&lt;/i&gt; parameter to select the process manager we want to use. In the above example it is &lt;i&gt;supervisord&lt;/i&gt;, but other options are also possible.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;We can use the following processes model (&lt;i&gt;processes.nix&lt;/i&gt;) to deploy a small version of our example system:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;{ pkgs ? import &amp;lt;nixpkgs&amp;gt; { inherit system; }&lt;br /&gt;, system ? builtins.currentSystem&lt;br /&gt;, stateDir ? &quot;/var&quot;&lt;br /&gt;, runtimeDir ? &quot;${stateDir}/run&quot;&lt;br /&gt;, logDir ? &quot;${stateDir}/log&quot;&lt;br /&gt;, cacheDir ? &quot;${stateDir}/cache&quot;&lt;br /&gt;, tmpDir ? (if stateDir == &quot;/var&quot; then &quot;/tmp&quot; else &quot;${stateDir}/tmp&quot;)&lt;br /&gt;, forceDisableUserChange ? false&lt;br /&gt;, processManager&lt;br /&gt;}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  nix-processmgmt = builtins.fetchGit {&lt;br /&gt;    url = https://github.com/svanderburg/nix-processmgmt.git;&lt;br /&gt;    ref = &quot;master&quot;;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  ids = if builtins.pathExists ./ids.nix then (import ./ids.nix).ids else {};&lt;br /&gt;&lt;br /&gt;  sharedConstructors = import &quot;${nix-processmgmt}/examples/services-agnostic/constructors/constructors.nix&quot; {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir cacheDir tmpDir forceDisableUserChange processManager ids;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  constructors = import &quot;${nix-processmgmt}/examples/webapps-agnostic/constructors/constructors.nix&quot; {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir tmpDir forceDisableUserChange processManager ids;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;rec {&lt;br /&gt;  webapp = rec {&lt;br /&gt;    port = ids.webappPorts.webapp or 0;&lt;br /&gt;    dnsName = &quot;webapp.local&quot;;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.webapp {&lt;br /&gt;      inherit port;&lt;br /&gt;    };&lt;br /&gt;&lt;br /&gt;    requiresUniqueIdsFor = [ &quot;webappPorts&quot; &quot;uids&quot; &quot;gids&quot; ];&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  nginx = rec {&lt;br /&gt;    port = ids.nginxPorts.nginx or 0;&lt;br /&gt;&lt;br /&gt;    pkg = sharedConstructors.nginxReverseProxyHostBased {&lt;br /&gt;      webapps = [ webapp ];&lt;br /&gt;      inherit port;&lt;br /&gt;    } {};&lt;br /&gt;&lt;br /&gt;    requiresUniqueIdsFor = [ &quot;nginxPorts&quot; &quot;uids&quot; &quot;gids&quot; ];&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above Nix expression configures two process instances, one &lt;i&gt;webapp&lt;/i&gt; process that returns a static HTML page with its identity and an Nginx reverse proxy that forwards connections to it.&lt;br /&gt;&lt;br /&gt;A notable difference between the expression shown above and the processes models of the same system shown in my previous blog posts, is that this expression does not contain any references to files on the local filesystem, with the exception of the ID assignments expression (&lt;i&gt;ids.nix&lt;/i&gt;).&lt;br /&gt;&lt;br /&gt;We obtain all required functionality from the Nix process management framework by invoking &lt;i&gt;builtins.fetchGit&lt;/i&gt;. Eliminating local references is required to allow the processes model to be copied into the container and deployed from within the container.&lt;br /&gt;&lt;br /&gt;We can build a Docker image as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-build&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;load the image into Docker:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker load -i result&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and create and start a Docker container:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;$ docker run -it --name webapps --network host multiprocess:test&lt;br /&gt;unpacking channels...&lt;br /&gt;warning: Nix search path entry '/nix/var/nix/profiles/per-user/root/channels' does not exist, ignoring&lt;br /&gt;created 1 symlinks in user environment&lt;br /&gt;2021-02-21 15:29:29,878 CRIT Supervisor is running as root.  Privileges were not dropped because no user is specified in the config file.  If you intend to run as root, you can set user=root in the config file to avoid this message.&lt;br /&gt;2021-02-21 15:29:29,878 WARN No file matches via include &quot;/etc/supervisor/conf.d/*&quot;&lt;br /&gt;2021-02-21 15:29:29,897 INFO RPC interface 'supervisor' initialized&lt;br /&gt;2021-02-21 15:29:29,897 CRIT Server 'inet_http_server' running without any HTTP authentication checking&lt;br /&gt;2021-02-21 15:29:29,898 INFO supervisord started with pid 1&lt;br /&gt;these derivations will be built:&lt;br /&gt;  /nix/store/011g52sj25k5k04zx9zdszdxfv6wy1dw-credentials.drv&lt;br /&gt;  /nix/store/1i9g728k7lda0z3mn1d4bfw07v5gzkrv-credentials.drv&lt;br /&gt;  /nix/store/fs8fwfhalmgxf8y1c47d0zzq4f89fz0g-nginx.conf.drv&lt;br /&gt;  /nix/store/vxpm2m6444fcy9r2p06dmpw2zxlfw0v4-nginx-foregroundproxy.sh.drv&lt;br /&gt;  /nix/store/4v3lxnpapf5f8297gdjz6kdra8g7k4sc-nginx.conf.drv&lt;br /&gt;  /nix/store/mdldv8gwvcd5fkchncp90hmz3p9rcd99-builder.pl.drv&lt;br /&gt;  /nix/store/r7qjyr8vr3kh1lydrnzx6nwh62spksx5-nginx.drv&lt;br /&gt;  /nix/store/h69khss5dqvx4svsc39l363wilcf2jjm-webapp.drv&lt;br /&gt;  /nix/store/kcqbrhkc5gva3r8r0fnqjcfhcw4w5il5-webapp.conf.drv&lt;br /&gt;  /nix/store/xfc1zbr92pyisf8lw35qybbn0g4f46sc-webapp.drv&lt;br /&gt;  /nix/store/fjx5kndv24pia1yi2b7b2bznamfm8q0k-supervisord.d.drv&lt;br /&gt;these paths will be fetched (78.80 MiB download, 347.06 MiB unpacked):&lt;br /&gt;...&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;As may be noticed by looking at the output, on first startup the Nix process management framework is invoked to deploy the system with Nix.&lt;br /&gt;&lt;br /&gt;After the system has been deployed, we should be able to connect to the &lt;i&gt;webapp&lt;/i&gt; process via the Nginx reverse proxy:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ curl -H 'Host: webapp.local' http://localhost:8080&lt;br /&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;br /&gt;&amp;lt;html&amp;gt;&lt;br /&gt;  &amp;lt;head&amp;gt;&lt;br /&gt;    &amp;lt;title&amp;gt;Simple test webapp&amp;lt;/title&amp;gt;&lt;br /&gt;  &amp;lt;/head&amp;gt;&lt;br /&gt;  &amp;lt;body&amp;gt;&lt;br /&gt;    Simple test webapp listening on port: 5000&lt;br /&gt;  &amp;lt;/body&amp;gt;&lt;br /&gt;&amp;lt;/html&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;When it is desired to upgrade the system, we can change the system's configuration by connecting to the container instance:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker exec -it webapps /bin/bash&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;In the container, we can edit the &lt;i&gt;processes.nix&lt;/i&gt; configuration file:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ mcedit /etc/nixproc/processes.nix&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and make changes to the configuration of the system. For example, we can change the processes model to include a second &lt;i&gt;webapp&lt;/i&gt; process:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;{ pkgs ? import &amp;lt;nixpkgs&amp;gt; { inherit system; }&lt;br /&gt;, system ? builtins.currentSystem&lt;br /&gt;, stateDir ? &quot;/var&quot;&lt;br /&gt;, runtimeDir ? &quot;${stateDir}/run&quot;&lt;br /&gt;, logDir ? &quot;${stateDir}/log&quot;&lt;br /&gt;, cacheDir ? &quot;${stateDir}/cache&quot;&lt;br /&gt;, tmpDir ? (if stateDir == &quot;/var&quot; then &quot;/tmp&quot; else &quot;${stateDir}/tmp&quot;)&lt;br /&gt;, forceDisableUserChange ? false&lt;br /&gt;, processManager&lt;br /&gt;}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  nix-processmgmt = builtins.fetchGit {&lt;br /&gt;    url = https://github.com/svanderburg/nix-processmgmt.git;&lt;br /&gt;    ref = &quot;master&quot;;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  ids = if builtins.pathExists ./ids.nix then (import ./ids.nix).ids else {};&lt;br /&gt;&lt;br /&gt;  sharedConstructors = import &quot;${nix-processmgmt}/examples/services-agnostic/constructors/constructors.nix&quot; {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir cacheDir tmpDir forceDisableUserChange processManager ids;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  constructors = import &quot;${nix-processmgmt}/examples/webapps-agnostic/constructors/constructors.nix&quot; {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir tmpDir forceDisableUserChange processManager ids;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;rec {&lt;br /&gt;  webapp = rec {&lt;br /&gt;    port = ids.webappPorts.webapp or 0;&lt;br /&gt;    dnsName = &quot;webapp.local&quot;;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.webapp {&lt;br /&gt;      inherit port;&lt;br /&gt;    };&lt;br /&gt;&lt;br /&gt;    requiresUniqueIdsFor = [ &quot;webappPorts&quot; &quot;uids&quot; &quot;gids&quot; ];&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  webapp2 = rec {&lt;br /&gt;    port = ids.webappPorts.webapp2 or 0;&lt;br /&gt;    dnsName = &quot;webapp2.local&quot;;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.webapp {&lt;br /&gt;      inherit port;&lt;br /&gt;      instanceSuffix = &quot;2&quot;;&lt;br /&gt;    };&lt;br /&gt;&lt;br /&gt;    requiresUniqueIdsFor = [ &quot;webappPorts&quot; &quot;uids&quot; &quot;gids&quot; ];&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  nginx = rec {&lt;br /&gt;    port = ids.nginxPorts.nginx or 0;&lt;br /&gt;&lt;br /&gt;    pkg = sharedConstructors.nginxReverseProxyHostBased {&lt;br /&gt;      webapps = [ webapp webapp2 ];&lt;br /&gt;      inherit port;&lt;br /&gt;    } {};&lt;br /&gt;&lt;br /&gt;    requiresUniqueIdsFor = [ &quot;nginxPorts&quot; &quot;uids&quot; &quot;gids&quot; ];&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;In the above process model model, a new process instance named: &lt;i&gt;webapp2&lt;/i&gt; was added that listens on a unique port that can be reached with the &lt;i&gt;webapp2.local&lt;/i&gt; virtual host value.&lt;br /&gt;&lt;br /&gt;By running the following command, the system in the container gets upgraded:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nixproc-supervisord-switch&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;resulting in two &lt;i&gt;webapp&lt;/i&gt; process instances running in the container:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ supervisorctl &lt;br /&gt;nginx                            RUNNING   pid 847, uptime 0:00:08&lt;br /&gt;webapp                           RUNNING   pid 459, uptime 0:05:54&lt;br /&gt;webapp2                          RUNNING   pid 846, uptime 0:00:08&lt;br /&gt;supervisor&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The first instance: &lt;i&gt;webapp&lt;/i&gt; was left untouched, because its configuration was not changed.&lt;br /&gt;&lt;br /&gt;The second instance: &lt;i&gt;webapp2&lt;/i&gt; can be reached as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ curl -H 'Host: webapp2.local' http://localhost:8080&lt;br /&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;br /&gt;&amp;lt;html&amp;gt;&lt;br /&gt;  &amp;lt;head&amp;gt;&lt;br /&gt;    &amp;lt;title&amp;gt;Simple test webapp&amp;lt;/title&amp;gt;&lt;br /&gt;  &amp;lt;/head&amp;gt;&lt;br /&gt;  &amp;lt;body&amp;gt;&lt;br /&gt;    Simple test webapp listening on port: 5001&lt;br /&gt;  &amp;lt;/body&amp;gt;&lt;br /&gt;&amp;lt;/html&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;After upgrading the system, the new configuration should also get reactivated after a container restart.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;A more interesting example: Hydra&lt;/h2&gt;&lt;br /&gt;As explained earlier, to create upgradable containers we require a fully functional Nix installation in a container. This observation made a think about a more interesting example than the trivial web application system.&lt;br /&gt;&lt;br /&gt;A prominent example of a system that requires Nix and is composed out of multiple tightly integrated process is &lt;a href=&quot;https://sandervanderburg.blogspot.com/2013/04/setting-up-hydra-build-cluster-for.html&quot;&gt;Hydra: the Nix-based continuous integration service&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;To make it possible to deploy a minimal Hydra service in a container, I have packaged all its relevant components for the Nix process management framework.&lt;br /&gt;&lt;br /&gt;The processes model looks as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;{ pkgs ? import &amp;lt;nixpkgs&amp;gt; { inherit system; }&lt;br /&gt;, system ? builtins.currentSystem&lt;br /&gt;, stateDir ? &quot;/var&quot;&lt;br /&gt;, runtimeDir ? &quot;${stateDir}/run&quot;&lt;br /&gt;, logDir ? &quot;${stateDir}/log&quot;&lt;br /&gt;, cacheDir ? &quot;${stateDir}/cache&quot;&lt;br /&gt;, tmpDir ? (if stateDir == &quot;/var&quot; then &quot;/tmp&quot; else &quot;${stateDir}/tmp&quot;)&lt;br /&gt;, forceDisableUserChange ? false&lt;br /&gt;, processManager&lt;br /&gt;}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  nix-processmgmt = builtins.fetchGit {&lt;br /&gt;    url = https://github.com/svanderburg/nix-processmgmt.git;&lt;br /&gt;    ref = &quot;master&quot;;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  nix-processmgmt-services = builtins.fetchGit {&lt;br /&gt;    url = https://github.com/svanderburg/nix-processmgmt-services.git;&lt;br /&gt;    ref = &quot;master&quot;;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  constructors = import &quot;${nix-processmgmt-services}/services-agnostic/constructors.nix&quot; {&lt;br /&gt;    inherit nix-processmgmt pkgs stateDir runtimeDir logDir tmpDir cacheDir forceDisableUserChange processManager;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  instanceSuffix = &quot;&quot;;&lt;br /&gt;  hydraUser = hydraInstanceName;&lt;br /&gt;  hydraInstanceName = &quot;hydra${instanceSuffix}&quot;;&lt;br /&gt;  hydraQueueRunnerUser = &quot;hydra-queue-runner${instanceSuffix}&quot;;&lt;br /&gt;  hydraServerUser = &quot;hydra-www${instanceSuffix}&quot;;&lt;br /&gt;in&lt;br /&gt;rec {&lt;br /&gt;  nix-daemon = {&lt;br /&gt;    pkg = constructors.nix-daemon;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  postgresql = rec {&lt;br /&gt;    port = 5432;&lt;br /&gt;    postgresqlUsername = &quot;postgresql&quot;;&lt;br /&gt;    postgresqlPassword = &quot;postgresql&quot;;&lt;br /&gt;    socketFile = &quot;${runtimeDir}/postgresql/.s.PGSQL.${toString port}&quot;;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.simplePostgresql {&lt;br /&gt;      inherit port;&lt;br /&gt;      authentication = ''&lt;br /&gt;        # TYPE  DATABASE   USER   ADDRESS    METHOD&lt;br /&gt;        local   hydra      all               ident map=hydra-users&lt;br /&gt;      '';&lt;br /&gt;      identMap = ''&lt;br /&gt;        # MAPNAME       SYSTEM-USERNAME          PG-USERNAME&lt;br /&gt;        hydra-users     ${hydraUser}             ${hydraUser}&lt;br /&gt;        hydra-users     ${hydraQueueRunnerUser}  ${hydraUser}&lt;br /&gt;        hydra-users     ${hydraServerUser}       ${hydraUser}&lt;br /&gt;        hydra-users     root                     ${hydraUser}&lt;br /&gt;        # The postgres user is used to create the pg_trgm extension for the hydra database&lt;br /&gt;        hydra-users     postgresql               postgresql&lt;br /&gt;      '';&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  hydra-server = rec {&lt;br /&gt;    port = 3000;&lt;br /&gt;    hydraDatabase = hydraInstanceName;&lt;br /&gt;    hydraGroup = hydraInstanceName;&lt;br /&gt;    baseDir = &quot;${stateDir}/lib/${hydraInstanceName}&quot;;&lt;br /&gt;    inherit hydraUser instanceSuffix;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.hydra-server {&lt;br /&gt;      postgresqlDBMS = postgresql;&lt;br /&gt;      user = hydraServerUser;&lt;br /&gt;      inherit nix-daemon port instanceSuffix hydraInstanceName hydraDatabase hydraUser hydraGroup baseDir;&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  hydra-evaluator = {&lt;br /&gt;    pkg = constructors.hydra-evaluator {&lt;br /&gt;      inherit nix-daemon hydra-server;&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  hydra-queue-runner = {&lt;br /&gt;    pkg = constructors.hydra-queue-runner {&lt;br /&gt;      inherit nix-daemon hydra-server;&lt;br /&gt;      user = hydraQueueRunnerUser;&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  apache = {&lt;br /&gt;    pkg = constructors.reverseProxyApache {&lt;br /&gt;      dependency = hydra-server;&lt;br /&gt;      serverAdmin = &quot;admin@localhost&quot;;&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;In the above processes model, each process instance represents a component of a Hydra installation:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The &lt;i&gt;nix-daemon&lt;/i&gt; process is a service that comes with Nix package manager to facilitate multi-user package installations. The &lt;i&gt;nix-daemon&lt;/i&gt; carries out builds on behalf of a user.&lt;br /&gt;    &lt;br /&gt;    Hydra requires it to perform builds as an unprivileged Hydra user and uses the Nix protocol to more efficiently orchestrate large builds.&lt;/li&gt;  &lt;li&gt;Hydra uses a PostgreSQL database backend to store data about projects and builds.&lt;br /&gt;    &lt;br /&gt;    The &lt;i&gt;postgresql&lt;/i&gt; process refers to the PostgreSQL database management system (DBMS) that is configured in such a way that the Hydra components are authorized to manage and modify the Hydra database.&lt;/li&gt;  &lt;li&gt;&lt;i&gt;hydra-server&lt;/i&gt; is the front-end of the Hydra service that provides a web user interface. The initialization procedure of this service is responsible for initializing the Hydra database.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;hydra-evaluator&lt;/i&gt; regularly updates the repository checkouts and evaluates the Nix expressions to decide which packages need to be built.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;hydra-queue-runner&lt;/i&gt; builds all jobs that were evaluated by the &lt;i&gt;hydra-evaluator&lt;/i&gt;.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;apache&lt;/i&gt; server is used as a reverse proxy server forwarding requests to the &lt;i&gt;hydra-server&lt;/i&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;With the following commands, we can build the image, load it into Docker, and deploy a container that runs Hydra:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-build hydra-image.nix&lt;br /&gt;$ docker load -i result&lt;br /&gt;$ docker run -it --name hydra-test --network host hydra:test&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;After deploying the system, we can connect to the container:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker exec -it hydra-test /bin/bash&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and observe that all processes are running and managed by supervisord:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ supervisorctl&lt;br /&gt;apache                           RUNNING   pid 1192, uptime 0:00:42&lt;br /&gt;hydra-evaluator                  RUNNING   pid 1297, uptime 0:00:38&lt;br /&gt;hydra-queue-runner               RUNNING   pid 1296, uptime 0:00:38&lt;br /&gt;hydra-server                     RUNNING   pid 1188, uptime 0:00:42&lt;br /&gt;nix-daemon                       RUNNING   pid 1186, uptime 0:00:42&lt;br /&gt;postgresql                       RUNNING   pid 1187, uptime 0:00:42&lt;br /&gt;supervisor&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With the following commands, we can create our initial admin user:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ su - hydra&lt;br /&gt;$ hydra-create-user sander --password secret --role admin&lt;br /&gt;creating new user `sander'&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;We can connect to the Hydra front-end in a web browser by opening &lt;i&gt;http://localhost&lt;/i&gt; (this works because the container uses host networking):&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-9P1SBynzxgo/YDK7XrxQegI/AAAAAAAALO8/NWhE5qVcmjMaFfjJSPnA3QochULSVBK9ACLcBGAsYHQ/s1145/hydraoverview.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-9P1SBynzxgo/YDK7XrxQegI/AAAAAAAALO8/NWhE5qVcmjMaFfjJSPnA3QochULSVBK9ACLcBGAsYHQ/s600/hydraoverview.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;and configure a job set to a build a project, such as &lt;a href=&quot;https://sandervanderburg.blogspot.com/2017/01/some-programming-patterns-for-multi.html&quot;&gt;libprocreact&lt;/a&gt;:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-hl88Kza5uo4/YDK7tsoWRUI/AAAAAAAALPE/WQ4eq5VpCj0qbmVTcu7CUwU0COgbk-pUgCLcBGAsYHQ/s1145/hydrajobset.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-hl88Kza5uo4/YDK7tsoWRUI/AAAAAAAALPE/WQ4eq5VpCj0qbmVTcu7CUwU0COgbk-pUgCLcBGAsYHQ/s600/hydrajobset.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Another nice bonus feature of having multiple process managers supported is that if we build Hydra's &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/06/using-disnix-as-simple-and-minimalistic.html&quot;&gt;Nix process management configuration for Disnix&lt;/a&gt;, we can also visualize the deployment architecture of the system with &lt;i&gt;disnix-visualize&lt;/i&gt;:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-fUTW7mautrU/YDK74Os1ePI/AAAAAAAALPI/KfHr6U3FNbAyjtMVOWH6eYnoBiOWAf1jQCLcBGAsYHQ/s0/deploymentarch.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-fUTW7mautrU/YDK74Os1ePI/AAAAAAAALPI/KfHr6U3FNbAyjtMVOWH6eYnoBiOWAf1jQCLcBGAsYHQ/s0/deploymentarch.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;The above diagram displays the following properties:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The outer box indicates that we are deploying to a single machine: &lt;i&gt;localhost&lt;/i&gt;&lt;/li&gt;  &lt;li&gt;The inner box indicates that all components are managed as processes&lt;/li&gt;  &lt;li&gt;The ovals correspond to process instances in the processes model and the arrows denote dependency relationships.&lt;br /&gt;    &lt;br /&gt;    For example, the &lt;i&gt;apache&lt;/i&gt; reverse proxy has a dependency on &lt;i&gt;hydra-server&lt;/i&gt;, meaning that the latter process instance should be deployed first, otherwise the reverse proxy is not able to forward requests to it.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Building a Nix-enabled container image&lt;/h2&gt;&lt;br /&gt;As explained in the previous section, mutable Docker images require a fully functional Nix package manager in the container.&lt;br /&gt;&lt;br /&gt;Since this may also be an interesting sub use case, I have created a convenience function: &lt;i&gt;createNixImage&lt;/i&gt; that can be used to build an image whose only purpose is to provide a working Nix installation:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;let&lt;br /&gt;  pkgs = import &amp;lt;nixpkgs&amp;gt; {};&lt;br /&gt;&lt;br /&gt;  nix-processmgmt = builtins.fetchGit {&lt;br /&gt;    url = https://github.com/svanderburg/nix-processmgmt.git;&lt;br /&gt;    ref = &quot;master&quot;;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  createNixImage = import &quot;${nix-processmgmt}/nixproc/create-image-from-steps/create-nix-image.nix&quot; {&lt;br /&gt;    inherit pkgs;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;createNixImage {&lt;br /&gt;  name = &quot;foobar&quot;;&lt;br /&gt;  tag = &quot;test&quot;;&lt;br /&gt;  contents = [ pkgs.mc ];&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above Nix expression builds a Docker image with a working Nix setup and a custom package: the &lt;a href=&quot;http://midnight-commander.org&quot;&gt;Midnight Commander&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Conclusions&lt;/h2&gt;&lt;br /&gt;In this blog post, I have described a new function in the Nix process management framework: &lt;i&gt;createMutableMultiProcessImage&lt;/i&gt; that creates reproducible mutable multi-process container images, by combining the reproducibility properties of Docker and Nix. With the exception of the process manager, process instances in a container can be upgraded without bringing the entire container down.&lt;br /&gt;&lt;br /&gt;With this new functionality, the deployment workflow of a multi-process container configuration has become very similar to how physical and virtual machines are managed with &lt;a href=&quot;https://sandervanderburg.blogspot.com/2011/01/nixos-purely-functional-linux.html&quot;&gt;NixOS&lt;/a&gt; -- you can edit a declarative specification of a system and run a single command-line instruction to deploy the new configuration.&lt;br /&gt;&lt;br /&gt;Moreover, this new functionality allows us to deploy a complex, tightly coupled multi-process system, such as Hydra: the Nix-based continuous integration service. In the Hydra example case, we are using Nix for three deployment aspects: constructing the Docker image, deploying the multi-process system configuration and building the projects that are configured in Hydra.&lt;br /&gt;&lt;br /&gt;A big drawback of mutable multi-process images is that there is no sharing possible between multiple multi-process containers. Since the images are not built from common layers, the Nix store is private to each container and all packages are deployed in the writable custom layer, this may lead to substantial disk and RAM overhead per container instance.&lt;br /&gt;&lt;br /&gt;Deploying the processes model to a container instance can probably be made more convenient by using &lt;a href=&quot;https://nixos.wiki/wiki/Flakes&quot;&gt;Nix flakes&lt;/a&gt; -- a new Nix feature that is still experimental. With flakes we can easily deploy an arbitrary number of Nix expressions to a container and pin the deployment to a specific version of Nixpkgs.&lt;br /&gt;&lt;br /&gt;Another interesting observation is the word: mutable. I am not completely sure if it is appropriate -- both the layers of a Docker image, as well as the Nix store paths are immutable and never change after they have been built. For both solutions, immutability is an important ingredient in making sure that a deployment is reproducible.&lt;br /&gt;&lt;br /&gt;I have decided to still call these deployments mutable, because I am looking at the problem from a Docker perspective -- the writable layer of the container (that is mounted on top of the immutable layers of an image) is modified each time that we upgrade a system.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Future work&lt;/h2&gt;&lt;br /&gt;Although I am quite happy with the ability to create mutable multi-process containers, there is still quite a bit of work that needs to be done to make the Nix process management framework more usable.&lt;br /&gt;&lt;br /&gt;Most importantly, trying to deploy Hydra revealed all kinds of regressions in the framework. To cope with all these breaking changes, a structured testing approach is required. Currently, such an approach is completely absent.&lt;br /&gt;&lt;br /&gt;I could also (in theory) automate the still missing parts of Hydra. For example, I have not automated the process that updates the garbage collector roots, which needs to run in a timely manner. To solve this, I need to use a &lt;i&gt;cron&lt;/i&gt; service or systemd timer units, which is beyond the scope of my experiment.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Availability&lt;/h2&gt;&lt;br /&gt;The &lt;i&gt;createMutableMultiProcessImage&lt;/i&gt; function is part of the experimental &lt;a href=&quot;https://github.com/svanderburg/nix-processmgmt&quot;&gt;Nix process management framework GitHub repository&lt;/a&gt; that is still under heavy development.&lt;br /&gt;&lt;br /&gt;Because the amount of services that can be deployed with the framework has grown considerably, I have moved all non-essential services (not required for testing) into a &lt;a href=&quot;https://github.com/svanderburg/nix-processmgmt-services&quot;&gt;separate repository&lt;/a&gt;. The Hydra constructor functions can be found in this repository as well.&lt;br /&gt;</description>
	<pubDate>Wed, 24 Feb 2021 21:46:00 +0000</pubDate>
	<author>noreply@blogger.com (Sander van der Burg)</author>
</item>
<item>
	<title>Tweag I/O: Derivation outputs in a content-addressed world</title>
	<guid isPermaLink="true">https://tweag.io/blog/2021-02-17-derivation-outputs-and-output-paths/</guid>
	<link>https://tweag.io/blog/2021-02-17-derivation-outputs-and-output-paths/</link>
	<description>&lt;p&gt;This is another blog post on the upcoming content-addressed derivations for Nix.
We’ve already &lt;a href=&quot;https://www.tweag.io/blog/2020-09-10-nix-cas/&quot;&gt;explained the feature and some of its advantages&lt;/a&gt;, as well as &lt;a href=&quot;https://www.tweag.io/blog/2020-11-18-nix-cas-self-references/&quot;&gt;the reasons why it isn’t easy to implement&lt;/a&gt;.
Now we’re going to talk about about a concrete user-facing change that this feature will entail: the distinction between “derivation outputs” and “output paths”.&lt;/p&gt;
&lt;p&gt;Note that the changes presented here might not yet be implemented or merged upstream.&lt;/p&gt;
&lt;h1&gt;Store paths&lt;/h1&gt;
&lt;p&gt;Store paths are pervasive in Nix.
Run &lt;code class=&quot;language-text&quot;&gt;nix build&lt;/code&gt;? This will return a store path.
Want to move derivation outputs around? Just &lt;code class=&quot;language-text&quot;&gt;nix copy&lt;/code&gt; their store path.
Even if you can run &lt;code class=&quot;language-text&quot;&gt;nix copy nixpkgs#hello&lt;/code&gt;, this is strictly equivalent to &lt;code class=&quot;language-text&quot;&gt;nix build nixpkgs#hello --out-link hello &amp;amp;&amp;amp; nix copy $(realpath ./hello)&lt;/code&gt;.
Need to know whether a derivation has been built locally or in a binary cache? Just check whether its output path exists.&lt;/p&gt;
&lt;p&gt;This is really nice in a world where the output of the derivations are input-addressed, because there’s a direct mapping between a derivation and its output paths − the &lt;code class=&quot;language-text&quot;&gt;.drv&lt;/code&gt; file actually explicitly contains them − which means that given a derivation Nix can directly know what its output paths are.&lt;/p&gt;
&lt;p&gt;However this falls short with the addition of content-addressed derivations: if &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; is content-addressed then I can’t introspect the derivation to know its output path anymore (see &lt;a href=&quot;https://www.tweag.io/blog/2020-09-10-nix-cas/&quot;&gt;the previous post on that topic&lt;/a&gt;).
Locally, Nix has a database that stores (amongst other things) which derivation produced which outputs, meaning that it knows that &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; has already been built and that its output path is &lt;code class=&quot;language-text&quot;&gt;/nix/store/1234-hello&lt;/code&gt;.
But if I just copy this output path to another machine, and try to rebuild &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; there, Nix won’t be able to know that its output path is already there (because it doesn’t have that mapping), so it will have rebuild the derivation, only to realise that it yields the output path &lt;code class=&quot;language-text&quot;&gt;/nix/store/1234-hello&lt;/code&gt; that’s already there and discard the result.&lt;/p&gt;
&lt;p&gt;This is very frustrating, as it means that the following won’t work:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-console&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ nix copy --to ssh://somewhereelse nixpkgs.hello
# Try to build with `--max-jobs 0` to make it fail if it needs to rebuild anything
$ ssh somewhereelse nix build nixpkgs.hello --max-jobs 0
error: --- Error ----- nix
252 derivations need to be built, but neither local builds ('--max-jobs') nor remote builds ('--builders') are enabled&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We could ask for Nix to copy the mapping between the &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; derivation and its output paths as well, but many derivations might have produced this path, so if we just say &lt;code class=&quot;language-text&quot;&gt;nix copy --to ssh://somewhereelse /nix/store/1234-hello&lt;/code&gt;, does that mean that we want to copy the &lt;code class=&quot;language-text&quot;&gt;1234-hello&lt;/code&gt; store path? Or &lt;code class=&quot;language-text&quot;&gt;1234-hello&lt;/code&gt; the output of the &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; derivation? Or &lt;code class=&quot;language-text&quot;&gt;1234-hello&lt;/code&gt; the output of the &lt;code class=&quot;language-text&quot;&gt;hello2&lt;/code&gt; derivation? Nix has no way to know that.&lt;/p&gt;
&lt;p&gt;This means that we need another way to identify these outputs other than just their store paths.&lt;/p&gt;
&lt;h1&gt;Introducing derivation outputs&lt;/h1&gt;
&lt;p&gt;The one thing that we know though, and that uniquely identifies the derivation, is the hash of the derivation itself.
The derivation for &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; will be stored as &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-hello.drv&lt;/code&gt; (where &lt;code class=&quot;language-text&quot;&gt;xxx&lt;/code&gt; is a hash), and that &lt;code class=&quot;language-text&quot;&gt;xxx&lt;/code&gt; definitely identifies the derivation (and is known before the build).
As this derivation &lt;a href=&quot;https://nixos.org/manual/nix/unstable/expressions/derivations.html?highlight=outputs&quot;&gt;might have several outputs&lt;/a&gt;, we need to append the name of the considered output to get a truly unique identifier, giving us &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-hello.drv!out&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So given this “derivation output id”, Nix will be able to both retrieve the corresponding output path (if it has been built), and know the mapping &lt;code class=&quot;language-text&quot;&gt;(derivation, outputName) -&amp;gt; outputPath&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;With this in hand, we now can run &lt;code class=&quot;language-text&quot;&gt;nix copy --to ssh://somewhereelse /nix/store/xxx-hello.drv!out&lt;/code&gt;, which will both copy the output path &lt;code class=&quot;language-text&quot;&gt;/nix/store/1234-hello&lt;/code&gt; and register on the remote machine that this path is the output &lt;code class=&quot;language-text&quot;&gt;out&lt;/code&gt; of the derivation &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-hello.drv&lt;/code&gt;.
Likewise, &lt;code class=&quot;language-text&quot;&gt;nix copy nixpkgs.hello&lt;/code&gt; will be a shortcut for &lt;code class=&quot;language-text&quot;&gt;nix copy /nix/store/xxx-hello.drv&lt;/code&gt;.
And now we can do&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-console&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ nix copy --to ssh://somewhereelse nixpkgs.hello
# Try to build with `--max-jobs 0` to make it fail if it needs to rebuild anything
$ ssh somewhereelse nix build nixpkgs.hello --max-jobs 0
$ ./result/bin/hello
Hello, world!&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;In practice&lt;/h1&gt;
&lt;p&gt;What will this mean in practice?&lt;/p&gt;
&lt;p&gt;This means that the Nix cli will now return or accept either store paths or derivation output ids depending on the context.
For example &lt;code class=&quot;language-text&quot;&gt;nix build&lt;/code&gt; will still create symlinks to the output paths and &lt;code class=&quot;language-text&quot;&gt;nix shell&lt;/code&gt; will add them to the &lt;code class=&quot;language-text&quot;&gt;PATH&lt;/code&gt; because that’s what makes sense in the context.
But as we’ve seen above, &lt;code class=&quot;language-text&quot;&gt;nix copy&lt;/code&gt; will accept both store paths and derivation output ids, and these will have different semantics.
Copying store paths will just copy the store paths as it used to do (in the case you don’t care about rebuilding them on the other side) while copying derivation outputs will also register these outputs on the remote side.&lt;/p&gt;
&lt;p&gt;Once more, right now, this feature is still under development, so the changes presented here might not yet be implemented or merged upstream.
So don’t be surprised when the feature lands in the near future!&lt;/p&gt;</description>
	<pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Sander van der Burg: Developing an s6-rc backend for the Nix process management framework</title>
	<guid isPermaLink="false">tag:blogger.com,1999:blog-1397115249631682228.post-3970557408955368621</guid>
	<link>http://sandervanderburg.blogspot.com/2021/02/developing-s6-rc-backend-for-nix.html</link>
	<description>One of my major blog topics last year was &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/02/a-declarative-process-manager-agnostic.html&quot;&gt;my experimental Nix process management framework&lt;/a&gt;, that is still under heavy development.&lt;br /&gt;&lt;br /&gt;As explained in many of my earlier blog posts, one of its major objectives is to facilitate &lt;strong&gt;high-level deployment specifications&lt;/strong&gt; of running processes that can be translated to configurations for all kinds of process managers and deployment solutions.&lt;br /&gt;&lt;br /&gt;The backends that I have implemented so far, were picked for the following reasons:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;&lt;strong&gt;Multiple operating systems support&lt;/strong&gt;. The most common process management service was chosen for each operating system: On Linux, &lt;i&gt;sysvinit&lt;/i&gt; (because this used to be the most common solution) and &lt;i&gt;systemd&lt;/i&gt; (because it is used by many conventional Linux distributions today), &lt;i&gt;bsdrc&lt;/i&gt; on FreeBSD, &lt;i&gt;launchd&lt;/i&gt; for macOS, and &lt;i&gt;cygrunsrv&lt;/i&gt; for Cygwin.&lt;/li&gt;  &lt;li&gt;&lt;strong&gt;Supporting unprivileged user deployments&lt;/strong&gt;. To supervise processes without requiring a service that runs on PID 1, that also works for unprivileged users, &lt;i&gt;supervisord&lt;/i&gt; is very convenient because it was specifically designed for this purpose.&lt;/li&gt;  &lt;li&gt;&lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/08/experimenting-with-nix-and-service.html&quot;&gt;&lt;strong&gt;Docker&lt;/strong&gt; was selected&lt;/a&gt; because it is a very popular solution for managing services, and process management is one of its sub responsibilities.&lt;/li&gt;  &lt;li&gt;&lt;strong&gt;Universal process management&lt;/strong&gt;. &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/06/using-disnix-as-simple-and-minimalistic.html&quot;&gt;Disnix was selected&lt;/a&gt; because it can be used as a primitive process management solution that works on any operating system supported by the Nix package manager. Moreover, the Disnix services model is a super set of the processes model used by the process management framework.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Not long after writing my blog post about the process manager-agnostic abstraction layer, somebody opened &lt;a href=&quot;https://github.com/svanderburg/nix-processmgmt/issues/1&quot;&gt;an issue on GitHub&lt;/a&gt; with the suggestion to also support &lt;i&gt;s6-rc&lt;/i&gt;. Although I was already aware that more process/service management solutions exist, &lt;i&gt;s6-rc&lt;/i&gt; was a solution that I did not know about.&lt;br /&gt;&lt;br /&gt;Recently, I have implemented the suggested &lt;i&gt;s6-rc&lt;/i&gt; backend. Although deploying &lt;i&gt;s6-rc&lt;/i&gt; services now works quite conveniently, getting to know &lt;i&gt;s6-rc&lt;/i&gt; and its companion tools was somewhat challenging for me.&lt;br /&gt;&lt;br /&gt;In this blog post, I will elaborate about my learning experiences and explain how the &lt;i&gt;s6-rc&lt;/i&gt; backend was implemented.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;The s6 tool suite&lt;/h2&gt;&lt;br /&gt;&lt;a href=&quot;https://skarnet.org/software/s6-rc&quot;&gt;&lt;i&gt;s6-rc&lt;/i&gt;&lt;/a&gt; is a software projected published on &lt;a href=&quot;https://skarnet.org&quot;&gt;skarnet&lt;/a&gt; and part of a bigger &lt;a href=&quot;https://skarnet.org/software&quot;&gt;tool ecosystem&lt;/a&gt;. &lt;i&gt;s6-rc&lt;/i&gt; is a companion tool of &lt;a href=&quot;https://skarnet.org/software/s6&quot;&gt;s6&lt;/a&gt;: skarnet.org's small &amp;amp; secure supervision software suite.&lt;br /&gt;&lt;br /&gt;On Linux and many other UNIX-like systems, the initialization process (typically &lt;i&gt;/sbin/init&lt;/i&gt;) is a &lt;strong&gt;highly critical&lt;/strong&gt; program:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;It is the first program loaded by the kernel and responsible for setting the remainder of the boot procedure in motion. This procedure is responsible for mounting additional file systems, loading device drivers, and starting essential system services, such as SSH and logging services.&lt;/li&gt;  &lt;li&gt;The PID 1 process supervises all processes that were directly loaded by it, as well as indirect child processes that get orphaned -- when this happens they get automatically adopted by the process that runs as PID 1.&lt;br /&gt;    &lt;br /&gt;    As explained in &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/01/writing-well-behaving-daemon-in-c.html&quot;&gt;an earlier blog post&lt;/a&gt;, traditional UNIX services that daemonize on their own, deliberately orphan themselves so that they remain running in the background.&lt;/li&gt;  &lt;li&gt;When a child process terminates, the parent process must take notice or the terminated process will stay behind as a zombie process.&lt;br /&gt;    &lt;br /&gt;    Because the PID 1 process is the common ancestor of all other processes, it is required to automatically reap all relevant zombie processes that become a child of it.&lt;/li&gt;  &lt;li&gt;The PID 1 process runs with root privileges and, as a result, has full access to the system. When the security of the PID 1 process gets compromised, the entire system is at risk.&lt;/li&gt;  &lt;li&gt;If the PID 1 process crashes, the kernel crashes (and hence the entire system) with a kernel panic.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;There are many kinds of programs that you can use as a system's PID 1. For example, you can directly use a shell, such as &lt;i&gt;bash&lt;/i&gt;, but is far more common to use an init system, such as &lt;a href=&quot;https://savannah.nongnu.org/projects/sysvinit&quot;&gt;&lt;i&gt;sysvinit&lt;/i&gt;&lt;/a&gt; or &lt;a href=&quot;https://www.freedesktop.org/wiki/Software/systemd&quot;&gt;&lt;i&gt;systemd&lt;/i&gt;&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;According to the author of &lt;i&gt;s6&lt;/i&gt;, &lt;a href=&quot;https://skarnet.org/software/s6-linux-init/why.html&quot;&gt;an init system is made out of four parts&lt;/a&gt;:&lt;br /&gt;&lt;br /&gt;&lt;blockquote&gt;  &lt;ol&gt;    &lt;li&gt;&lt;i&gt;/sbin/init&lt;/i&gt;: the first userspace program that is run by the kernel at boot time (not counting an initramfs).&lt;/li&gt;    &lt;li&gt;pid 1: the program that will run as process 1 for most of the lifetime of the machine. This is not necessarily the same executable as &lt;i&gt;/sbin/init&lt;/i&gt;, because &lt;i&gt;/sbin/init&lt;/i&gt; can exec into something else.&lt;/li&gt;    &lt;li&gt;a process supervisor.&lt;/li&gt;    &lt;li&gt;a service manager.&lt;/li&gt;  &lt;/ol&gt;&lt;/blockquote&gt;&lt;br /&gt;In the &lt;i&gt;s6&lt;/i&gt; tool eco-system, most of these parts are implemented by separate tools:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The first userspace program: &lt;i&gt;s6-linux-init&lt;/i&gt; takes care of the coordination of the initialization process. It does a variety of one-time boot things: for example, it traps the ctrl-alt-del keyboard combination, it starts the shutdown daemon (that is responsible for eventually shutting down the system), and runs the initial boot script (&lt;i&gt;rc.init&lt;/i&gt;).&lt;br /&gt;    &lt;br /&gt;    (As a sidenote: this is almost true -- the &lt;i&gt;/sbin/init&lt;/i&gt; process is a wrapper script that &quot;execs&quot; into &lt;i&gt;s6-linux-linux-init&lt;/i&gt; with the appropriate parameters).&lt;/li&gt;  &lt;li&gt;When the initialization is done, &lt;i&gt;s6-linux-init&lt;/i&gt; execs into a process called &lt;i&gt;s6-svscan&lt;/i&gt; provided by the &lt;i&gt;s6&lt;/i&gt; toolset. &lt;i&gt;s6-svscan&lt;/i&gt;'s task is to supervise an entire process supervision tree, which I will explain later.&lt;/li&gt;  &lt;li&gt;Starting and stopping services is done by a separate service manager started from the &lt;i&gt;rc.init&lt;/i&gt; script. &lt;i&gt;s6-rc&lt;/i&gt; is the most prominent option (that we will use in this blog post), but also other tools can be used.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Many conventional init systems, implement most (or sometimes all) of these aspects in a single executable.&lt;br /&gt;&lt;br /&gt;In particular, the &lt;i&gt;s6&lt;/i&gt; author is highly critical of systemd: the init system that is widely used by many conventional Linux distributions today -- he dedicated &lt;a href=&quot;https://skarnet.org/software/systemd.html&quot;&gt;an entire page with criticisms about it&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;The author of &lt;i&gt;s6&lt;/i&gt; advocates a number of design principles for his tool eco-system (that systemd violates in many ways):&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The Unix philosophy: do one job and do it well.&lt;/li&gt;  &lt;li&gt;Doing less instead of more (preventing feature creep).&lt;/li&gt;  &lt;li&gt;Keeping tight quality control over every tool by only opening up repository access to small teams only (or rather a single person).&lt;/li&gt;  &lt;li&gt;Integration support: he is against the &lt;a href=&quot;http://www.catb.org/esr/writings/cathedral-bazaar&quot;&gt;bazaar&lt;/a&gt; approach on project level, but in favor of the bazaar approach on an eco-system level in which everybody can write their own tools that integrate with existing tools.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;The concepts implemented by the &lt;i&gt;s6&lt;/i&gt; tool suite were not completely &quot;invented&quot; from scratch. &lt;a href=&quot;http://cr.yp.to/daemontools.html&quot;&gt;daemontools&lt;/a&gt; is what the author considers the ancestor of s6 (if you look at the web page then you will notice that the concept of a &quot;supervision tree&quot; was pioneered there and that some of the tools listed resemble the same tools in the &lt;i&gt;s6&lt;/i&gt; tool suite), and &lt;a href=&quot;http://smarden.org/runit&quot;&gt;runit&lt;/a&gt; its cousin (that is also heavily inspired by daemontools).&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;A basic usage scenario of s6 and s6-rc&lt;/h2&gt;&lt;br /&gt;Although it is possible to use Linux distributions in which the init system, supervisor and service manager are all provided by skarnet tools, a sub set of &lt;i&gt;s6&lt;/i&gt; and &lt;i&gt;s6-rc&lt;/i&gt; can also be used on any Linux distribution and other supported operating systems, such as the BSDs.&lt;br /&gt;&lt;br /&gt;Root privileges are not required to experiment with these tools.&lt;br /&gt;&lt;br /&gt;For example, with the following command we can use the Nix package manager to deploy the &lt;i&gt;s6&lt;/i&gt; supervision toolset in a development shell session:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-shell -p s6&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;In this development shell session, we can start the &lt;i&gt;s6-svscan&lt;/i&gt; service as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ mkdir -p $HOME/var/run/service&lt;br /&gt;$ s6-svscan $HOME/var/run/service&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The &lt;i&gt;s6-svscan&lt;/i&gt; is a service that supervises an entire process supervision tree, including processes that may accidentally become a child of it, such as orphaned processes.&lt;br /&gt;&lt;br /&gt;The directory parameter is a &lt;strong&gt;scan directory&lt;/strong&gt; that maintains the configurations of the processes that are currently supervised. So far, no supervised process have been deployed yet.&lt;br /&gt;&lt;br /&gt;We can actually deploy services by using the &lt;i&gt;s6-rc&lt;/i&gt; toolset.&lt;br /&gt;&lt;br /&gt;For example, I can easily configure &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/02/a-declarative-process-manager-agnostic.html&quot;&gt;my trivial example system&lt;/a&gt; used in previous blog posts that consists of one or multiple web application processes (with an embedded HTTP server) returning static HTML pages and an Nginx reverse proxy that forwards requests to one of the web application processes based on the appropriate virtual host header.&lt;br /&gt;&lt;br /&gt;Contrary to the other process management solutions that I have investigated earlier, &lt;i&gt;s6-rc&lt;/i&gt; does not have an elaborate configuration language. It does not implement a parser (&lt;a href=&quot;https://skarnet.org/software/s6-rc/faq.html&quot;&gt;for very good reasons as explained by the author&lt;/a&gt;, because it introduces extra complexity and bugs).&lt;br /&gt;&lt;br /&gt;Instead, you have to create directories with text files, in which each file represents a configuration property.&lt;br /&gt;&lt;br /&gt;With the following command, I can spawn a development shell with all the required utilities to work with &lt;i&gt;s6-rc&lt;/i&gt;:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-shell -p s6 s6-rc execline&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The following shell commands create an &lt;i&gt;s6-rc&lt;/i&gt; service configuration directory and a configuration for a single &lt;i&gt;webapp&lt;/i&gt; process instance:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ mkdir -p sv/webapp&lt;br /&gt;$ cd sv/webapp&lt;br /&gt;&lt;br /&gt;$ echo &quot;longrun&quot; &amp;gt; type&lt;br /&gt;&lt;br /&gt;$ cat &amp;gt; run &amp;lt;&amp;lt;EOF&lt;br /&gt;$ #!$(type -p execlineb) -P&lt;br /&gt;&lt;br /&gt;envfile $HOME/envfile&lt;br /&gt;exec $HOME/webapp/bin/webapp&lt;br /&gt;EOF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above shell script creates a configuration directory for a service named: &lt;i&gt;webapp&lt;/i&gt; with the following properties:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;It creates a service with &lt;strong&gt;type&lt;/strong&gt;: &lt;i&gt;longrun&lt;/i&gt;. A long run service deploys a process that runs in the foreground that will get supervised by &lt;i&gt;s6&lt;/i&gt;.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;run&lt;/i&gt; file refers to an &lt;strong&gt;executable&lt;/strong&gt; that &lt;strong&gt;starts&lt;/strong&gt; the service. For &lt;i&gt;s6-rc&lt;/i&gt; services it is common practice to implement wrapper scripts using &lt;a href=&quot;https://skarnet.org/software/execline/&quot;&gt;&lt;i&gt;execline&lt;/i&gt;&lt;/a&gt;: a non-interactive scripting language.&lt;br /&gt;    &lt;br /&gt;    The execline script shown above loads an environment variable config file with the following content: &lt;i&gt;PORT=5000&lt;/i&gt;. This environment variable is used to configure the TCP port number to which the service should bind to and then &quot;execs&quot; into a new process that runs the &lt;i&gt;webapp&lt;/i&gt; process.&lt;br /&gt;    &lt;br /&gt;    (As a sidenote: although it is a common habit to use &lt;i&gt;execline&lt;/i&gt; for writing wrapper scripts, this is not a hard requirement -- any executable implemented in any language can be used. For example, we could also write the above &lt;i&gt;run&lt;/i&gt; wrapper script as a bash script).&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;We can also configure the Nginx reverse proxy service in a similar way:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;$ mkdir -p ../nginx&lt;br /&gt;$ cd ../nginx&lt;br /&gt;&lt;br /&gt;$ echo &quot;longrun&quot; &amp;gt; type&lt;br /&gt;$ echo &quot;webapp&quot; &amp;gt; dependencies&lt;br /&gt;&lt;br /&gt;$ cat &amp;gt; run &amp;lt;&amp;lt;EOF&lt;br /&gt;$ #!$(type -p execlineb) -P&lt;br /&gt;&lt;br /&gt;foreground { mkdir -p $HOME/var/nginx/logs $HOME/var/cache/nginx }&lt;br /&gt;exec $(type -p nginx) &quot;-p&quot; &quot;$HOME/var/nginx&quot; &quot;-c&quot; &quot;$HOME/nginx/nginx.conf&quot; &quot;-g&quot; &quot;daemon off;&quot;&lt;br /&gt;EOF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above shell script creates a configuration directory for a service named: &lt;i&gt;nginx&lt;/i&gt; with the following properties:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;It again creates a service of &lt;strong&gt;type&lt;/strong&gt;: &lt;i&gt;longrun&lt;/i&gt; because Nginx should be started as a foreground process.&lt;/li&gt;  &lt;li&gt;It declares the &lt;i&gt;webapp&lt;/i&gt; service (that we have configured earlier) a &lt;strong&gt;dependency&lt;/strong&gt; ensuring that &lt;i&gt;webapp&lt;/i&gt; is started before &lt;i&gt;nginx&lt;/i&gt;. This dependency relationship is important to prevent Nginx doing a redirect to a non-existent service.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;run&lt;/i&gt; script first creates all mandatory state directories and finally execs into the Nginx process, with a configuration file using the above state directories, and turning off daemon mode so that it runs in the foreground.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;In addition to configuring the above services, we also want to deploy the system as a whole. This can be done by creating &lt;strong&gt;bundles&lt;/strong&gt; that encapsulate collections of services:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;mkdir -p ../default&lt;br /&gt;cd ../default&lt;br /&gt;&lt;br /&gt;echo &quot;bundle&quot; &amp;gt; type&lt;br /&gt;&lt;br /&gt;cat &amp;gt; contents &amp;lt;&amp;lt;EOF&lt;br /&gt;webapp&lt;br /&gt;nginx&lt;br /&gt;EOF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above shell instructions create a bundle named: &lt;strong&gt;default&lt;/strong&gt; referring to both the &lt;i&gt;webapp&lt;/i&gt; and &lt;i&gt;nginx&lt;/i&gt; reverse proxy service that we have configured earlier.&lt;br /&gt;&lt;br /&gt;Our &lt;i&gt;s6-rc&lt;/i&gt; configuration directory structure looks as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ find ./sv&lt;br /&gt;./sv&lt;br /&gt;./sv/default&lt;br /&gt;./sv/default/contents&lt;br /&gt;./sv/default/type&lt;br /&gt;./sv/nginx/run&lt;br /&gt;./sv/nginx/type&lt;br /&gt;./sv/webapp/dependencies&lt;br /&gt;./sv/webapp/run&lt;br /&gt;./sv/webapp/type&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;If we want to deploy the service directory structure shown above, we first need to &lt;strong&gt;compile&lt;/strong&gt; it into a &lt;strong&gt;configuration database&lt;/strong&gt;. This can be done with the following command:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ mkdir -p $HOME/etc/s6/rc&lt;br /&gt;$ s6-rc-compile $HOME/etc/s6/rc/compiled-1 $HOME/sv&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command creates a compiled database file in: &lt;i&gt;$HOME/etc/s6/rc/compiled-1&lt;/i&gt; stored in: &lt;i&gt;$HOME/sv&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;With the following command we can &lt;strong&gt;initialize&lt;/strong&gt; the &lt;i&gt;s6-rc&lt;/i&gt; system with our compiled configuration database:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ s6-rc-init -c $HOME/etc/s6/rc/compiled-1 -l $HOME/var/run/s6-rc \&lt;br /&gt;  $HOME/var/run/service&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command generates a &quot;live directory&quot; in: &lt;i&gt;$HOME/var/run/s6-rc&lt;/i&gt; containing the state of &lt;i&gt;s6-rc&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;With the following command, we can start all services in the: &lt;i&gt;default&lt;/i&gt; bundle:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ s6-rc -l $HOME/var/run/s6-rc -u change default&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command deploys a running system with the following process tree:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-rByP1YrSicM/YBVdDrW8UmI/AAAAAAAALMk/CadZ92HB40IJEuoYNEtOIRnbp0NkUE1swCLcBGAsYHQ/s0/processtree.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-rByP1YrSicM/YBVdDrW8UmI/AAAAAAAALMk/CadZ92HB40IJEuoYNEtOIRnbp0NkUE1swCLcBGAsYHQ/s0/processtree.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;As as can be seen in the diagram above, the entire process tree is supervised by &lt;i&gt;s6-svscan&lt;/i&gt; (the program that we have started first). Every &lt;i&gt;longrun&lt;/i&gt; service deployed by &lt;i&gt;s6-rc&lt;/i&gt; is supervised by a process named: &lt;i&gt;s6-supervise&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Managing service logging&lt;/h2&gt;&lt;br /&gt;Another important property of &lt;i&gt;s6&lt;/i&gt; and &lt;i&gt;s6-rc&lt;/i&gt; is the way it handles logging. By default, all output that the supervised processes produce on the standard output and standard error are captured by &lt;i&gt;s6-svscan&lt;/i&gt; and written to a single log stream (in our case, it will be redirected to the terminal).&lt;br /&gt;&lt;br /&gt;When it is desired to capture the output of a service into its own dedicated log file, you need to configure the service in such a way that it writes all relevant information to a pipe. A companion &lt;strong&gt;logging service&lt;/strong&gt; is required to capture the data that is sent over the pipe.&lt;br /&gt;&lt;br /&gt;The following command-line instructions modify the &lt;i&gt;webapp&lt;/i&gt; service (that we have created earlier) to let it send its output to another service:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ cd sv&lt;br /&gt;$ mv webapp webapp-srv&lt;br /&gt;$ cd webapp-srv&lt;br /&gt;&lt;br /&gt;$ echo &quot;webapp-log&quot; &amp;gt; producer-for&lt;br /&gt;$ cat &amp;gt; run &amp;lt;&amp;lt;EOF&lt;br /&gt;$ #!$(type -p execlineb) -P&lt;br /&gt;&lt;br /&gt;envfile $HOME/envfile&lt;br /&gt;fdmove -c 2 1&lt;br /&gt;exec $HOME/webapp/bin/webapp&lt;br /&gt;EOF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;In the script above, we have changed the &lt;i&gt;webapp&lt;/i&gt; service configuration as follows:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;We &lt;strong&gt;rename&lt;/strong&gt; the service from: &lt;i&gt;webapp&lt;/i&gt; to &lt;i&gt;webapp-srv&lt;/i&gt;. Using suffixes is a convention commonly used for &lt;i&gt;s6-rc&lt;/i&gt; services that also have a log companion service.&lt;/li&gt;  &lt;li&gt;With the &lt;i&gt;producer-for&lt;/i&gt; property, we specify that the &lt;i&gt;webapp-srv&lt;/i&gt; is a service that &lt;strong&gt;produces&lt;/strong&gt; output for another service named: &lt;i&gt;webapp-log&lt;/i&gt;. We will configure this service later.&lt;/li&gt;  &lt;li&gt;We create a new &lt;i&gt;run&lt;/i&gt; script that &lt;strong&gt;adds&lt;/strong&gt; the following command: &lt;i&gt;fdmove -c 2 1&lt;/i&gt;.&lt;br /&gt;    &lt;br /&gt;    The purpose of this added instruction is to redirect all output that is sent over the standard error (file descriptor: 2) to the standard output (file descriptor: 1). This redirection makes it possible that all data can be captured by the log companion service.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;We can configure the log companion service: &lt;i&gt;webapp-log&lt;/i&gt; with the following command-line instructions:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ mkdir ../webapp-log&lt;br /&gt;$ cd ../webapp-log&lt;br /&gt;&lt;br /&gt;$ echo &quot;longrun&quot; &amp;gt; type&lt;br /&gt;$ echo &quot;webapp-srv&quot; &amp;gt; consumer-for&lt;br /&gt;$ echo &quot;webapp&quot; &amp;gt; pipeline-name&lt;br /&gt;$ echo 3 &amp;gt; notification-fd&lt;br /&gt;&lt;br /&gt;$ cat &amp;gt; run &amp;lt;&amp;lt;EOF&lt;br /&gt;#!$(type -p execlineb) -P&lt;br /&gt;&lt;br /&gt;foreground { mkdir -p $HOME/var/log/s6-log/webapp }&lt;br /&gt;exec -c s6-log -d3 $HOME/var/log/s6-log/webapp&lt;br /&gt;EOF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The service configuration created above does the following:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;We create a service named: &lt;i&gt;webapp-log&lt;/i&gt; that is a &lt;strong&gt;long running&lt;/strong&gt; service.&lt;/li&gt;  &lt;li&gt;We declare the service to be a &lt;strong&gt;consumer&lt;/strong&gt; for the &lt;i&gt;webapp-srv&lt;/i&gt; (earlier, we have already declared the companion service: &lt;i&gt;webapp-srv&lt;/i&gt; to be a producer for this logging service).&lt;/li&gt;  &lt;li&gt;We configure a &lt;strong&gt;pipeline name&lt;/strong&gt;: &lt;i&gt;webapp&lt;/i&gt; causing &lt;i&gt;s6-rc&lt;/i&gt; to automatically generate a bundle with the name: &lt;i&gt;webapp&lt;/i&gt; in which all involved services are its contents.&lt;br /&gt;    &lt;br /&gt;    This generated bundle allows us to always manage the service and logging companion as a single deployment unit.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;s6-log&lt;/i&gt; service supports &lt;strong&gt;readiness notifications&lt;/strong&gt;. File descriptor: &lt;i&gt;3&lt;/i&gt; is configured to receive that notification.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;run&lt;/i&gt; script creates the log directory in which the output should be stored and starts the &lt;i&gt;s6-log&lt;/i&gt; service to capture the output and store the data in the corresponding log directory.&lt;br /&gt;    &lt;br /&gt;    The &lt;i&gt;-d3&lt;/i&gt; parameter instructs it to send a readiness notification over file descriptor 3.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;After modifying the configuration files in such a way that each &lt;i&gt;longrun&lt;/i&gt; service has a logging companion, we need to compile a new database that provides &lt;i&gt;s6-rc&lt;/i&gt; our new configuration:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ s6-rc-compile $HOME/etc/s6/rc/compiled-2 $HOME/sv&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command creates a database with a new filename in: &lt;i&gt;$HOME/etc/s6/rc/compiled-2&lt;/i&gt;. We are required to give it a new name -- the old configuration database (&lt;i&gt;compiled-1&lt;/i&gt;) must be retained to make the upgrade process work.&lt;br /&gt;&lt;br /&gt;With the following command, we can upgrade our running configuration:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ s6-rc-update -l $HOME/var/run/s6-rc $HOME/etc/s6/rc/compiled-2&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The result is the following process supervision tree:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-8VvXDUt3BAw/YBWGVzXn6AI/AAAAAAAALM8/feklrGascBMxW4Dm0wGErY4W_gDmFzR6gCLcBGAsYHQ/s0/processtreewithloggers.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-8VvXDUt3BAw/YBWGVzXn6AI/AAAAAAAALM8/feklrGascBMxW4Dm0wGErY4W_gDmFzR6gCLcBGAsYHQ/s0/processtreewithloggers.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;As you may observe by looking at the diagram above, every service has a companion &lt;i&gt;s6-log&lt;/i&gt; service that is responsible for capturing and storing its output.&lt;br /&gt;&lt;br /&gt;The log files of the services can be found in &lt;i&gt;$HOME/var/log/s6-log/webapp&lt;/i&gt; and &lt;i&gt;$HOME/var/log/s6-log/nginx&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;One shot services&lt;/h2&gt;&lt;br /&gt;In addition to &lt;i&gt;longrun&lt;/i&gt; services that are useful for managing system services, more aspects need to be automated in a boot process, such as mounting file systems.&lt;br /&gt;&lt;br /&gt;These kinds of tasks can be automated with &lt;i&gt;oneshot&lt;/i&gt; services, that execute an &lt;i&gt;up&lt;/i&gt; script on startup, and optionally, a &lt;i&gt;down&lt;/i&gt; script on shutdown.&lt;br /&gt;&lt;br /&gt;The following service configuration can be used to mount the kernel's &lt;i&gt;/proc&lt;/i&gt; filesystem:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;mkdir -p ../mount-proc&lt;br /&gt;cd ../mount-proc&lt;br /&gt;&lt;br /&gt;echo &quot;oneshot&quot; &amp;gt; type&lt;br /&gt;&lt;br /&gt;cat &amp;gt; run &amp;lt;&amp;lt;EOF&lt;br /&gt;$ #!$(type -p execlineb) -P&lt;br /&gt;foreground { mount -t proc proc /proc }&lt;br /&gt;EOF&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;Chain loading&lt;/h2&gt;&lt;br /&gt;The &lt;i&gt;execline&lt;/i&gt; scripts shown in this blog post resemble shell scripts in many ways. One particular aspect that sets execline scripts apart from shell scripts is that all commands make intensive use of a concept called &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Chain_loading&quot;&gt;chain loading&lt;/a&gt;&lt;/strong&gt;.&lt;br /&gt;&lt;br /&gt;Every instruction in an execline script executes a task, may imperatively modify the environment (e.g. by changing environment variables, or changing the current working directory etc.) and then &quot;execs&quot; into a new chain loading task.&lt;br /&gt;&lt;br /&gt;The last parameter of each command-line instruction refers to the command-line instruction that it needs to &quot;execs into&quot; -- typically this command-line instruction is put on the next line.&lt;br /&gt;&lt;br /&gt;The &lt;i&gt;execline&lt;/i&gt; package, as well as many packages in the &lt;i&gt;s6&lt;/i&gt; ecosystem, contain many programs that support chain loading.&lt;br /&gt;&lt;br /&gt;It is also possible to implement custom chain loaders that follow the same protocol.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Developing s6-rc function abstractions for the Nix process management framework&lt;/h2&gt;&lt;br /&gt;In the Nix process management framework, I have added function abstractions for each &lt;i&gt;s6-rc&lt;/i&gt; service type: &lt;i&gt;longrun&lt;/i&gt;, &lt;i&gt;oneshot&lt;/i&gt; and &lt;i&gt;bundle&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;For example, with the following Nix expression we can generate an &lt;i&gt;s6-rc&lt;/i&gt; &lt;i&gt;longrun&lt;/i&gt; configuration for the &lt;i&gt;webapp&lt;/i&gt; process:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;{createLongRunService, writeTextFile, execline, webapp}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  envFile = writeTextFile {&lt;br /&gt;    name = &quot;envfile&quot;;&lt;br /&gt;    text = ''&lt;br /&gt;      PORT=5000&lt;br /&gt;    '';&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;createLongRunService {&lt;br /&gt;  name = &quot;webapp&quot;;&lt;br /&gt;  run = writeTextFile {&lt;br /&gt;    name = &quot;run&quot;;&lt;br /&gt;    executable = true;&lt;br /&gt;    text = ''&lt;br /&gt;      #!${execline}/bin/execlineb -P&lt;br /&gt;&lt;br /&gt;      envfile ${envFile}&lt;br /&gt;      fdmove -c 2 1&lt;br /&gt;      exec ${webapp}/bin/webapp&lt;br /&gt;    '';&lt;br /&gt;  };&lt;br /&gt;  autoGenerateLogService = true;&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;Evaluating the Nix expression above does the following:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;It generates a service directory that corresponds to the: &lt;i&gt;name&lt;/i&gt; parameter with a &lt;i&gt;longrun&lt;/i&gt; &lt;i&gt;type&lt;/i&gt; property file.&lt;/li&gt;  &lt;li&gt;It generates a &lt;i&gt;run&lt;/i&gt; execline script, that uses a generated &lt;i&gt;envFile&lt;/i&gt; for configuring the service's port number, redirects the standard error to the standard output and starts the &lt;i&gt;webapp&lt;/i&gt; process (that runs in the foreground).&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;autoGenerateLogService&lt;/i&gt; parameter is a concept I introduced myself, to conveniently configure a companion log service, because this a very common operation -- I cannot think of any scenario in which you do not want to have a dedicated log file for a long running service.&lt;br /&gt;    &lt;br /&gt;    Enabling this option causes the service to automatically become a producer for the log companion service (having the same name with a &lt;i&gt;-log&lt;/i&gt; suffix) and automatically configures a logging companion service that consumes from it.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;In addition to constructing long run services from Nix expressions, there are also abstraction functions to create one shots: &lt;i&gt;createOneShotService&lt;/i&gt; and bundles: &lt;i&gt;createServiceBundle&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;The function that generates a log companion service can also be directly invoked with: &lt;i&gt;createLogServiceForLongRunService&lt;/i&gt;, if desired.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Generating a s6-rc service configuration from a process-manager agnostic configuration&lt;/h2&gt;&lt;br /&gt;The following Nix expression is a process manager-agnostic configuration for the &lt;i&gt;webapp&lt;/i&gt; service, that can be translated to a configuration for any supported process manager in the Nix process management framework:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;{createManagedProcess, tmpDir}:&lt;br /&gt;{port, instanceSuffix ? &quot;&quot;, instanceName ? &quot;webapp${instanceSuffix}&quot;}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  webapp = import ../../webapp;&lt;br /&gt;in&lt;br /&gt;createManagedProcess {&lt;br /&gt;  name = instanceName;&lt;br /&gt;  description = &quot;Simple web application&quot;;&lt;br /&gt;  inherit instanceName;&lt;br /&gt;&lt;br /&gt;  process = &quot;${webapp}/bin/webapp&quot;;&lt;br /&gt;  daemonArgs = [ &quot;-D&quot; ];&lt;br /&gt;&lt;br /&gt;  environment = {&lt;br /&gt;    PORT = port;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  overrides = {&lt;br /&gt;    sysvinit = {&lt;br /&gt;      runlevels = [ 3 4 5 ];&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The Nix expression above specifies the following high-level configuration concepts:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The &lt;i&gt;name&lt;/i&gt; and &lt;i&gt;description&lt;/i&gt; attributes are just meta data. The &lt;i&gt;description&lt;/i&gt; property is ignored by the &lt;i&gt;s6-rc&lt;/i&gt; generator, because &lt;i&gt;s6-rc&lt;/i&gt; has no equivalent configuration property for capturing a description.&lt;/li&gt;  &lt;li&gt;A process manager-agnostic configuration can specify both how the service can be started as a &lt;strong&gt;foreground process&lt;/strong&gt; or as a process that &lt;strong&gt;daemonizes&lt;/strong&gt; itself.&lt;br /&gt;    &lt;br /&gt;    In the above example, the &lt;i&gt;process&lt;/i&gt; attribute specifies that the same executable needs to invoked for both a &lt;i&gt;foregroundProcess&lt;/i&gt; and &lt;i&gt;daemon&lt;/i&gt;. The &lt;i&gt;daemonArgs&lt;/i&gt; parameter specifies the command-line arguments that need to be propagated to the executable to let it daemonize itself.&lt;br /&gt;  &lt;br /&gt;    &lt;i&gt;s6-rc&lt;/i&gt; has a preference for managing foreground processes, because these can be more reliably managed. When a &lt;i&gt;foregroundProcess&lt;/i&gt; executable can be inferred, the generator will automatically compose a &lt;i&gt;longrun&lt;/i&gt; service making it possible for &lt;i&gt;s6&lt;/i&gt; to supervise it.&lt;br /&gt;    &lt;br /&gt;    If only a &lt;i&gt;daemon&lt;/i&gt; can be inferred, the generator will compose a &lt;i&gt;oneshot&lt;/i&gt; service that starts the daemon with the &lt;i&gt;up&lt;/i&gt; script, and on shutdown, terminates the daemon by dereferencing the PID file in the &lt;i&gt;down&lt;/i&gt; script.   &lt;/li&gt;  &lt;li&gt;The &lt;i&gt;environment&lt;/i&gt; attribute set parameter is automatically translated to an &lt;i&gt;envfile&lt;/i&gt; that the generated &lt;i&gt;run&lt;/i&gt; script consumes.&lt;/li&gt;  &lt;li&gt;Similar to the &lt;i&gt;sysvinit&lt;/i&gt; backend, it is also possible to override the generated arguments for the &lt;i&gt;s6-rc&lt;/i&gt; backend, if desired.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;As already explained in the blog post that covers the framework's concepts, the Nix expression above needs to be complemented with a &lt;strong&gt;constructors&lt;/strong&gt; expression that composes the common parameters of every process configuration and a &lt;strong&gt;processes&lt;/strong&gt; model that constructs process instances that need to be deployed.&lt;br /&gt;&lt;br /&gt;The following processes model can be used to deploy a &lt;i&gt;webapp&lt;/i&gt; process and an &lt;i&gt;nginx&lt;/i&gt; reverse proxy instance that connects to it:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;{ pkgs ? import &amp;lt;nixpkgs&amp;gt; { inherit system; }&lt;br /&gt;, system ? builtins.currentSystem&lt;br /&gt;, stateDir ? &quot;/var&quot;&lt;br /&gt;, runtimeDir ? &quot;${stateDir}/run&quot;&lt;br /&gt;, logDir ? &quot;${stateDir}/log&quot;&lt;br /&gt;, cacheDir ? &quot;${stateDir}/cache&quot;&lt;br /&gt;, tmpDir ? (if stateDir == &quot;/var&quot; then &quot;/tmp&quot; else &quot;${stateDir}/tmp&quot;)&lt;br /&gt;, forceDisableUserChange ? false&lt;br /&gt;, processManager&lt;br /&gt;}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  constructors = import ./constructors.nix {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir tmpDir;&lt;br /&gt;    inherit forceDisableUserChange processManager;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;rec {&lt;br /&gt;  webapp = rec {&lt;br /&gt;    port = 5000;&lt;br /&gt;    dnsName = &quot;webapp.local&quot;;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.webapp {&lt;br /&gt;      inherit port;&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  nginx = rec {&lt;br /&gt;    port = 8080;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.nginxReverseProxyHostBased {&lt;br /&gt;      webapps = [ webapp ];&lt;br /&gt;      inherit port;&lt;br /&gt;    } {};&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With the following command-line instruction, we can automatically create a scan directory and start &lt;i&gt;s6-svscan&lt;/i&gt;:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nixproc-s6-svscan --state-dir $HOME/var&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The &lt;i&gt;--state-dir&lt;/i&gt; causes the scan directory to be created in the user's home directory making unprivileged deployments possible.&lt;br /&gt;&lt;br /&gt;With the following command, we can deploy the entire system, that will get supervised by the &lt;i&gt;s6-svscan&lt;/i&gt; service that we just started:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nixproc-s6-rc-switch --state-dir $HOME/var \&lt;br /&gt;  --force-disable-user-change processes.nix&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The &lt;i&gt;--force-disable-user-change&lt;/i&gt; parameter prevents the deployment system from creating users and groups and changing user privileges, allowing the deployment as an unprivileged user to succeed.&lt;br /&gt;&lt;br /&gt;The result is a running system that allows us to connect to the &lt;i&gt;webapp&lt;/i&gt; service via the Nginx reverse proxy:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ curl -H 'Host: webapp.local' http://localhost:8080&lt;br /&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;br /&gt;&amp;lt;html&amp;gt;&lt;br /&gt;  &amp;lt;head&amp;gt;&lt;br /&gt;    &amp;lt;title&amp;gt;Simple test webapp&amp;lt;/title&amp;gt;&lt;br /&gt;  &amp;lt;/head&amp;gt;&lt;br /&gt;  &amp;lt;body&amp;gt;&lt;br /&gt;    Simple test webapp listening on port: 5000&lt;br /&gt;  &amp;lt;/body&amp;gt;&lt;br /&gt;&amp;lt;/html&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;Constructing multi-process Docker images supervised by s6&lt;/h2&gt;&lt;br /&gt;Another feature of the Nix process management framework is constructing &lt;strong&gt;multi-process Docker images&lt;/strong&gt; in which multiple process instances are supervised by a process manager of choice.&lt;br /&gt;&lt;br /&gt;&lt;i&gt;s6&lt;/i&gt; can also be used as a supervisor in a container. To accomplish this, we can use &lt;i&gt;s6-linux-init&lt;/i&gt; as an entry point.&lt;br /&gt;&lt;br /&gt;The following attribute generates a skeleton configuration directory:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;let&lt;br /&gt;  skelDir = pkgs.stdenv.mkDerivation {&lt;br /&gt;    name = &quot;s6-skel-dir&quot;;&lt;br /&gt;    buildCommand = ''&lt;br /&gt;      mkdir -p $out&lt;br /&gt;      cd $out&lt;br /&gt;&lt;br /&gt;      cat &amp;gt; rc.init &amp;lt;&amp;lt;EOF&lt;br /&gt;      #! ${pkgs.stdenv.shell} -e&lt;br /&gt;      rl=&quot;\$1&quot;&lt;br /&gt;      shift&lt;br /&gt;&lt;br /&gt;      # Stage 1&lt;br /&gt;      s6-rc-init -c /etc/s6/rc/compiled /run/service&lt;br /&gt;      &lt;br /&gt;      # Stage 2&lt;br /&gt;      s6-rc -v2 -up change default&lt;br /&gt;      EOF&lt;br /&gt;      &lt;br /&gt;      chmod 755 rc.init&lt;br /&gt;      &lt;br /&gt;      cat &amp;gt; rc.shutdown &amp;lt;&amp;lt;EOF&lt;br /&gt;      #! ${pkgs.stdenv.shell} -e&lt;br /&gt;      &lt;br /&gt;      exec s6-rc -v2 -bDa change&lt;br /&gt;      EOF&lt;br /&gt;&lt;br /&gt;      chmod 755 rc.shutdown&lt;br /&gt;      &lt;br /&gt;      cat &amp;gt; rc.shutdown.final &amp;lt;&amp;lt;EOF&lt;br /&gt;      #! ${pkgs.stdenv.shell} -e&lt;br /&gt;      # Empty&lt;br /&gt;      EOF&lt;br /&gt;      chmod 755 rc.shutdown.final&lt;br /&gt;    '';&lt;br /&gt;  };&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The skeleton directory generated by the above sub expression contains three configuration files:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;&lt;i&gt;rc.init&lt;/i&gt; is the script that the init system starts, right after starting the supervisor: &lt;i&gt;s6-svscan&lt;/i&gt;. It is responsible for initializing the &lt;i&gt;s6-rc&lt;/i&gt; system and starting all services in the &lt;i&gt;default&lt;/i&gt; bundle.&lt;/li&gt;  &lt;li&gt;&lt;i&gt;rc.shutdown&lt;/i&gt; script is executed on shutdown and stops all previously started services by &lt;i&gt;s6-rc&lt;/i&gt;.&lt;/li&gt;  &lt;li&gt;&lt;i&gt;rc.shutdown.final&lt;/i&gt; runs at the very end of the shutdown procedure, after all processes have been killed and all file systems have been unmounted. In the above expression, it does nothing.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;In the initialization process of the image (the &lt;i&gt;runAsRoot&lt;/i&gt; parameter of &lt;i&gt;dockerTools.buildImage&lt;/i&gt;), we need to execute a number of dynamic initialization steps.&lt;br /&gt;&lt;br /&gt;First, we must initialize &lt;i&gt;s6-linux-init&lt;/i&gt; to read its configuration files from &lt;i&gt;/etc/s6/current&lt;/i&gt; using the skeleton directory (that we have configured in the sub expression shown earlier) as its initial contents (the &lt;i&gt;-f&lt;/i&gt; parameter) and run the init system in container mode (the &lt;i&gt;-C&lt;/i&gt; parameter):&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;mkdir -p /etc/s6&lt;br /&gt;s6-linux-init-maker -c /etc/s6/current -p /bin -m 0022 -f ${skelDir} -N -C -B /etc/s6/current&lt;br /&gt;mv /etc/s6/current/bin/* /bin&lt;br /&gt;rmdir etc/s6/current/bin&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;i&gt;s6-linux-init-maker&lt;/i&gt; generates an &lt;i&gt;/bin/init&lt;/i&gt; script, that we can use as the container's entry point.&lt;br /&gt;&lt;br /&gt;I want the logging services to run as an unprivileged user (&lt;i&gt;s6-log&lt;/i&gt;) requiring me to create the user and corresponding group first:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;groupadd -g 2 s6-log&lt;br /&gt;useradd -u 2 -d /dev/null -g s6-log s6-log&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;We must also compile a database from the &lt;i&gt;s6-rc&lt;/i&gt; configuration files, by running the following command-line instructions:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;mkdir -p /etc/s6/rc&lt;br /&gt;s6-rc-compile /etc/s6/rc/compiled ${profile}/etc/s6/sv&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;As can be seen in the &lt;i&gt;rc.init&lt;/i&gt; script that we have generated earlier, the compiled database: &lt;i&gt;/etc/s6/rc/compiled&lt;/i&gt; is propagated to &lt;i&gt;s6-rc-init&lt;/i&gt; as a command-line parameter.&lt;br /&gt;&lt;br /&gt;With the following Nix expression, we can build an &lt;i&gt;s6-rc&lt;/i&gt; managed multi-process Docker image that deploys all the process instances in the processes model that we have written earlier:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;let&lt;br /&gt;  pkgs = import &amp;lt;nixpkgs&amp;gt; {};&lt;br /&gt;&lt;br /&gt;  createMultiProcessImage = import ../../nixproc/create-multi-process-image/create-multi-process-image-universal.nix {&lt;br /&gt;    inherit pkgs system;&lt;br /&gt;    inherit (pkgs) dockerTools stdenv;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;createMultiProcessImage {&lt;br /&gt;  name = &quot;multiprocess&quot;;&lt;br /&gt;  tag = &quot;test&quot;;&lt;br /&gt;  exprFile = ./processes.nix;&lt;br /&gt;  stateDir = &quot;/var&quot;;&lt;br /&gt;  processManager = &quot;s6-rc&quot;;&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With the following command, we can build the image:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-build&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and load the image into Docker with the following command:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker load -i result&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;Discussion&lt;/h2&gt;&lt;br /&gt;With the addition of the &lt;i&gt;s6-rc&lt;/i&gt; backend in the Nix process management framework, we have a modern alternative to systemd at our disposal.&lt;br /&gt;&lt;br /&gt;We can easily let services be managed by &lt;i&gt;s6-rc&lt;/i&gt; using the same agnostic high-level deployment configurations that can also be used to target other process management backends, including systemd.&lt;br /&gt;&lt;br /&gt;What I particularly like about the &lt;i&gt;s6&lt;/i&gt; tool ecosystem (and this also applies in some extent to its ancestor: &lt;i&gt;daemontools&lt;/i&gt; and cousin project: &lt;i&gt;runit&lt;/i&gt;) is the idea to construct the entire system's initialization process and its sub concerns (process supervision, logging and service management) from separate tools, each having clear/fixed scopes.&lt;br /&gt;&lt;br /&gt;This kind of design reminds me of &lt;a href=&quot;https://en.wikipedia.org/wiki/Microkernel&quot;&gt;microkernels&lt;/a&gt; -- in a microkernel design, the kernel is basically split into multiple collaborating processes each having their own responsibilities (e.g. file systems, drivers).&lt;br /&gt;&lt;br /&gt;The microkernel is the only process that has full access to the system and typically only has very few responsibilities (e.g. memory management, task scheduling, interrupt handling).&lt;br /&gt;&lt;br /&gt;When a process crashes, such as a driver, this failure should not tear the entire system down. Systems can even recover from problems, by restarting crashed processes.&lt;br /&gt;&lt;br /&gt;Furthermore, these non-kernel processes typically have very few privileges. If a process' security gets compromised (such as a leaky driver), the system as a whole will not be affected.&lt;br /&gt;&lt;br /&gt;Aside from a number of functional differences compared to systemd, there are also some non-functional differences as well.&lt;br /&gt;&lt;br /&gt;systemd can only be used on Linux using glibc as the system's libc, &lt;i&gt;s6&lt;/i&gt; can also be used on different operating systems (e.g. the BSDs) with different libc implementations, such as &lt;a href=&quot;https://musl.libc.org/&quot;&gt;musl&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Moreover, the supervisor service (&lt;i&gt;s6-svscan&lt;/i&gt;) &lt;a href=&quot;https://skarnet.org/software/s6/s6-svscan-not-1.html&quot;&gt;can also be used as a user-level supervisor that does not need to run as PID 1&lt;/a&gt;. Although systemd supports user sessions (allowing service deployments from unprivileged users), it still has the requirement to have systemd as an init system that needs to run as the system's PID 1.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Improvement suggestions&lt;/h2&gt;&lt;br /&gt;Although the &lt;i&gt;s6&lt;/i&gt; ecosystem provides useful tools and has all kinds of powerful features, I also have a number of improvement suggestions. They are mostly usability related:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;I have noticed that the command-line tools have very &lt;strong&gt;brief help pages&lt;/strong&gt; -- they only enumerate the available options, but they do not provide any additional information explaining what these options do.&lt;br /&gt;    &lt;br /&gt;    I have also noticed that there are no official manpages, but there is a &lt;a href=&quot;https://github.com/flexibeast/s6-man-pages&quot;&gt;third-party initiative&lt;/a&gt; that seems to provide them.&lt;br /&gt;    &lt;br /&gt;    The &quot;official&quot; source of reference are the HTML pages. For me personally, it is not always convenient to access HTML pages on limited machines with no Internet connection and/or only terminal access.&lt;/li&gt;  &lt;li&gt;Although each individual tool is well documented (albeit in HTML), I was having quite a few difficulties figuring out &lt;strong&gt;how to use them together&lt;/strong&gt; -- because every tool has a very specific purpose, you typically need to combine them in interesting ways to do something meaningful.&lt;br /&gt;    &lt;br /&gt;    For example, I could not find any clear documentation on skarnet describing typical combined usage scenarios, such as how to use &lt;i&gt;s6-rc&lt;/i&gt; on a conventional Linux distribution that already has a different service management solution.&lt;br /&gt;    &lt;br /&gt;    Fortunately, I discovered a Linux distribution that turned out to be immensely helpful: &lt;a href=&quot;https://artixlinux.org&quot;&gt;Artix Linux&lt;/a&gt;. Artix Linux provides &lt;i&gt;s6&lt;/i&gt; as one of its supported process management solutions. I ended up installing Artix Linux in a virtual machine and reading &lt;a href=&quot;https://wiki.artixlinux.org/Main/S6&quot;&gt;their documentation&lt;/a&gt;.&lt;br /&gt;  &lt;br /&gt;  This kind of unclarity seems to be somewhat analogous to common criticisms of microkernels: &lt;a href=&quot;https://yarchive.net/comp/microkernels.html&quot;&gt;one of Linus Torvalds' criticisms&lt;/a&gt; is that in microkernel designs, the pieces are simplified, but the coordination of the entire system is more difficult.&lt;/li&gt;  &lt;li&gt;&lt;strong&gt;Updating&lt;/strong&gt; existing service configurations is &lt;strong&gt;difficult&lt;/strong&gt; and &lt;strong&gt;cumbersome&lt;/strong&gt;. Each time I want to change something (e.g. adding a new service), then I need to compile a new database, make sure that the newly compiled database co-exists with the previous database, and then run &lt;i&gt;s6-rc-update&lt;/i&gt;.&lt;br /&gt;    &lt;br /&gt;    It is very easy to make mistakes. For example, I ended up overwriting the previous database several times. When this happens, the upgrade process gets stuck.&lt;br /&gt;  &lt;br /&gt;  systemd, on the other hand, allows you to put a new service configuration file in the configuration directory, such as: &lt;i&gt;/etc/systemd/system&lt;/i&gt;. We can conveniently reload the configuration with a single command-line instruction:&lt;br /&gt;    &lt;br /&gt;    &lt;pre&gt;&lt;br /&gt;$ systemctl daemon-reload&lt;br /&gt;    &lt;/pre&gt;    I believe that the updating process can still be somewhat simplified in &lt;i&gt;s6-rc&lt;/i&gt;. Fortunately, I have managed to hide that complexity in the &lt;i&gt;nixproc-s6-rc-deploy&lt;/i&gt; tool.&lt;/li&gt;  &lt;li&gt;It was also difficult to find out all the available configuration properties for &lt;i&gt;s6-rc&lt;/i&gt; services -- I ended up looking at the &lt;a href=&quot;https://github.com/skarnet/s6-rc/tree/master/examples&quot;&gt;examples&lt;/a&gt; and studying the documentation pages for &lt;a href=&quot;https://skarnet.org/software/s6-rc/s6-rc-compile.html&quot;&gt;&lt;i&gt;s6-rc-compile&lt;/i&gt;&lt;/a&gt;, &lt;a href=&quot;https://skarnet.org/software/s6/s6-supervise.html&quot;&gt;&lt;i&gt;s6-supervise&lt;/i&gt;&lt;/a&gt; and &lt;a href=&quot;https://skarnet.org/software/s6/servicedir.html&quot;&gt;service directories&lt;/a&gt;.&lt;br /&gt;    &lt;br /&gt;    I think that it could be very helpful to write a dedicated documentation page that describes all configurable properties of &lt;i&gt;s6-rc&lt;/i&gt; services.&lt;/li&gt;  &lt;li&gt;I believe it is also very common that for each &lt;i&gt;longrun&lt;/i&gt; service (with a &lt;i&gt;-srv&lt;/i&gt; suffix), that you want a companion logging service (with a &lt;i&gt;-log&lt;/i&gt; suffix).&lt;br /&gt;    &lt;br /&gt;    As a matter of fact, I can hardly think of a situation in which you do not want this. Maybe it helps to introduce a convenience property to automatically facilitate the generation of log companion services.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Availability&lt;/h2&gt;&lt;br /&gt;The &lt;i&gt;s6-rc&lt;/i&gt; backend described in this blog post is part of the current development version of the Nix process management framework, that is still under heavy development.&lt;br /&gt;&lt;br /&gt;The framework can be obtained from &lt;a href=&quot;https://github.com/svanderburg/nix-processmgmt&quot;&gt;my GitHub page&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;</description>
	<pubDate>Mon, 01 Feb 2021 21:29:00 +0000</pubDate>
	<author>noreply@blogger.com (Sander van der Burg)</author>
</item>
<item>
	<title>Mayflower: Safe service upgrades using system.stateVersion</title>
	<guid isPermaLink="true">https://nixos.mayflower.consulting/blog/2021/01/28/nextcloud-stateversion/</guid>
	<link>https://nixos.mayflower.consulting/blog/2021/01/28/nextcloud-stateversion/</link>
	<description>One of the most important features for system administrators who operate NixOS systems are atomic upgrades which means that a deployment won’t reach an inconsistent state: if building a new system’s configuration succeeds, it will be activated in a single step by replacing the /run/current-system-symlink. If a build fails, e.g. due to broken packages, the configuration won’t be activated.
This also means that downgrades are fairly simple since a previous configuration can be reactivated in a so-called rollback by changing the symlink to /run/current-system back to the previous store-path.</description>
	<pubDate>Thu, 28 Jan 2021 10:23:42 +0000</pubDate>
</item>
<item>
	<title>Tweag I/O: Programming with contracts in Nickel</title>
	<guid isPermaLink="true">https://tweag.io/blog/2021-01-22-nickel-contracts/</guid>
	<link>https://tweag.io/blog/2021-01-22-nickel-contracts/</link>
	<description>&lt;p&gt;In a &lt;a href=&quot;https://www.tweag.io/blog/2020-10-22-nickel-open-sourcing/&quot;&gt;previous post&lt;/a&gt;, I gave a taste of &lt;a href=&quot;https://github.com/tweag/nickel/&quot;&gt;Nickel&lt;/a&gt;, a configuration
language we are developing at Tweag. One cool feature of Nickel is the ability
to validate data and enforce program invariants using so-called contracts. In
this post, I introduce the general concept of programming with contracts and
illustrate it in Nickel.&lt;/p&gt;
&lt;h2&gt;Contracts are everywhere&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You go to your favorite bakery and buy a croissant. Is there a contract binding you to the baker?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A long time ago, I was puzzled by this very first question of a law class exam.
It looked really simple, yet I had absolutely no clue.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Ehm..No?”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A contract should write down terms and conditions, and be signed by both
parties. How could buying a croissant involve such a daunting liability?&lt;/p&gt;
&lt;p&gt;Well, I have to confess that this exam didn’t go very well.&lt;/p&gt;
&lt;p&gt;It turns out the sheer act of selling something implicitly and automatically
establishes a legally binding contract between both parties (at least in
&lt;a href=&quot;https://fr.wikipedia.org/wiki/Contrat_de_vente_en_France#Formation_du_contrat&quot;&gt;France&lt;/a&gt;). For once, the programming world is not that different
from the physical world: if I see a &lt;code class=&quot;language-text&quot;&gt;ConcurrentHashmap&lt;/code&gt; class in a Java library,
given the context of Java’s naming conventions, I rightfully expect it to be a
thread-safe implementation of a hashmap. This is a form of contract. If a
programmer uses &lt;code class=&quot;language-text&quot;&gt;ConcurrentHashmap&lt;/code&gt; to name a class that implements a non-thread
safe linked list, they should probably be sent to court.&lt;/p&gt;
&lt;p&gt;Contracts may take multiple forms. A contract can be &lt;em&gt;explicit&lt;/em&gt;, such as in a
formal specification, or &lt;em&gt;implicit&lt;/em&gt;, as in the &lt;code class=&quot;language-text&quot;&gt;ConcurrentHashMap&lt;/code&gt; example. They
can be &lt;em&gt;enforced&lt;/em&gt; or not, such as a type signature in a statically typed
language versus an invariant written as a comment in a dynamically typed
language. Here are a few examples:&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Contract&lt;/th&gt;
&lt;th&gt;Explicitness&lt;/th&gt;
&lt;th&gt;Enforced&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Static types&lt;/td&gt;
&lt;td&gt;Implicit if inferred, explicit otherwise&lt;/td&gt;
&lt;td&gt;Yes, at compile time&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dynamic types&lt;/td&gt;
&lt;td&gt;Implicit&lt;/td&gt;
&lt;td&gt;Yes, at run-time&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Documentation&lt;/td&gt;
&lt;td&gt;Explicit&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Naming&lt;/td&gt;
&lt;td&gt;Implicit&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code class=&quot;language-text&quot;&gt;assert()&lt;/code&gt; primitive&lt;/td&gt;
&lt;td&gt;Explicit&lt;/td&gt;
&lt;td&gt;Yes, at run-time&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pre/post conditions&lt;/td&gt;
&lt;td&gt;Explicit&lt;/td&gt;
&lt;td&gt;Yes, at run-time or compile time&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;p&gt;As often, explicit is better than implicit: it leaves no room for
misunderstanding. Enforced is better than not, because I would rather be
protected by a proper legal system in case of contract violation.&lt;/p&gt;
&lt;h2&gt;Programming with Contracts&lt;/h2&gt;
&lt;p&gt;Until now, I’ve been using the word contract in a wide sense. It turns out
contracts also refer to a particular programming paradigm which embodies the
general notion pretty well. Such contracts are &lt;em&gt;explicit&lt;/em&gt; and &lt;em&gt;enforced&lt;/em&gt;,
following our terminology. They are most notably used in
&lt;a href=&quot;https://docs.racket-lang.org/reference/contracts.html&quot;&gt;Racket&lt;/a&gt;. From now on, I shall use contract in this more
specific sense.&lt;/p&gt;
&lt;p&gt;To first approximation, contracts are assertions. They check that a value
satisfies some property at run-time. If the test passes, the execution can go on
normally. Otherwise, an error is raised.&lt;/p&gt;
&lt;p&gt;In Nickel, one can enforce a contract using the &lt;code class=&quot;language-text&quot;&gt;|&lt;/code&gt; operator:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let x = (1 + 1 | Num) in 2*x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, &lt;code class=&quot;language-text&quot;&gt;x&lt;/code&gt; is bound to a &lt;code class=&quot;language-text&quot;&gt;Num&lt;/code&gt; contract. When evaluating &lt;code class=&quot;language-text&quot;&gt;x&lt;/code&gt;, the following steps
are performed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;evaluate &lt;code class=&quot;language-text&quot;&gt;1 + 1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;check that the result is a number&lt;/li&gt;
&lt;li&gt;if it is, return the expression unchanged. Otherwise, raise an error that
halts the program.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s see it in action:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;$nickel &amp;lt;&amp;lt;&amp;lt; '1 + 1 | Num'
Done: Num(2.0)

$nickel &amp;lt;&amp;lt;&amp;lt; 'false | Num'
error: Blame error: contract broken by a value.
  ┌─ :1:1
  │
1 │ Num
  │ --- expected type
  │
  ┌─ &amp;lt;stdin&amp;gt;:1:9
  │
1 │ false | Num
  │         ^^^ bound here&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Contracts versus types&lt;/h2&gt;
&lt;p&gt;I’ve described contracts as assertions, but the above snippet suspiciously
resembles a type annotation. How do contracts compare to types? First of all,
contracts are checked at run-time, so they would correspond to dynamic typing
rather than static typing. Secondly, contracts can check more than just the
membership to a type:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let GreaterThan2 = fun label x =&amp;gt;
  if builtins.isNum x then
    if x &amp;gt; 2 then
      x
    else
      contracts.blame (contracts.tag &quot;smaller or equals&quot; label)
  else
    contracts.blame (contracts.tag &quot;not a number&quot; label)
in

(3 | #GreaterThan2) // Ok, evaluate to 3
(1 | #GreaterThan2) // Err, `smaller or equals`
(&quot;a&quot; | #GreaterThan2) // Err, `not a number`&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, we just built a &lt;em&gt;custom contract&lt;/em&gt;. A custom contract is a function of two
arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the label &lt;code class=&quot;language-text&quot;&gt;label&lt;/code&gt;, carrying information for error reporting.&lt;/li&gt;
&lt;li&gt;the value &lt;code class=&quot;language-text&quot;&gt;x&lt;/code&gt; to be tested.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the value satisfies the condition, it is returned. Otherwise, a call to
&lt;code class=&quot;language-text&quot;&gt;blame&lt;/code&gt; signals rejection with an optional error message attached via &lt;code class=&quot;language-text&quot;&gt;tag&lt;/code&gt;.
When evaluating &lt;code class=&quot;language-text&quot;&gt;value | #Contract&lt;/code&gt;, the interpreter calls &lt;code class=&quot;language-text&quot;&gt;Contract&lt;/code&gt; with an
appropriate label and &lt;code class=&quot;language-text&quot;&gt;value&lt;/code&gt; as arguments.&lt;/p&gt;
&lt;p&gt;Such custom contracts can check arbitrary properties. Enforcing the property of
being greater than two using static types is rather hard, requiring a fancy type
system such as &lt;a href=&quot;https://ucsd-progsys.github.io/liquidhaskell-blog/&quot;&gt;refinement types&lt;/a&gt; , while the role of dynamic
types generally stops at distinguishing basic datatypes and functions.&lt;/p&gt;
&lt;p&gt;Back to our first example &lt;code class=&quot;language-text&quot;&gt;1 + 1 | Num&lt;/code&gt;, we could have written instead:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let MyNum = fun label x =&amp;gt;
  if builtins.isNum x then x else contracts.blame label in
(1 + 1 | #MyNum)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is in fact pretty much what &lt;code class=&quot;language-text&quot;&gt;1 + 1 | Num&lt;/code&gt; evaluates to. While a contract is
not the same entity as a type, one can derive a contract from any type. Writing
&lt;code class=&quot;language-text&quot;&gt;1 + 1 | Num&lt;/code&gt; asks the interpreter to derive a contract from the type &lt;code class=&quot;language-text&quot;&gt;Num&lt;/code&gt; and
to check &lt;code class=&quot;language-text&quot;&gt;1 + 1&lt;/code&gt; against it. This is just a convenient syntax to specify common
contracts. The&lt;code class=&quot;language-text&quot;&gt;#&lt;/code&gt; character distinguishes &lt;em&gt;contracts as types&lt;/em&gt; from &lt;em&gt;contracts
as functions&lt;/em&gt; (that is, custom contracts).&lt;/p&gt;
&lt;p&gt;To sum up, contracts are just glorified assertions. Also, there is this
incredibly convenient syntax that spares us a whole three characters by writing &lt;code class=&quot;language-text&quot;&gt;Num&lt;/code&gt;
instead of &lt;code class=&quot;language-text&quot;&gt;#MyNum&lt;/code&gt;. So… is that all the fuss is about?&lt;/p&gt;
&lt;h2&gt;Function contracts&lt;/h2&gt;
&lt;p&gt;Until now, we have only considered what are called &lt;em&gt;flat&lt;/em&gt; contracts, which
operate on data. But Nickel is a functional programming language: so what about
function contracts? They exist too!&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let f | Str -&amp;gt; Num = fun x =&amp;gt; if x == &quot;a&quot; then 0 else 1 in ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here again, we ask Nickel to derive a contract for us, from the type &lt;code class=&quot;language-text&quot;&gt;Str -&amp;gt; Num&lt;/code&gt;
of functions sending strings to numbers. To find out how this contract could
work, we must understand what is the defining property of a function of type
&lt;code class=&quot;language-text&quot;&gt;Str -&amp;gt; Num&lt;/code&gt; that the contract should enforce.&lt;/p&gt;
&lt;p&gt;A function of type &lt;code class=&quot;language-text&quot;&gt;Str -&amp;gt; Num&lt;/code&gt; has a &lt;em&gt;duty&lt;/em&gt;: it must produce a number. But what
if I call &lt;code class=&quot;language-text&quot;&gt;f&lt;/code&gt; on a boolean? That’s unfair, because the function has also a
&lt;em&gt;right&lt;/em&gt;: the argument must be a string. The full contract is thus: if you give
me a string, I give you a number. If you give me something else, you broke the
contract, so I can’t guarantee anything. Another way of viewing it is that the
left side of the arrow represents &lt;strong&gt;preconditions&lt;/strong&gt; on the input while the right
side represents &lt;strong&gt;postconditions&lt;/strong&gt; on the output.&lt;/p&gt;
&lt;p&gt;More than flat contracts, function contracts show similarities with traditional
legal contracts. We have two parties: the &lt;strong&gt;caller&lt;/strong&gt;, &lt;code class=&quot;language-text&quot;&gt;f &quot;b&quot;&lt;/code&gt;, and the
&lt;strong&gt;callee&lt;/strong&gt;, &lt;code class=&quot;language-text&quot;&gt;f&lt;/code&gt;. Both must meet conditions: the caller must provide a string
while the callee must return a number.&lt;/p&gt;
&lt;p&gt;In practice, inspecting the term &lt;code class=&quot;language-text&quot;&gt;f&lt;/code&gt; can tell us if it is a function at most.
This is because a function is inert, waiting for an argument to hand back a
result. In consequence, the contract is doomed to fire only when &lt;code class=&quot;language-text&quot;&gt;f&lt;/code&gt; is applied
to an argument, in which case it checks that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The argument satisfies the &lt;code class=&quot;language-text&quot;&gt;Str&lt;/code&gt; contract&lt;/li&gt;
&lt;li&gt;The return value satisfies the &lt;code class=&quot;language-text&quot;&gt;Num&lt;/code&gt; contract&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The interpreter performs additional bookkeeping to be able to correctly blame
the offending code in case of a higher-order contract violation:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;$nickel &amp;lt;&amp;lt;&amp;lt; 'let f | Str -&amp;gt; Num = fun x =&amp;gt; if x == &quot;a&quot; then 0 else 1 in f &quot;a&quot;'
Done: Num(0.0)

$nickel &amp;lt;&amp;lt;&amp;lt; '... in f 0'
error: Blame error: contract broken by the caller.
  ┌─ :1:1
  │
1 │ Str -&amp;gt; Num
  │ --- expected type of the argument provided by the caller
  │
  ┌─ &amp;lt;stdin&amp;gt;:1:9
  │
1 │ let f | Str -&amp;gt; Num = fun x =&amp;gt; if x == &quot;a&quot; then 0 else 1 in f 0
  │         ^^^^^^^^^^ bound here
[..]

$nickel &amp;lt;&amp;lt;&amp;lt; 'let f | Str -&amp;gt; Num = fun x =&amp;gt; x in f &quot;a&quot;'
error: Blame error: contract broken by a function.
  ┌─ :1:8
  │
1 │ Str -&amp;gt; Num
  │        --- expected return type
  │
  ┌─ &amp;lt;stdin&amp;gt;:1:9
  │
1 │ let f | Str -&amp;gt; Num = fun x =&amp;gt; x in f &quot;a&quot;
  │         ^^^^^^^^^^ bound here&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These examples illustrate three possible situations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The contract is honored by both parties.&lt;/li&gt;
&lt;li&gt;The contract is broken by the caller, which provides a number instead of a
string.&lt;/li&gt;
&lt;li&gt;The contract is broken by the function (callee), which rightfully got a
string but returned a string instead of a number.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Combined with custom contracts, function contracts make it possible to express
succinctly non-trivial invariants:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let f | #GreaterThan2 -&amp;gt; #GreaterThan2 = fun x =&amp;gt; x + 1 in ..&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;A warning about laziness&lt;/h2&gt;
&lt;p&gt;Nickel is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Lazy_evaluation&quot;&gt;lazy programming language&lt;/a&gt;. This means that expressions,
including contracts, are evaluated only if they are needed. If you are
experimenting with contracts and some checks buried inside lists or records do
not seem to trigger, you can use the &lt;code class=&quot;language-text&quot;&gt;deepSeq&lt;/code&gt; operator to recursively force the
evaluation of all subterms, including contracts:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;let exp = ..YOUR CODE WITH CONTRACTS.. in builtins.deepSeq exp exp&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In this post, I introduced programming with contracts. Contracts offer a
principled and ergonomic way of validating data and enforcing invariants with a
good error reporting story. Contracts can express arbitrary properties that are
hard to enforce statically, and they can handle higher-order functions.&lt;/p&gt;
&lt;p&gt;Contracts also have a special relationship with static typing. While we compared
them as competitors somehow, contracts and static types are actually
complementary, reunited in the setting of &lt;a href=&quot;https://wphomes.soic.indiana.edu/jsiek/what-is-gradual-typing/&quot;&gt;gradual typing&lt;/a&gt;.
Nickel has gradual types, which will be the subject of a coming post.&lt;/p&gt;
&lt;p&gt;The examples here are illustrative, but we’ll see more specific and compelling
usages of contracts in yet another coming post about Nickel’s meta-values,
which, together with contracts, serve as a unified way to describe and validate
configurations.&lt;/p&gt;</description>
	<pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate>
</item>
<item>
	<title>nixbuild.net: Finding Non-determinism with nixbuild.net</title>
	<guid isPermaLink="true">https://blog.nixbuild.net/posts/2021-01-13-finding-non-determinism-with-nixbuild-net.html</guid>
	<link>https://blog.nixbuild.net/posts/2021-01-13-finding-non-determinism-with-nixbuild-net.html</link>
	<description>&lt;p&gt;During the last decade, many initiatives focussing on making builds reproducible have gained momentum. &lt;a href=&quot;https://reproducible-builds.org/&quot;&gt;reproducible-builds.org&lt;/a&gt; is a great resource for anyone interested in how the work progresses in multiple software communities. &lt;a href=&quot;https://r13y.com/&quot;&gt;r13y.com&lt;/a&gt; tracks the current reproducibility metrics in &lt;a href=&quot;https://nixos.org/&quot;&gt;NixOS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Nix is particularly suited for working on reproducibility, since it by design isolates builds and comes with &lt;a href=&quot;https://nixos.org/manual/nix/stable/#chap-diff-hook&quot;&gt;tools&lt;/a&gt; for finding non-determinism. The Nix community also works on related projects, like &lt;a href=&quot;https://www.tweag.io/blog/2020-12-16-trustix-announcement/&quot;&gt;Trustix&lt;/a&gt; and the &lt;a href=&quot;https://www.tweag.io/blog/2020-09-10-nix-cas/&quot;&gt;content-addressed store&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This blog post summarises how &lt;a href=&quot;https://nixbuild.net/&quot;&gt;nixbuild.net&lt;/a&gt; can be useful for finding non-deterministic builds, and announces a new feature related to reproducibility!&lt;/p&gt;

&lt;h2 id=&quot;repeated-builds&quot;&gt;Repeated Builds&lt;/h2&gt;
&lt;p&gt;The way to find non-reproducible builds is to run the same build multiple times and check for any difference in results, when compared bit-for-bit. Since Nix guarantees that all inputs will be identical between the runs, just finding differing output results is enough to conclude that a build is non-deterministic. Of course, we can never &lt;em&gt;prove&lt;/em&gt; that a build is &lt;em&gt;deterministic&lt;/em&gt; this way, but if we run the build many times, we gain a certain confidence in it.&lt;/p&gt;
&lt;p&gt;To run a Nix build multiple times, simply add the &lt;a href=&quot;https://nixos.org/manual/nix/stable/#conf-repeat&quot;&gt;–repeat&lt;/a&gt; option to your build command. It will run your build the number of extra times you specify.&lt;/p&gt;
&lt;p&gt;Suppose we have the following Nix expression in &lt;code&gt;deterministic.nix&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let
  inherit (import &amp;lt;nixpkgs&amp;gt; {}) runCommand;
in {
  stable = runCommand &quot;stable&quot; {} ''
    touch $out
  '';

  unstable = runCommand &quot;unstable&quot; {} ''
    echo $RANDOM &amp;gt; $out
  '';
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can run repeated builds like this (note that the &lt;code&gt;--builders &quot;&quot;&lt;/code&gt; option is there to force a local build, to not use nixbuild.net):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nix-build deterministic.nix --builders &quot;&quot; -A stable --repeat 1
these derivations will be built:
  /nix/store/0fj164aqyhsciy7x97s1baswygxn8lzf-stable.drv
building '/nix/store/0fj164aqyhsciy7x97s1baswygxn8lzf-stable.drv' (round 1/2)...
building '/nix/store/0fj164aqyhsciy7x97s1baswygxn8lzf-stable.drv' (round 2/2)...
/nix/store/6502c5490rap0c8dhvfwm5rhi22i9clz-stable

$ nix-build deterministic.nix --builders &quot;&quot; -A unstable --repeat 1
these derivations will be built:
  /nix/store/psmn1s3bb97989w5a5b1gmjmprqcmf0k-unstable.drv
building '/nix/store/psmn1s3bb97989w5a5b1gmjmprqcmf0k-unstable.drv' (round 1/2)...
building '/nix/store/psmn1s3bb97989w5a5b1gmjmprqcmf0k-unstable.drv' (round 2/2)...
output '/nix/store/g7a5sf7iwdxs7q12ksrzlvjvz69yfq3l-unstable' of '/nix/store/psmn1s3bb97989w5a5b1gmjmprqcmf0k-unstable.drv' differs from previous round
error: build of '/nix/store/psmn1s3bb97989w5a5b1gmjmprqcmf0k-unstable.drv' failed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running repeated builds on nixbuild.net works exactly the same way:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nix-build deterministic.nix -A stable --repeat 1
these derivations will be built:
  /nix/store/wnd5y30jp3xwpw1bhs4bmqsg5q60vc8i-stable.drv
building '/nix/store/wnd5y30jp3xwpw1bhs4bmqsg5q60vc8i-stable.drv' (round 1/2) on 'ssh://eu.nixbuild.net'...
copying 1 paths...
copying path '/nix/store/z3wlpwgz66ningdbggakqpvl0jp8bp36-stable' from 'ssh://eu.nixbuild.net'...
/nix/store/z3wlpwgz66ningdbggakqpvl0jp8bp36-stable

$ nix-build deterministic.nix -A unstable --repeat 1
these derivations will be built:
  /nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv
building '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' (round 1/2) on 'ssh://eu.nixbuild.net'...
[nixbuild.net] output '/nix/store/srch6l8pyl7z93c7gp1xzf6mq6rwqbaq-unstable' of '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' differs from previous round
error: build of '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' on 'ssh://eu.nixbuild.net' failed: build was non-deterministic
builder for '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' failed with exit code 1
error: build of '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' failed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the log output differs slightly between the local and the remote builds. This is because when Nix submits a remote build, it will not do the determinism check itself, instead it will leave it up to the builder (nixbuild.net in our case). This is actually a good thing, because it allows nixbuild.net to perform some optimizations for repeated builds. The following sections will enumerate those optimizations.&lt;/p&gt;
&lt;h2 id=&quot;finding-non-determinism-in-past-builds&quot;&gt;Finding Non-determinism in Past Builds&lt;/h2&gt;
&lt;p&gt;If you locally try to rebuild a something that has failed due to non-determinism, Nix will build it again at least two times (due to &lt;code&gt;--repeat&lt;/code&gt;) and fail it due to non-determinism again, since it keeps no record of the previous build failure (other than the build log).&lt;/p&gt;
&lt;p&gt;However, nixbuild.net keeps a record of every build performed, also for repeated builds. So when you try to build the same derivation again, nixbuild.net is smart enough to look at its past build and figure out that the derivation is non-deterministic without having to rebuild it. We can demonstrate this by re-running the last build from the example above:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nix-build deterministic.nix -A unstable --repeat 1
these derivations will be built:
  /nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv
building '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' (round 1/2) on 'ssh://eu.nixbuild.net'...
[nixbuild.net] output '/nix/store/srch6l8pyl7z93c7gp1xzf6mq6rwqbaq-unstable' of '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' differs from previous round
error: build of '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' on 'ssh://eu.nixbuild.net' failed: a previous build of the derivation was non-deterministic
builder for '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' failed with exit code 1
error: build of '/nix/store/6im1drv4pklqn8ziywbn44vq8am977vm-unstable.drv' failed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the exact same derivation fails again, but now the build status message says: &lt;code&gt;a previous build of the derivation was non-deterministic&lt;/code&gt;. This means nixbuild.net didn’t have to run the build, it just checked its past outputs for the derivation and noticed they differed.&lt;/p&gt;
&lt;p&gt;When nixbuild.net looks at past builds it considers all outputs that have been signed by a key that the account trusts. That means that it can even compare outputs that have been fetched by substitution.&lt;/p&gt;
&lt;h2 id=&quot;scaling-out-repeated-builds&quot;&gt;Scaling Out Repeated Builds&lt;/h2&gt;
&lt;p&gt;When you use &lt;code&gt;--repeat&lt;/code&gt;, nixbuild.net will create multiple copies of the build and schedule all of them like any other build would have been scheduled. This means that every repeated build will run in parallel, saving time for the user. As soon as nixbuild.net has found proof of non-determinism, any repeated build still running will be cancelled.&lt;/p&gt;
&lt;h2 id=&quot;provoking-non-determinism-through-filesystem-randomness&quot;&gt;Provoking Non-determinism through Filesystem Randomness&lt;/h2&gt;
&lt;p&gt;As promised in the beginning of this blog post, we have new a feature to announce! nixbuild.net is now able to inject randomness into the filesystem that the builds see when they run. This can be used to provoke builds to uncover non-deterministic behavior.&lt;/p&gt;
&lt;p&gt;The idea is not new, it is in fact the exact same concept as have been implemented in the &lt;a href=&quot;https://salsa.debian.org/reproducible-builds/disorderfs&quot;&gt;disorderfs&lt;/a&gt; project by &lt;a href=&quot;https://reproducible-builds.org/&quot;&gt;reproducible-builds.org&lt;/a&gt;. However, we’re happy to make it easily accessible to nixbuild.net users. The feature is disabled by default, but can be enabled through a new &lt;a href=&quot;https://docs.nixbuild.net/settings/#inject-fs-randomness&quot;&gt;user setting&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the moment, the implementation will return directory entries in a random order when enabled. In the future we might inject more metadata randomness.&lt;/p&gt;
&lt;p&gt;To demonstrate this feature, let’s use this build:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let
  inherit (import &amp;lt;nixpkgs&amp;gt; {}) runCommand;
in rec {
  files = runCommand &quot;files&quot; {} ''
    mkdir $out
    touch $out/{1..10}
  '';

  list = runCommand &quot;list&quot; {} ''
    ls -f ${files} &amp;gt; $out
  '';
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;files&lt;/code&gt; build just creates ten empty files as its output, and the &lt;code&gt;list&lt;/code&gt; build lists those file with &lt;code&gt;ls&lt;/code&gt;. The &lt;code&gt;-f&lt;/code&gt; option of &lt;code&gt;ls&lt;/code&gt; disables sorting entirely, so the file names will be printed in the order the filesystem returns them. This means that the build output will depend on how the underlying filesystem is implemented, which could be considered a non-deterministic behavior.&lt;/p&gt;
&lt;p&gt;First, we build it locally with &lt;code&gt;--repeat&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nix-build non-deterministic-fs.nix --builders &quot;&quot; -A list --repeat 1
these derivations will be built:
  /nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv
building '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' (round 1/2)...
building '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' (round 2/2)...
/nix/store/h1591y02qff8vls5v41khgjz2zpdr2mg-list&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the build succeeded. Then we delete the result from our Nix store so we can run the build again:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rm result
nix-store --delete /nix/store/h1591y02qff8vls5v41khgjz2zpdr2mg-list&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We enable the &lt;code&gt;inject-fs-randomness&lt;/code&gt; feature through the &lt;a href=&quot;https://docs.nixbuild.net/nixbuild-shell/&quot;&gt;nixbuild.net shell&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nixbuild.net&amp;gt; set inject-fs-randomness true&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we run the build (with &lt;code&gt;--repeat&lt;/code&gt;) on nixbuild.net:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nix-build non-deterministic-fs.nix -A list --repeat 1
these derivations will be built:
  /nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv
building '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' (round 1/2) on 'ssh://eu.nixbuild.net'...
copying 1 paths...
copying path '/nix/store/vl13q40hqp4q8x6xjvx0by06s1v9g3jy-files' to 'ssh://eu.nixbuild.net'...
[nixbuild.net] output '/nix/store/h1591y02qff8vls5v41khgjz2zpdr2mg-list' of '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' differs from previous round
error: build of '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' on 'ssh://eu.nixbuild.net' failed: build was non-deterministic
builder for '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' failed with exit code 1
error: build of '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' failed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, nixbuild.net found the non-determinism! We can double check that the directory entries are in a random order by running without &lt;code&gt;--repeat&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ nix-build non-deterministic-fs.nix -A list
these derivations will be built:
  /nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv
building '/nix/store/153s3ir379cy27wpndd94qlfhz0wj71v-list.drv' on 'ssh://eu.nixbuild.net'...
copying 1 paths...
copying path '/nix/store/h1591y02qff8vls5v41khgjz2zpdr2mg-list' from 'ssh://eu.nixbuild.net'...
/nix/store/h1591y02qff8vls5v41khgjz2zpdr2mg-list

$ cat /nix/store/h1591y02qff8vls5v41khgjz2zpdr2mg-list
6
1
2
5
10
7
8
..
9
4
3
.&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;future-work&quot;&gt;Future Work&lt;/h2&gt;
&lt;p&gt;There are lots of possibilities to improve the utility of nixbuild.net when it comes to reproducible builds. Your feedback and ideas are very welcome to &lt;a href=&quot;mailto:support@nixbuild.net&quot;&gt;support@nixbuild.net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are some of the things that could be done:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Make it possible to trigger repeated builds for any previous build, without submitting a new build with Nix. For example, there could be a command in the nixbuild.net shell allowing a user to trigger a repeated build and report back any non-determinism issues.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Implement functionality similar to &lt;a href=&quot;https://diffoscope.org/&quot;&gt;diffoscope&lt;/a&gt; to be able to find out exactly what differs between builds. This could be available as a shell command or through an API.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make it possible to download specific build outputs. The way Nix downloads outputs (and stores them locally) doesn’t allow for having multiple variants of the same output, but nixbuild.net could provide this functionality through the shell or an API.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inject more randomness inside the sandbox. Since we have complete control over the sandbox environment we can introduce more differences between repeated builds to provoke non-determinism. For example, we can schedule builds on different hardware or use different kernels between repeated builds.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add support for listing known non-deterministic derivations.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
	<pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate>
	<author>support@nixbuild.net (nixbuild.net)</author>
</item>
<item>
	<title>nixbuild.net: The First Year</title>
	<guid isPermaLink="true">https://blog.nixbuild.net/posts/2020-12-29-the-first-year.html</guid>
	<link>https://blog.nixbuild.net/posts/2020-12-29-the-first-year.html</link>
	<description>&lt;p&gt;&lt;a href=&quot;https://discourse.nixos.org/t/announcing-nixbuild-net-nix-build-as-a-service&quot;&gt;One year ago&lt;/a&gt; nixbuild.net was announced to the Nix community for the very first time. The service then ran as a closed beta for 7 months until it was made &lt;a href=&quot;https://blog.nixbuild.net/posts/2020-08-28-nixbuild-net-is-generally-available.html&quot;&gt;generally available&lt;/a&gt; on the 28th of August 2020.&lt;/p&gt;
&lt;p&gt;This blog post will try to summarize how nixbuild.net has evolved since GA four months ago, and give a glimpse of the future for the service.&lt;/p&gt;

&lt;h2 id=&quot;stability-and-performance&quot;&gt;Stability and Performance&lt;/h2&gt;
&lt;p&gt;Thousands of Nix builds have been built by nixbuild.net so far, and every build helps in making the service more reliable by uncovering possible edge cases in the build environment.&lt;/p&gt;
&lt;p&gt;These are some of the stability-related improvements and fixes that have been deployed since GA:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Better detection and handling of builds that time out or hang.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improved retry logic should our backend storage not deliver Nix closures as expected.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fixes to the virtual file system inside the KVM sandbox.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Better handling of builds that have binary data in their log output.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Changes to the virtual sandbox environment so it looks even more like a “standard” Linux environment.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Application of the &lt;a href=&quot;https://nixos.org/manual/nix/stable/#conf-sandbox&quot;&gt;Nix sandbox&lt;/a&gt; inside our KVM sandbox. This basically guarantees that the Nix environment provided through nixbuild.net is identical to the Nix environment for local builds.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Support for following HTTP redirects from binary caches.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;even-better-build-reuse&quot;&gt;Even Better Build Reuse&lt;/h2&gt;
&lt;p&gt;One of the fundamental ideas in nixbuild.net is to try as hard as possible to &lt;em&gt;not&lt;/em&gt; build your builds, if an existing build result can be reused instead. We can trivially reuse an account’s own builds since they are implicitly trusted by the user, but also untrusted builds can be reused under certain circumstances. This has been described in detail in an &lt;a href=&quot;https://blog.nixbuild.net/posts/2020-08-13-build-reuse-in-nixbuild-net.html&quot;&gt;earlier blog post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Since GA we’ve introduced a number of new ways build results can be reused.&lt;/p&gt;
&lt;h3 id=&quot;reuse-of-build-failures&quot;&gt;Reuse of Build Failures&lt;/h3&gt;
&lt;p&gt;Build failures are now also reused. This means that if someone tries to build a build that is identical (in the sense that the derivation and its transitive input closure is bit-by-bit identical) to a previously failed build, nixbuild.net will immediately serve back the failed result instead of re-running the build. You will even get the build log replayed.&lt;/p&gt;
&lt;p&gt;Build failures can be reused since we are confident that our sandbox is pure, meaning that it will behave exactly the same as long as the build is exactly the same. Only non-transient failures will be reused. So if the builder misbehaves in some way that is out of control for Nix, that failure will not be reused. This can happen if the builder machine breaks down or something similar. In such cases we will automatically re-run the build anyway.&lt;/p&gt;
&lt;p&gt;When we fix bugs or make major changes in our sandbox it can happen that we alter the behavior in terms of which builds succeed or fail. For example, we could find a build that fail just because we have missed implementing some specific detail in the sandbox. Once that is fixed, we don’t want to reuse such failures. To avoid that, all existing build failures will be “invalidated” on each major update of the sandbox.&lt;/p&gt;
&lt;p&gt;If a user really wants to re-run a failed build on nixbuild.net, failure reuse can be turned off using the new &lt;em&gt;user settings&lt;/em&gt; (see below).&lt;/p&gt;
&lt;h3 id=&quot;reuse-of-build-timeouts&quot;&gt;Reuse of Build Timeouts&lt;/h3&gt;
&lt;p&gt;In a similar vein to reused build failures, we can also reuse build timeouts. This is not enabled by default, since users can select different timeout limits. A user can activate reuse of build timeouts through the user settings.&lt;/p&gt;
&lt;p&gt;The reuse of timed out builds works like this: Each time a new build is submitted, we check if we have any previous build results of the exact same build. If no successful results or plain failures are found, we look for builds that have timed out. We then check if any of the existing timed out builds ran for longer than the user-specified timeout for the new build. If we can find such a result, it will be served back to the user instead of re-running the build.&lt;/p&gt;
&lt;p&gt;This feature can be very useful if you want to avoid re-running builds that timeout over and over again (which can be a very time-consuming excercise). For example, say that you have your build timeout set to two hours, and some input needed for a build takes longer than that to build. The first time that input is needed you have to wait two hours to detect that the build will fail. If you then try building something else that happens to depend on the very same input you will save two hours by directly being served the build failure from nixbuild.net!&lt;/p&gt;
&lt;h3 id=&quot;wait-for-running-builds&quot;&gt;Wait for Running Builds&lt;/h3&gt;
&lt;p&gt;When a new build is submitted, nixbuild.net will now check if there is any identical build currently running (after checking for previous build results or failures). If there is, the new build will simply hold until the running build has finished. After that, the result of the running build will likely be served back as the result of the new build (as long as the running build wasn’t terminated in a transient way, in which case the new build will have to run from scratch). The identical running builds are checked and reused across accounts.&lt;/p&gt;
&lt;p&gt;Before this change, nixbuild.net would simply start another build in parallel even if the builds were identical.&lt;/p&gt;
&lt;h2 id=&quot;new-features&quot;&gt;New Features&lt;/h2&gt;
&lt;h3 id=&quot;user-settings&quot;&gt;User Settings&lt;/h3&gt;
&lt;p&gt;A completely new feature has been launched since GA: &lt;strong&gt;&lt;a href=&quot;https://docs.nixbuild.net/settings/&quot;&gt;User Settings&lt;/a&gt;&lt;/strong&gt;. This allows end users to tweak the behavior of nixbuild.net. For example, the build reuse described above can be controlled by user settings. Other settings includes &lt;a href=&quot;https://docs.nixbuild.net/settings/#max-cpu-hours-per-month&quot;&gt;controlling the maximum used build time per month&lt;/a&gt;, and the possibility to &lt;a href=&quot;https://docs.nixbuild.net/settings/#allow-override&quot;&gt;lock down&lt;/a&gt; specific SSH keys which is useful in CI setups.&lt;/p&gt;
&lt;p&gt;The user settings can be set in various way; through the &lt;a href=&quot;https://docs.nixbuild.net/nixbuild-shell/index.html#configure-settings&quot;&gt;nixbuild.net shell&lt;/a&gt;, the &lt;a href=&quot;https://docs.nixbuild.net/settings/#ssh-environment&quot;&gt;SSH client environment&lt;/a&gt; and even through the &lt;a href=&quot;https://docs.nixbuild.net/settings/#nix-derivation&quot;&gt;Nix derivations&lt;/a&gt; themselves.&lt;/p&gt;
&lt;p&gt;Even if many users probably never need to change any settings, it can be helpful to read through the &lt;a href=&quot;https://docs.nixbuild.net/settings/&quot;&gt;documentation&lt;/a&gt; to get a feeling for what is possible. If you need to differentiate permissions in any way (different settings for account administrators, developers, CI etc) you should definitely look into the various user settings.&lt;/p&gt;
&lt;h3 id=&quot;github-ci-action&quot;&gt;GitHub CI Action&lt;/h3&gt;
&lt;p&gt;A &lt;a href=&quot;https://github.com/marketplace/actions/nixbuild-net&quot;&gt;GitHub Action&lt;/a&gt; has been published. This action makes it very easy to use nixbuild.net as a remote Nix builder in your GitHub Actions workflows. Instead of running you Nix builds on the two vCPUs provided by GitHub you can now enjoy scale-out Nix builds on nixbuild.net with minimal setup required.&lt;/p&gt;
&lt;p&gt;The nixbuild.net GitHub Action is developed by the nixbuild.net team and there are plans on adding more functionality that nixbuild.net can offer users, like automatically generated cost and performance reports for your Nix builds.&lt;/p&gt;
&lt;h3 id=&quot;shell-improvements&quot;&gt;Shell Improvements&lt;/h3&gt;
&lt;p&gt;Various minor improvements have been made to the &lt;a href=&quot;https://docs.nixbuild.net/nixbuild-shell/&quot;&gt;nixbuild.net shell&lt;/a&gt;. It is for example now much easier to get an overview on how large your next invoice will be, through the &lt;a href=&quot;https://docs.nixbuild.net/nixbuild-shell/#check-your-account-usage&quot;&gt;usage&lt;/a&gt; command.&lt;/p&gt;
&lt;h2 id=&quot;the-future&quot;&gt;The Future&lt;/h2&gt;
&lt;p&gt;After one year of real world usage, we are very happy with the progress of nixbuild.net. It has been well received in the Nix community, proved both reliable and scalable, and it has delivered on our initial vision of a simple service that can integrate into any setup using Nix.&lt;/p&gt;
&lt;p&gt;We feel that we can go anywhere from here, but we also realize that we must be guided by our users’ needs. We have compiled a small and informal roadmap below. The items on this list are things that we, based on the feedback we’ve received throughout the year, think are natural next steps for nixbuild.net.&lt;/p&gt;
&lt;p&gt;The roadmap has no dates and no prioritization, and should be seen as merely a hint about which direction the development is heading. Any question or comment concerning this list (or what’s missing from the list) is very welcome to &lt;a href=&quot;mailto:support@nixbuild.net&quot;&gt;support@nixbuild.net&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;support-aarch64-linux-builds&quot;&gt;Support aarch64-linux Builds&lt;/h3&gt;
&lt;p&gt;Work is already underway to add support for &lt;code&gt;aarch64-linux&lt;/code&gt; builds to nixbuild.net, and so far it is looking good. With the current surge in performant ARM hardware (Apple M1, Ampere Altra etc), we think having &lt;code&gt;aarch64&lt;/code&gt; support in nixbuild.net is an obvious feature. It is also something that has been requested by our users.&lt;/p&gt;
&lt;p&gt;We don’t know yet how the pricing of &lt;code&gt;aarch64&lt;/code&gt; builds will look, or what scalability promises we can make. If you are interested in evaluating &lt;code&gt;aarch64&lt;/code&gt; builds on nixbuild.net in an early access setting, just send us an email to &lt;a href=&quot;mailto:support@nixbuild.net&quot;&gt;support@nixbuild.net&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;provide-an-api-over-ssh-and-http&quot;&gt;Provide an API over SSH and HTTP&lt;/h3&gt;
&lt;p&gt;Currently the &lt;a href=&quot;https://docs.nixbuild.net/nixbuild-shell/&quot;&gt;nixbuild.net shell&lt;/a&gt; is the administrative tool we offer end users. We will keep developing the shell and make it more intuitive for interactive use. But will also add an alternative, more scriptable variant of the shell.&lt;/p&gt;
&lt;p&gt;This alternative version will provide roughly the same functionality as the original shell, only more adapted to scripting instead of interactive use. The reason for providing such an SSH-based API is to make it easy to integrate nixbuild.net more tightly into CI and similar scenarios.&lt;/p&gt;
&lt;p&gt;There is in fact already a tiny version of this API deployed. You can run the following command to try it out:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh eu.nixbuild.net api show public-signing-key
{&quot;keyName&quot;:&quot;nixbuild.net/bob-1&quot;,&quot;publicKey&quot;:&quot;PmUhzAc4Ug6sf1uG8aobbqMdalxW41SHWH7FE0ie1BY=&quot;}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above API command is in use by the &lt;a href=&quot;https://github.com/nixbuild/nixbuild-action&quot;&gt;nixbuild-action&lt;/a&gt; for GitHub. So far, this is the only API command implemented, and it should be seen as a very first proof of concept. Nothing has been decided on how the API should look and work in the future.&lt;/p&gt;
&lt;p&gt;The API will also be offered over HTTP in addition to SSH.&lt;/p&gt;
&lt;h3 id=&quot;upload-builds-to-binary-caches&quot;&gt;Upload builds to binary caches&lt;/h3&gt;
&lt;p&gt;Adding custom binary caches that nixbuild.net can fetch dependencies from is supported today, although such requests are still handled manually through support.&lt;/p&gt;
&lt;p&gt;We also want to support uploading to custom binary caches. That way users could gain performance by not having to first download build results from nixbuild.net and then upload them somewhere else. This could be very useful for CI setups that can spend a considerable amount of their time just uploading closures.&lt;/p&gt;
&lt;h3 id=&quot;provide-an-http-based-binary-cache&quot;&gt;Provide an HTTP-based binary cache&lt;/h3&gt;
&lt;p&gt;Using nixbuild.net as a binary cache is handy since you don’t have to wait for any uploads after a build has finished. Instead, the closures will be immediately available in the binary cache, backed by nixbuild.net.&lt;/p&gt;
&lt;p&gt;It is actually possible to use nixbuild.net as a binary cache today, by configuring an SSH-based cache (&lt;code&gt;ssh://eu.nixbuild.net&lt;/code&gt;). This works out of the box right now. You can even use &lt;code&gt;nix-copy-closure&lt;/code&gt; to upload paths to nixbuild.net. We just don’t yet give any guarantees on how long store paths are kept.&lt;/p&gt;
&lt;p&gt;However, there are benfits to providing an HTTP-based cache. It would most probably have better performance (serving nar files over HTTP instead of using the &lt;code&gt;nix-store&lt;/code&gt; protocol over SSH), but more importantly it would let us use a CDN for serving cache contents. This could help mitigate the fact that nixbuild.net is only deployed in Europe so far.&lt;/p&gt;
&lt;h3 id=&quot;support-builds-that-use-kvm&quot;&gt;Support builds that use KVM&lt;/h3&gt;
&lt;p&gt;The primary motivation for this is to be able to run NixOS tests (with good performance) on nixbuild.net.&lt;/p&gt;
&lt;h2 id=&quot;thank-you&quot;&gt;Thank You!&lt;/h2&gt;
&lt;p&gt;Finally we’d like to thank all our users. We look forward to an exciting new year with lots of Nix builds!&lt;/p&gt;</description>
	<pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
	<author>support@nixbuild.net (nixbuild.net)</author>
</item>
<item>
	<title>Cachix: Postmortem of outage on 20th December</title>
	<guid isPermaLink="true">https://blog.cachix.org/posts/2020-12-23-post-mortem-recent-downtime/</guid>
	<link>https://blog.cachix.org/posts/2020-12-23-post-mortem-recent-downtime/</link>
	<description>On 20 December, Cachix experienced a six-hour downtime, the second significant outage since the service started operating on 1 June 2018.
Here are the details of what exactly happened and what has been done to prevent similar events from happening.
Timeline (UTC)  02:55:07 - Backend starts to emit errors for all HTTP requests 02:56:00 - Pagerduty tries to notify me of outage via email, phone and mobile app 09:01:00 - I wake up and see the notifications 09:02:02 - Backend is restarted and recovers  Root cause analysis All ~24k HTTP requests that reached the backend during the outage failed with the following exception:</description>
	<pubDate>Thu, 24 Dec 2020 11:30:00 +0000</pubDate>
	<author>support@cachix.org (Domen Kožar)</author>
</item>
<item>
	<title>Ollie Charles: Monad Transformers and Effects with Backpack</title>
	<guid isPermaLink="true">http://ocharles.org.uk/blog/posts/2020-12-23-monad-transformers-and-effects-with-backpack.html</guid>
	<link>http://ocharles.org.uk/blog/posts/2020-12-23-monad-transformers-and-effects-with-backpack.html</link>
	<description>&lt;p&gt;A good few years ago &lt;a href=&quot;http://ezyang.com/&quot;&gt;Edward Yang&lt;/a&gt; gifted us an implementation of Backpack - a way for us to essentially abstract modules over other modules, allowing us to write code independently of implementation. A big benefit of doing this is that it opens up new avenues for program optimization. When we provide concrete instantiations of signatures, GHC compiles it as if that were the original code we wrote, and we can benefit from a lot of specialization. So aside from organizational concerns, Backpack gives us the ability to write some really fast code. This benefit isn’t just theoretical - Edward Kmett gave us &lt;a href=&quot;https://hackage.haskell.org/package/unpacked-containers&quot;&gt;unpacked-containers&lt;/a&gt;, removing a level of indirection from all keys, and Oleg Grenrus showed as how we can use Backpack to &lt;a href=&quot;https://www.well-typed.com/blog/2019/11/unrolling-data-with-backpack/&quot;&gt;“unroll” fixed sized vectors&lt;/a&gt;. In this post, I want to show how we can use Backpack to give us the performance benefits of explicit transformers, but without having library code commit to any specific stack. In short, we get the ability to have multiple interpretations of our program, but without paying the performance cost of abstraction.&lt;/p&gt;
&lt;h1 id=&quot;the-problem&quot;&gt;The Problem&lt;/h1&gt;
&lt;p&gt;Before we start looking at any code, let’s look at some requirements, and understand the problems that come with some potential solutions. The main requirement is that we are able to write code that requires some effects (in essence, writing our code to an effect &lt;em&gt;interface&lt;/em&gt;), and then run this code with different interpretations. For example, in production I might want to run as fast as possible, in local development I might want further diagnostics, and in testing I might want a pure or in memory solution. This change in representation shouldn’t require me to change the underlying library code.&lt;/p&gt;
&lt;p&gt;Seasoned Haskellers might be familiar with the use of effect systems to solve these kinds of problems. Perhaps the most familiar is the &lt;code&gt;mtl&lt;/code&gt; approach - perhaps unfortunately named as the technique itself doesn’t have much to do with the library. In the &lt;code&gt;mtl&lt;/code&gt; approach, we write our interfaces as type classes abstracting over some &lt;code&gt;Monad m&lt;/code&gt;, and then provide instances of these type classes - either by stacking transformers (“plucking constraints”, in the &lt;a href=&quot;https://www.parsonsmatt.org/2020/01/03/plucking_constraints.html&quot;&gt;words of Matt Parson&lt;/a&gt;), or by a “mega monad” that implements many of these instances at once (e.g., like Tweag’s &lt;a href=&quot;https://github.com/tweag/capability&quot;&gt;&lt;code&gt;capability&lt;/code&gt;&lt;/a&gt;) approach.&lt;/p&gt;
&lt;p&gt;Despite a few annoyances (e.g., the “n+k” problem, the lack of implementations being first-class, and a few other things), this approach can work well. It also has the &lt;em&gt;potential&lt;/em&gt; to generate a great code, but &lt;em&gt;in practice&lt;/em&gt; it’s rarely possible to achieve maximal performance. In her excellent talk &lt;a href=&quot;https://www.youtube.com/watch?v=0jI-AlWEwYI&quot;&gt;“Effects for Less”&lt;/a&gt;, &lt;a href=&quot;https://lexi-lambda.github.io/&quot;&gt;Alexis King&lt;/a&gt; hits the nail on the head - despite being able to provide good code for the implementations of particular &lt;em&gt;parts&lt;/em&gt; of an effect, the majority of effectful code is really just threading around inside the &lt;code&gt;Monad&lt;/code&gt; constraint. When we’re being polymorphic over any &lt;code&gt;Monad m&lt;/code&gt;, GHC is at a loss to do any further optimization - and how could it? We know nothing more than “there will be some &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt; function when you get here, promise!” Let’s look at this in a bit more detail.&lt;/p&gt;
&lt;p&gt;Say we have the following:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb1-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;foo ::&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Monad&lt;/span&gt; m &lt;span class=&quot;ot&quot;&gt;=&amp;gt;&lt;/span&gt; m &lt;span class=&quot;dt&quot;&gt;Int&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb1-2&quot;&gt;&lt;/a&gt;foo &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; go &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;_000_000_000&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb1-3&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb1-4&quot;&gt;&lt;/a&gt;    go acc &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; acc&lt;/span&gt;
&lt;span id=&quot;cb1-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb1-5&quot;&gt;&lt;/a&gt;    go acc i &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; acc &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; go (acc &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) (i &lt;span class=&quot;op&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is obviously “I needed an example for my blog” levels of contrived, but at least small. How does it execute? What are the runtime consequences of this code? To answer, we’ll go all the way down to the STG level with &lt;code&gt;-ddump-stg&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;wfoo &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-2&quot;&gt;&lt;/a&gt;    \r [ww_s2FA ww1_s2FB]&lt;/span&gt;
&lt;span id=&quot;cb2-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-3&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb2-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-4&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;dt&quot;&gt;Rec&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb2-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-5&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;sgo_s2FC &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-6&quot;&gt;&lt;/a&gt;              \r [sc_s2FD sc1_s2FE]&lt;/span&gt;
&lt;span id=&quot;cb2-7&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-7&quot;&gt;&lt;/a&gt;                  &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; eqInteger&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; sc_s2FD lvl1_r2Fp &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb2-8&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-8&quot;&gt;&lt;/a&gt;                    __DEFAULT &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-9&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-9&quot;&gt;&lt;/a&gt;                        &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb2-10&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-10&quot;&gt;&lt;/a&gt;                          sat_s2FK &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-11&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-11&quot;&gt;&lt;/a&gt;                              \u []&lt;/span&gt;
&lt;span id=&quot;cb2-12&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-12&quot;&gt;&lt;/a&gt;                                  &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;+#&lt;/span&gt; [sc1_s2FE &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;] &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; sat_s2FJ {&lt;/span&gt;
&lt;span id=&quot;cb2-13&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-13&quot;&gt;&lt;/a&gt;                                    __DEFAULT &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-14&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-14&quot;&gt;&lt;/a&gt;                                        &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; minusInteger sc_s2FD lvl_r2Fo &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; sat_s2FI {&lt;/span&gt;
&lt;span id=&quot;cb2-15&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-15&quot;&gt;&lt;/a&gt;                                          __DEFAULT &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;sgo_s2FC sat_s2FI sat_s2FJ;&lt;/span&gt;
&lt;span id=&quot;cb2-16&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-16&quot;&gt;&lt;/a&gt;                                        };&lt;/span&gt;
&lt;span id=&quot;cb2-17&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-17&quot;&gt;&lt;/a&gt;                                  }; } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-18&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-18&quot;&gt;&lt;/a&gt;                        &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb2-19&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-19&quot;&gt;&lt;/a&gt;                          sat_s2FH &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-20&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-20&quot;&gt;&lt;/a&gt;                              \u []&lt;/span&gt;
&lt;span id=&quot;cb2-21&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-21&quot;&gt;&lt;/a&gt;                                  &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; { sat_s2FG &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;CCCS&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#!&lt;/span&gt; [sc1_s2FE]; } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;  ww1_s2FB sat_s2FG;&lt;/span&gt;
&lt;span id=&quot;cb2-22&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-22&quot;&gt;&lt;/a&gt;                        } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;  ww_s2FA sat_s2FH sat_s2FK;&lt;/span&gt;
&lt;span id=&quot;cb2-23&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-23&quot;&gt;&lt;/a&gt;                    &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-24&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-24&quot;&gt;&lt;/a&gt;                        &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; { sat_s2FL &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;CCCS&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#!&lt;/span&gt; [sc1_s2FE]; } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;  ww1_s2FB sat_s2FL;&lt;/span&gt;
&lt;span id=&quot;cb2-25&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-25&quot;&gt;&lt;/a&gt;                  };&lt;/span&gt;
&lt;span id=&quot;cb2-26&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-26&quot;&gt;&lt;/a&gt;          end &lt;span class=&quot;dt&quot;&gt;Rec&lt;/span&gt; }&lt;/span&gt;
&lt;span id=&quot;cb2-27&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-27&quot;&gt;&lt;/a&gt;        } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;sgo_s2FC lvl2_r2Fq &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb2-28&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-28&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-29&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-29&quot;&gt;&lt;/a&gt;foo &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-30&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-30&quot;&gt;&lt;/a&gt;    \r [w_s2FM]&lt;/span&gt;
&lt;span id=&quot;cb2-31&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-31&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; w_s2FM &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb2-32&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-32&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;dt&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;Monad&lt;/span&gt; _ _ ww3_s2FQ ww4_s2FR &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;wfoo ww3_s2FQ ww4_s2FR;&lt;/span&gt;
&lt;span id=&quot;cb2-33&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb2-33&quot;&gt;&lt;/a&gt;        };&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In STG, whenever we have a &lt;code&gt;let&lt;/code&gt; we have to do a heap allocation - and this code has quite a few! Of particular interest is the what’s going on inside the actual loop &lt;code&gt;$sgo_s2FC&lt;/code&gt;. This loop first compares &lt;code&gt;i&lt;/code&gt; to see if it’s &lt;code&gt;0&lt;/code&gt;. In the case that’s it’s not, we allocate two objects and call &lt;code&gt;ww_s2Fa&lt;/code&gt;. If you squint, you’ll notice that &lt;code&gt;ww_s2FA&lt;/code&gt; is the first argument to &lt;code&gt;$wfoo&lt;/code&gt;, and it ultimately comes from unpacking a &lt;code&gt;C:Monad&lt;/code&gt; dictionary. I’ll save you the labor of working out what this is - &lt;code&gt;ww_s2Fa&lt;/code&gt; is the &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;. We can see that every iteration of our loop incurs two allocations for each argument to &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;. A heap allocation doesn’t come for free - not only do we have to do the allocation, the entry into the heap incurs a pointer indirection (as heap objects have an info table that points to their entry), and also by merely being on the heap we increase our GC time as we have a bigger heap to traverse. While my STG knowledge isn’t great, my understanding of this code is that every time we want to call &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;, we need to supply it with its arguments. This means we have to allocate two closures for this function call - which is basically whenever we pressed “return” on our keyboard when we wrote the code. This seems crazy - can you imagine if you were told in C that merely using &lt;code&gt;;&lt;/code&gt; would cost time and memory?&lt;/p&gt;
&lt;p&gt;If we compile this code in a separate module, mark it as &lt;code&gt;{-# NOINLINE #-}&lt;/code&gt;, and then call it from &lt;code&gt;main&lt;/code&gt; - how’s the performance? Let’s check!&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb3-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Main&lt;/span&gt; (main) &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb3-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb3-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Foo&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb3-4&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb3-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb3-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;main ::&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;IO&lt;/span&gt; ()&lt;/span&gt;
&lt;span id=&quot;cb3-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb3-6&quot;&gt;&lt;/a&gt;main &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;=&amp;lt;&amp;lt;&lt;/span&gt; foo&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;$ ./Main +RTS -s
1000000000
 176,000,051,368 bytes allocated in the heap
       8,159,080 bytes copied during GC
          44,408 bytes maximum residency (1 sample(s))
          33,416 bytes maximum slop
               0 MB total memory in use (0 MB lost due to fragmentation)

                                     Tot time (elapsed)  Avg pause  Max pause
  Gen  0     169836 colls,     0 par    0.358s   0.338s     0.0000s    0.0001s
  Gen  1         1 colls,     0 par    0.000s   0.000s     0.0001s    0.0001s

  INIT    time    0.000s  (  0.000s elapsed)
  MUT     time   54.589s  ( 54.627s elapsed)
  GC      time    0.358s  (  0.338s elapsed)
  EXIT    time    0.000s  (  0.000s elapsed)
  Total   time   54.947s  ( 54.965s elapsed)

  %GC     time       0.0%  (0.0% elapsed)

  Alloc rate    3,224,078,302 bytes per MUT second

  Productivity  99.3% of total user, 99.4% of total elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;OUCH&lt;/strong&gt;. My i7 laptop took almost a minute to iterate a loop 1 billion times.&lt;/p&gt;
&lt;p&gt;A little disclaimer: I’m intentionally painting a severe picture here - in practice this cost is irrelevant to all but the most performance sensitive programs. Also, notice where the &lt;code&gt;let&lt;/code&gt; bindings are in the STG above - they are nested within the loop. This means that we’re essentially allocating “as we go” - these allocations are incredibly cheap, and the growth to GC is equal trivial, resulting in more like constant GC pressure, rather than impending doom. For code that is likely to do any IO, this cost is likely negligible compared to the rest of the work. Nonetheless, it is there, and when it’s there, it’s nice to know if there are alternatives.&lt;/p&gt;
&lt;p&gt;So, is the TL;DR that Haskell is completely incapable of writing effectful code? No, of course not. There is another way to compile this program, but we need a bit more information. If we happen to know what &lt;code&gt;m&lt;/code&gt; is and we have access to the &lt;code&gt;Monad&lt;/code&gt; dictionary for &lt;code&gt;m&lt;/code&gt;, then we might be able to inline &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt;. When we do this, GHC can be a lot smarter. The end result is code that now doesn’t allocate for every single &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt;, and instead just gets on with doing work. One trivial way to witness this is to define everything in a single module (Alexis rightly points out this is a trap for benchmarking that many fall into, but for our uses it’s the behavior we actually want).&lt;/p&gt;
&lt;p&gt;This time, let’s write everything in one module:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb5&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb5-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb5-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Main&lt;/span&gt; ( main ) &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb5-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb5-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And the STG:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb6&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb6-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-1&quot;&gt;&lt;/a&gt;lvl_r4AM &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;CCS_DONT_CARE&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#!&lt;/span&gt; [&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;];&lt;/span&gt;
&lt;span id=&quot;cb6-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-3&quot;&gt;&lt;/a&gt;lvl1_r4AN &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;CCS_DONT_CARE&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#!&lt;/span&gt; [&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;];&lt;/span&gt;
&lt;span id=&quot;cb6-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-4&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;dt&quot;&gt;Rec&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb6-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-6&quot;&gt;&lt;/a&gt;main_&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;sgo &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-7&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-7&quot;&gt;&lt;/a&gt;    \r [void_0E sc1_s4AY sc2_s4AZ]&lt;/span&gt;
&lt;span id=&quot;cb6-8&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-8&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; eqInteger&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; sc1_s4AY lvl_r4AM &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb6-9&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-9&quot;&gt;&lt;/a&gt;          __DEFAULT &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-10&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-10&quot;&gt;&lt;/a&gt;              &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;+#&lt;/span&gt; [sc2_s4AZ &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;] &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; sat_s4B2 {&lt;/span&gt;
&lt;span id=&quot;cb6-11&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-11&quot;&gt;&lt;/a&gt;                __DEFAULT &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-12&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-12&quot;&gt;&lt;/a&gt;                    &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; minusInteger sc1_s4AY lvl1_r4AN &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; sat_s4B1 {&lt;/span&gt;
&lt;span id=&quot;cb6-13&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-13&quot;&gt;&lt;/a&gt;                      __DEFAULT &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; main_&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;sgo void&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; sat_s4B1 sat_s4B2;&lt;/span&gt;
&lt;span id=&quot;cb6-14&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-14&quot;&gt;&lt;/a&gt;                    };&lt;/span&gt;
&lt;span id=&quot;cb6-15&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-15&quot;&gt;&lt;/a&gt;              };&lt;/span&gt;
&lt;span id=&quot;cb6-16&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-16&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; { sat_s4B3 &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;CCCS&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#!&lt;/span&gt; [sc2_s4AZ]; } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;  &lt;span class=&quot;dt&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; [sat_s4B3];&lt;/span&gt;
&lt;span id=&quot;cb6-17&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-17&quot;&gt;&lt;/a&gt;        };&lt;/span&gt;
&lt;span id=&quot;cb6-18&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-18&quot;&gt;&lt;/a&gt;end &lt;span class=&quot;dt&quot;&gt;Rec&lt;/span&gt; }&lt;/span&gt;
&lt;span id=&quot;cb6-19&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-19&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-20&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-20&quot;&gt;&lt;/a&gt;main2 &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;CCS_DONT_CARE&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#!&lt;/span&gt; [&lt;span class=&quot;dv&quot;&gt;1000000000&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;];&lt;/span&gt;
&lt;span id=&quot;cb6-21&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-21&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-22&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-22&quot;&gt;&lt;/a&gt;main1 &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-23&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-23&quot;&gt;&lt;/a&gt;    \r [void_0E]&lt;/span&gt;
&lt;span id=&quot;cb6-24&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-24&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; main_&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;sgo void&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; main2 &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb6-25&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-25&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;dt&quot;&gt;Unit&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; ipv1_s4B7 &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-26&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-26&quot;&gt;&lt;/a&gt;              &lt;span class=&quot;kw&quot;&gt;let&lt;/span&gt; { sat_s4B8 &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; \s [] &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;fShowInt_&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;cshow ipv1_s4B7;&lt;/span&gt;
&lt;span id=&quot;cb6-27&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-27&quot;&gt;&lt;/a&gt;              } &lt;span class=&quot;kw&quot;&gt;in&lt;/span&gt;  hPutStr' stdout sat_s4B8 &lt;span class=&quot;dt&quot;&gt;True&lt;/span&gt; void&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb6-28&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-28&quot;&gt;&lt;/a&gt;        };&lt;/span&gt;
&lt;span id=&quot;cb6-29&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-29&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-30&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-30&quot;&gt;&lt;/a&gt;main &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; \r [void_0E] main1 void&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb6-31&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-31&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-32&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-32&quot;&gt;&lt;/a&gt;main3 &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; \r [void_0E] runMainIO1 main1 void&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb6-33&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-33&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb6-34&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb6-34&quot;&gt;&lt;/a&gt;main &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; \r [void_0E] main3 void&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The same program compiled down to much tighter loop that is almost entirely free of allocations. In fact, the only allocation that happens is when the loop terminates, and it’s just boxing the unboxed integer that’s been accumulating in the loop.&lt;/p&gt;
&lt;p&gt;As we might hope, the performance of this is much better:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./Main +RTS -s
1000000000
  16,000,051,312 bytes allocated in the heap
         128,976 bytes copied during GC
          44,408 bytes maximum residency (1 sample(s))
          33,416 bytes maximum slop
               0 MB total memory in use (0 MB lost due to fragmentation)

                                     Tot time (elapsed)  Avg pause  Max pause
  Gen  0     15258 colls,     0 par    0.031s   0.029s     0.0000s    0.0000s
  Gen  1         1 colls,     0 par    0.000s   0.000s     0.0001s    0.0001s

  INIT    time    0.000s  (  0.000s elapsed)
  MUT     time    9.402s  (  9.405s elapsed)
  GC      time    0.031s  (  0.029s elapsed)
  EXIT    time    0.000s  (  0.000s elapsed)
  Total   time    9.434s  (  9.434s elapsed)

  %GC     time       0.0%  (0.0% elapsed)

  Alloc rate    1,701,712,595 bytes per MUT second

  Productivity  99.7% of total user, 99.7% of total elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our time in the garbage collector dropped by a factor of 10, from 0.3s to 0.03. Our total allocation dropped from 176GB (yes, you read that right) to 16GB (I’m still not entirely sure what this means, maybe someone can enlighten me). Most importantly our total runtime dropped from 54s to just under 10s. All this from just knowing what &lt;code&gt;m&lt;/code&gt; is at compile time.&lt;/p&gt;
&lt;p&gt;So GHC is capable of producing excellent code for monads - what are the circumstances under which this happens? We need, at least:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;The source code of the thing we’re compiling must be available. This means it’s either defined in the same module, or is available with an &lt;code&gt;INLINABLE&lt;/code&gt; pragma (or GHC has chosen to add this itself).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The definitions of &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt; and friends must also be available in the same way.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These constraints start to feel a lot like needing whole program compilation, and in practice are unreasonable constraints to reach. To understand why, consider that most real world programs have a small &lt;code&gt;Main&lt;/code&gt; module that opens some connections or opens some file handles, and then calls some library code defined in another module. If this code in the other module was already compiled, it will (probably) have been compiled as a function that takes a &lt;code&gt;Monad&lt;/code&gt; dictionary, and just calls the &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt; function repeatedly in the same manner as our original STG code. To get the allocation-free version, this library code needs to be available to the &lt;code&gt;Main&lt;/code&gt; module itself - as that’s the module that choosing what type to instantiate ‘m’ with - which means the library code has to have marked that code as being inlinable. While we could add &lt;code&gt;INLINE&lt;/code&gt; everywhere, this leads to an explosion in the amount of code produced, and can sky rocket compilation times.&lt;/p&gt;
&lt;p&gt;Alexis’ &lt;a href=&quot;https://github.com/hasura/eff&quot;&gt;&lt;code&gt;eff&lt;/code&gt;&lt;/a&gt; library works around this by &lt;em&gt;not&lt;/em&gt; being polymorphic in &lt;code&gt;m&lt;/code&gt;. Instead, it chooses a concrete monad with all sorts of fancy continuation features. Likewise, if we commit to a particular monad (a transformer stack, or maybe using &lt;code&gt;RIO&lt;/code&gt;), we again avoid this cost. Essentially, if the monad is known a priori at time of module compilation, GHC can go to town. However, the latter also commits to semantics - by choosing a transformer stack, we’re choosing a semantics for our monadic effects.&lt;/p&gt;
&lt;p&gt;With the scene set, I now want to present you with another approach to solving this problem using Backpack.&lt;/p&gt;
&lt;h1 id=&quot;a-backpack-primer&quot;&gt;A Backpack Primer&lt;/h1&gt;
&lt;p&gt;Vanilla GHC has a very simple module system - modules are essentially a method for name-spacing and separate compilation, they don’t do much more. The Backpack project extends this module system with a new concept - signatures. A signature is like the “type” of a module - a signature might mention the presence of some types, functions and type class instances, but it says nothing about what the definitions of these entities are. We’re going to (ab)use this system to build up transformer stacks at configuration time, and allow our library to be abstracted over different monads. By instantiating our library code with different monads, we get different interpretations of the same program.&lt;/p&gt;
&lt;p&gt;I won’t sugar coat - what follows is going to pretty miserable. Extremely fun, but miserable to write in practice. I’ll let you decide if you want to inflict this misery on your coworkers in practice - I’m just here to show you it can be done!&lt;/p&gt;
&lt;h2 id=&quot;a-signature-for-monads&quot;&gt;A Signature for Monads&lt;/h2&gt;
&lt;p&gt;The first thing we’ll need is a signature for data types that are monads. This is essentially the “hole” we’ll rely on with our library code - it will give us the ability to say “there exists a monad”, without committing to any particular choice.&lt;/p&gt;
&lt;p&gt;In our Cabal file, we have:&lt;/p&gt;
&lt;pre class=&quot;cabal&quot;&gt;&lt;code&gt;library monad-sig
  hs-source-dirs:   src-monad-sig
  signatures:       Control.Monad.Signature
  default-language: Haskell2010
  build-depends:    base&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The important line here is &lt;code&gt;signatures: Control.Monad.Signature&lt;/code&gt; which shows that this library is incomplete and exports a signature. The definition of &lt;code&gt;Control/Monad/Signature.hsig&lt;/code&gt; is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb9&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb9-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb9-1&quot;&gt;&lt;/a&gt;signature &lt;span class=&quot;dt&quot;&gt;Control.Monad.Signature&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb9-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb9-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt; a&lt;/span&gt;
&lt;span id=&quot;cb9-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb9-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Functor&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb9-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Applicative&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb9-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb9-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Monad&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This simply states that any module with this signature has some type &lt;code&gt;M&lt;/code&gt; with instances of &lt;code&gt;Functor&lt;/code&gt;, &lt;code&gt;Applicative&lt;/code&gt; and &lt;code&gt;Monad&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next, we’ll put that signature to use in our library code.&lt;/p&gt;
&lt;h2 id=&quot;libary-code&quot;&gt;Libary Code&lt;/h2&gt;
&lt;p&gt;For our library code, we’ll start with a new library in our Cabal file:&lt;/p&gt;
&lt;pre class=&quot;cabal&quot;&gt;&lt;code&gt;library business-logic
  hs-source-dirs:   lib
  signatures:       BusinessLogic.Monad
  exposed-modules:  BusinessLogic
  build-depends:
    , base
    , fused-effects
    , monad-sig

  default-language: Haskell2010
  mixins:
    monad-sig requires (Control.Monad.Signature as BusinessLogic.Monad)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our business-logic library itself exports a signature, which is really just a re-export of the &lt;code&gt;Control.Monad.Signature&lt;/code&gt;, but we rename it something more meaningful. It’s this module that will provide the monad that has all of the effects we need. Along with this signature, we also export the &lt;code&gt;BusinessLogic&lt;/code&gt; module:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb11&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb11-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;{-# language FlexibleContexts #-}&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;BusinessLogic&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-3&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;BusinessLogic.Monad&lt;/span&gt; ( &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt; )&lt;/span&gt;
&lt;span id=&quot;cb11-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-5&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Algebra&lt;/span&gt; ( &lt;span class=&quot;dt&quot;&gt;Has&lt;/span&gt; )&lt;/span&gt;
&lt;span id=&quot;cb11-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Effect.Empty&lt;/span&gt; ( &lt;span class=&quot;dt&quot;&gt;Empty&lt;/span&gt;, guard )&lt;/span&gt;
&lt;span id=&quot;cb11-7&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-7&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-8&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;businessCode ::&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Has&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Empty&lt;/span&gt; sig &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Bool&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Int&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-9&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-9&quot;&gt;&lt;/a&gt;businessCode b &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;do&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-10&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-10&quot;&gt;&lt;/a&gt;  guard b&lt;/span&gt;
&lt;span id=&quot;cb11-11&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb11-11&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;42&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this module I’m using &lt;code&gt;fused-effects&lt;/code&gt; as a framework to say which effects my monad should have (though this is not particularly important, I just like it!). Usually &lt;code&gt;Has&lt;/code&gt; would be applied to a type variable &lt;code&gt;m&lt;/code&gt;, but here we’re applying it to the type &lt;code&gt;M&lt;/code&gt;. This type comes from &lt;code&gt;BusinessLogic.Monad&lt;/code&gt;, which is a signature (you can confirm this by checking against the Cabal file). Other than that, this is all pretty standard!&lt;/p&gt;
&lt;h2 id=&quot;backpack-ing-monad-transformers&quot;&gt;Backpack-ing Monad Transformers&lt;/h2&gt;
&lt;p&gt;Now we get into the really fun stuff - providing implementations of effects. I mentioned earlier that one possible way to do this is with a stack of monad transformers. Generally speaking, one would write a single &lt;code&gt;newtype T m a&lt;/code&gt; for each effect type class, and have that transformer dispatch any effects in that class, and to &lt;code&gt;lift&lt;/code&gt; any effects from other classes - deferring their implementation to &lt;code&gt;m&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We’re going to take the same approach here, but we’ll absorb the idea of a transformer directly into the module itself. Let’s look at an implementation of the &lt;code&gt;Empty&lt;/code&gt; effect. The &lt;code&gt;Empty&lt;/code&gt; effect gives us a special &lt;code&gt;empty :: m a&lt;/code&gt; function, which serves the purpose of stopping execution immediately. As a monad transformer, one implementation is &lt;code&gt;MaybeT&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb12&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb12-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb12-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;newtype&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;MaybeT&lt;/span&gt; m a &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;MaybeT&lt;/span&gt; {&lt;span class=&quot;ot&quot;&gt; runMaybeT ::&lt;/span&gt; m (&lt;span class=&quot;dt&quot;&gt;Maybe&lt;/span&gt; a) }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But we can also write this using Backpack. First, our Cabal library:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb13&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb13-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-1&quot;&gt;&lt;/a&gt;library fused&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;effects&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;empty&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;maybe&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-2&quot;&gt;&lt;/a&gt;  hs&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;source&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;dirs&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;   src&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;fused&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;effects&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;backpack&lt;/span&gt;
&lt;span id=&quot;cb13-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-3&quot;&gt;&lt;/a&gt;  default&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;language&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Haskell2010&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-4&quot;&gt;&lt;/a&gt;  build&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;depends&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-5&quot;&gt;&lt;/a&gt;    , base&lt;/span&gt;
&lt;span id=&quot;cb13-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-6&quot;&gt;&lt;/a&gt;    , fused&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;effects&lt;/span&gt;
&lt;span id=&quot;cb13-7&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-7&quot;&gt;&lt;/a&gt;    , monad&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;sig&lt;/span&gt;
&lt;span id=&quot;cb13-8&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-8&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-9&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-9&quot;&gt;&lt;/a&gt;  exposed&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;modules&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Carrier.Backpack.Empty.Maybe&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-10&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-10&quot;&gt;&lt;/a&gt;  mixins&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-11&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb13-11&quot;&gt;&lt;/a&gt;    monad&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;sig requires (&lt;span class=&quot;dt&quot;&gt;Control.Monad.Signature&lt;/span&gt; as &lt;span class=&quot;dt&quot;&gt;Control.Carrier.Backpack.Empty.Maybe.Base&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our library exports the module &lt;code&gt;Control.Carrier.Backpack.Empty.Maybe&lt;/code&gt;, but also has a hole - the type of base monad this transformer stacks on top of. As a monad transformer, this would be the &lt;code&gt;m&lt;/code&gt; parameter, but when we use Backpack, we move that out into a separate module.&lt;/p&gt;
&lt;p&gt;The implementation of &lt;code&gt;Control.Carrier.Backpack.Empty.Maybe&lt;/code&gt; is short, and almost identical to the body of &lt;code&gt;Control.Monad.Trans.Maybe&lt;/code&gt; - we just change any occurrences of &lt;code&gt;m&lt;/code&gt; to instead refer to &lt;code&gt;M&lt;/code&gt; from our &lt;code&gt;.Base&lt;/code&gt; module:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb14&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb14-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;{-# language BlockArguments, FlexibleContexts, FlexibleInstances, LambdaCase,&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;      MultiParamTypeClasses, TypeOperators, UndecidableInstances #-}&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-3&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Carrier.Backpack.Empty.Maybe&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-5&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Algebra&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-7&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-7&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Effect.Empty&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-8&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-8&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;qualified&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Carrier.Backpack.Empty.Maybe.Base&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Base&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-9&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-9&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-10&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-10&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-11&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-11&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-12&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-12&quot;&gt;&lt;/a&gt;&lt;span class=&quot;co&quot;&gt;-- We could also write: newtype EmptyT a = EmptyT { runEmpty :: MaybeT Base.M a }&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-13&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-13&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;newtype&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; a &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; {&lt;span class=&quot;ot&quot;&gt; runEmpty ::&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Base.M&lt;/span&gt; (&lt;span class=&quot;dt&quot;&gt;Maybe&lt;/span&gt; a) }&lt;/span&gt;
&lt;span id=&quot;cb14-14&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-14&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-15&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-15&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Functor&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-16&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-16&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;fu&quot;&gt;fmap&lt;/span&gt; f (&lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; m) &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;fmap&lt;/span&gt; (&lt;span class=&quot;fu&quot;&gt;fmap&lt;/span&gt; f) m&lt;/span&gt;
&lt;span id=&quot;cb14-17&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-17&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-18&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-18&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Applicative&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-19&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-19&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;fu&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-20&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-20&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; f &lt;span class=&quot;op&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; x &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;do&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-21&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-21&quot;&gt;&lt;/a&gt;    f &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; \&lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-22&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-22&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-23&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-23&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt; f' &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; x &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; \&lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-24&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-24&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-25&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-25&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt; x' &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; (&lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt; (f' x'))&lt;/span&gt;
&lt;span id=&quot;cb14-26&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-26&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-27&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-27&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Monad&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-28&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-28&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;pure&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-29&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-29&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; x &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; f &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;do&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-30&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-30&quot;&gt;&lt;/a&gt;    x &lt;span class=&quot;op&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; \&lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-31&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-31&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt; x' &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; runEmpty (f x')&lt;/span&gt;
&lt;span id=&quot;cb14-32&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb14-32&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, we make sure that &lt;code&gt;Empty&lt;/code&gt; can handle the &lt;code&gt;Empty&lt;/code&gt; effect:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb15&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb15-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb15-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Algebra&lt;/span&gt; sig &lt;span class=&quot;dt&quot;&gt;Base.M&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Algebra&lt;/span&gt; (&lt;span class=&quot;dt&quot;&gt;Empty&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;:+:&lt;/span&gt; sig) &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb15-2&quot;&gt;&lt;/a&gt;  alg handle sig context &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; sig &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb15-3&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;dt&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Empty&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb15-4&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;dt&quot;&gt;R&lt;/span&gt; other &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;EmptyT&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;$&lt;/span&gt; thread (&lt;span class=&quot;fu&quot;&gt;maybe&lt;/span&gt; (&lt;span class=&quot;fu&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt;) runEmpty &lt;span class=&quot;op&quot;&gt;~&amp;lt;~&lt;/span&gt; handle) other (&lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt; context)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;base-monads&quot;&gt;Base Monads&lt;/h2&gt;
&lt;p&gt;Now that we have a way to run the &lt;code&gt;Empty&lt;/code&gt; effect, we need a base case to our transformer stack. As our transformer is now built out of modules that conform to the &lt;code&gt;Control.Monad.Signature&lt;/code&gt; signature, we need some modules for each monad that we could use as a base. For this POC, I’ve just added the IO monad:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library fused-effects-lift-io
  hs-source-dirs:   src-fused-effects-backpack
  default-language: Haskell2010
  build-depends:    base
  exposed-modules:  Control.Carrier.Backpack.Lift.IO&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb17&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb17-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb17-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Control.Carrier.Backpack.Lift.IO&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb17-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb17-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;IO&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That’s it!&lt;/p&gt;
&lt;h2 id=&quot;putting-it-all-together&quot;&gt;Putting It All Together&lt;/h2&gt;
&lt;p&gt;Finally we can put all of this together into an actual executable. We’ll take our library code, instantiate the monad to be a combination of &lt;code&gt;EmptyT&lt;/code&gt; and &lt;code&gt;IO&lt;/code&gt;, and write a little &lt;code&gt;main&lt;/code&gt; function that unwraps this all into an &lt;code&gt;IO&lt;/code&gt; type. First, here’s the &lt;code&gt;Main&lt;/code&gt; module:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb18&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb18-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;Main&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-2&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-3&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;BusinessLogic&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-4&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;qualified&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;BusinessLogic.Monad&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-5&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb18-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-6&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;main ::&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;IO&lt;/span&gt; ()&lt;/span&gt;
&lt;span id=&quot;cb18-7&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb18-7&quot;&gt;&lt;/a&gt;main &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;=&amp;lt;&amp;lt;&lt;/span&gt; BusinessLogic.Monad.runEmptyT (businessCode &lt;span class=&quot;dt&quot;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;BusinessLogic&lt;/code&gt; module we’ve seen before, but previously &lt;code&gt;BusinessLogic.Monad&lt;/code&gt; was a signature (remember, we renamed &lt;code&gt;Control.Monad.Signature&lt;/code&gt; to &lt;code&gt;BusinessLogic.Monad&lt;/code&gt;). In executables, you can’t have signatures - executables can’t be depended on, so it doesn’t make sense for them to have holes, they must be complete. The magic happens in our Cabal file:&lt;/p&gt;
&lt;pre class=&quot;cabal&quot;&gt;&lt;code&gt;executable test
  main-is:          Main.hs
  hs-source-dirs:   exe
  build-depends:
    , base
    , business-logic
    , fused-effects-empty-maybe
    , fused-effects-lift-io
    , transformers

  default-language: Haskell2010
  mixins:
    fused-effects-empty-maybe (Control.Carrier.Backpack.Empty.Maybe as BusinessLogic.Monad) requires (Control.Carrier.Backpack.Empty.Maybe.Base as BusinessLogic.Monad.Base),
    fused-effects-lift-io (Control.Carrier.Backpack.Lift.IO as BusinessLogic.Monad.Base)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wow, that’s a mouthful! The work is really happening in &lt;code&gt;mixins&lt;/code&gt;. Let’s take this step by step:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;First, we can see that we need to mixin the &lt;code&gt;fused-effects-empty-maybe&lt;/code&gt; library. The first &lt;code&gt;(X as Y)&lt;/code&gt; section specifies a list of modules from &lt;code&gt;fused-effects-empty-maybe&lt;/code&gt; and renames them for the &lt;code&gt;test&lt;/code&gt; executable that’s currently being compiled. Here, we’re renaming &lt;code&gt;Control.Carrier.Backpack.Empty.Maybe&lt;/code&gt; as &lt;code&gt;BusinessLogic.Monad&lt;/code&gt;. By doing this, we satisfy the hole in the &lt;code&gt;business-logic&lt;/code&gt; library, which was otherwise incomplete.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;But &lt;code&gt;fused-effects-empty-maybe&lt;/code&gt; itself has a hole - the base monad for the transformer. The &lt;code&gt;requires&lt;/code&gt; part lets us rename this hole, but we’ll still need to plug it. For now, we rename &lt;code&gt;Control.Carrier.Backpack.Empty.Maybe.Base&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, we mixin the &lt;code&gt;fused-effects-lift-io&lt;/code&gt; library, and rename &lt;code&gt;Control.Carrier.Backpack.Lift.IO&lt;/code&gt; to be &lt;code&gt;BusinessLogic.Monad.Base&lt;/code&gt;. We’ve now satisfied the hole for &lt;code&gt;fused-effects-empty-maybe&lt;/code&gt;, and our executable has no more holes and can be compiled.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;were-done&quot;&gt;We’re Done!&lt;/h2&gt;
&lt;p&gt;That’s “all” there is to it. We can finally run our program:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb20&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb20-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb20-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt; cabal run&lt;/span&gt;
&lt;span id=&quot;cb20-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb20-2&quot;&gt;&lt;/a&gt;&lt;span class=&quot;dt&quot;&gt;Just&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;42&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you compare against &lt;code&gt;businessCode&lt;/code&gt; you’ll see that we got passed the &lt;code&gt;guard&lt;/code&gt; and returned &lt;code&gt;42&lt;/code&gt;. Because we instantiated &lt;code&gt;BusinessLogic.Monad&lt;/code&gt; with a &lt;code&gt;MaybeT&lt;/code&gt;-like transformer, this &lt;code&gt;42&lt;/code&gt; got wrapped up in &lt;code&gt;Just&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&quot;is-this-fast&quot;&gt;Is This Fast?&lt;/h1&gt;
&lt;p&gt;The best check here is to just look at the underlying code itself. If we add&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb21&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb21-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb21-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ot&quot;&gt;{-# options -ddump-simpl -ddump-stg -dsuppress-all #-}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to &lt;code&gt;BusinessLogic&lt;/code&gt; and recompile, we’ll see the final code output to STDERR. The core is:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb22&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb22-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb22-1&quot;&gt;&lt;/a&gt;businessCode1&lt;/span&gt;
&lt;span id=&quot;cb22-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb22-2&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt; \ &lt;span class=&quot;op&quot;&gt;@&lt;/span&gt; sig_a2cM _ b_a13P eta_B1 &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb22-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb22-3&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; b_a13P &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb22-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb22-4&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;dt&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; (&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; eta_B1, &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;);&lt;/span&gt;
&lt;span id=&quot;cb22-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb22-5&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;dt&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; (&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt; eta_B1, lvl1_r2NP &lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&quot;cb22-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb22-6&quot;&gt;&lt;/a&gt;      }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the STG:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb23&quot;&gt;&lt;pre class=&quot;sourceCode haskell&quot;&gt;&lt;code class=&quot;sourceCode haskell&quot;&gt;&lt;span id=&quot;cb23-1&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb23-1&quot;&gt;&lt;/a&gt;businessCode1 &lt;span class=&quot;ot&quot;&gt;=&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb23-2&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb23-2&quot;&gt;&lt;/a&gt;    \r [&lt;span class=&quot;op&quot;&gt;$&lt;/span&gt;d(&lt;span class=&quot;op&quot;&gt;%&lt;/span&gt;,&lt;span class=&quot;op&quot;&gt;%&lt;/span&gt;)_s2PE b_s2PF eta_s2PG]&lt;/span&gt;
&lt;span id=&quot;cb23-3&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb23-3&quot;&gt;&lt;/a&gt;        &lt;span class=&quot;kw&quot;&gt;case&lt;/span&gt; b_s2PF &lt;span class=&quot;kw&quot;&gt;of&lt;/span&gt; {&lt;/span&gt;
&lt;span id=&quot;cb23-4&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb23-4&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;dt&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; (&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;,&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;) [eta_s2PG &lt;span class=&quot;dt&quot;&gt;Nothing&lt;/span&gt;];&lt;/span&gt;
&lt;span id=&quot;cb23-5&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb23-5&quot;&gt;&lt;/a&gt;          &lt;span class=&quot;dt&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;-&amp;gt;&lt;/span&gt; (&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;,&lt;span class=&quot;op&quot;&gt;#&lt;/span&gt;) [eta_s2PG lvl1_r2NP];&lt;/span&gt;
&lt;span id=&quot;cb23-6&quot;&gt;&lt;a href=&quot;https://ocharles.org.uk/blog/posts.rss#cb23-6&quot;&gt;&lt;/a&gt;        };&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Voila!&lt;/p&gt;
&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this post, I’ve hopefully shown how we &lt;em&gt;can&lt;/em&gt; use Backpack to write effectful code without paying the cost of abstraction. What I didn’t answer is the question of whether or you not you &lt;em&gt;should&lt;/em&gt;. There’s a lot more to effectful code than I’ve presented, and it’s unclear to me whether this approach can scale to the needs. For example, if we needed something like &lt;code&gt;mmorph&lt;/code&gt;’s &lt;code&gt;MFunctor&lt;/code&gt;, what do we do? Are we stuck? I don’t know! Beyond these technical challenges, it’s clear that Backpack here is also not remotely ergonomic, as is. We’ve had to write &lt;em&gt;five&lt;/em&gt; components just to get this done, and I pray for any one who comes to read this code and has to orientate themselves.&lt;/p&gt;
&lt;p&gt;Nonetheless, I think this an interesting point of the effect design space that hasn’t been explored, and maybe I’ve motivated some people to do some further exploration.&lt;/p&gt;
&lt;p&gt;The code for this blog post can be found at https://github.com/ocharles/fused-effects-backpack.&lt;/p&gt;
&lt;p&gt;Happy holidays, all!&lt;/p&gt;</description>
	<pubDate>Wed, 23 Dec 2020 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Tweag I/O: Trustix: Distributed trust and reproducibility tracking for binary caches</title>
	<guid isPermaLink="true">https://tweag.io/blog/2020-12-16-trustix-announcement/</guid>
	<link>https://tweag.io/blog/2020-12-16-trustix-announcement/</link>
	<description>&lt;p&gt;Downloading binaries from well-known providers is the easiest way to install new software.
After all, building software from source is a chore — it requires both time and technical expertise.
But how do we know that we aren’t installing something malicious from these providers?&lt;/p&gt;
&lt;p&gt;Typically, we trust these binaries because we trust the provider.
We believe that they were built from trusted sources, in a trusted computational environment, and with trusted build instructions.
But even if the provider does everything transparently and in good faith, the binaries could still be &lt;em&gt;anything&lt;/em&gt; if the provider’s system is compromised.
In other words, the build process requires &lt;em&gt;trust&lt;/em&gt; even if all build inputs (sources, dependencies, build scripts, etc…) are known.&lt;/p&gt;
&lt;p&gt;Overcoming this problem is hard — after all, how can we verify the output of arbitrary build inputs?
Excitingly, the last years have brought about ecosystems such as Nix, where all build inputs are known and where &lt;em&gt;significant amounts of builds are reproducible&lt;/em&gt;.
This means that the correspondence between inputs and outputs can be verified by building the same binary multiple times!
The &lt;a href=&quot;https://r13y.com/&quot;&gt;r13y&lt;/a&gt; project, for example, tracks non-reproducible builds by building them twice on the same machine, showing that this is indeed practical.&lt;/p&gt;
&lt;p&gt;But we can go further, and that’s the subject of this blog post, which introduces &lt;a href=&quot;https://github.com/tweag/trustix&quot;&gt;Trustix&lt;/a&gt;, a new tool we are working on.
Trustix compares build outputs for given build inputs across &lt;em&gt;independent&lt;/em&gt; providers and machines, effectively decentralizing trust.
This establishes what I like to call &lt;a href=&quot;https://build-transparency.org&quot;&gt;build transparency&lt;/a&gt; because it verifies what black box build machines are doing.
Behind the scenes Trustix builds a &lt;a href=&quot;https://en.wikipedia.org/wiki/Merkle_tree&quot;&gt;Merkle tree&lt;/a&gt;-based &lt;a href=&quot;https://en.wikipedia.org/wiki/Append-only&quot;&gt;append-only&lt;/a&gt; log that maps build inputs to build outputs, which I’ll come back to in a later post.
This log can be used to establish &lt;a href=&quot;https://en.wikipedia.org/wiki/Consensus_(computer_science)&quot;&gt;consensus&lt;/a&gt; whether certain build inputs always produce the same output — and can therefore be trusted.
Conversely, it can also be used to uncover non-reproducible builds, corrupted or not, on a large scale.&lt;/p&gt;
&lt;p&gt;The initial implementation of Trustix, and its description in this post are based on the Nix package manager.
Nix focuses on isolated builds, provides access to the hashes of all build inputs as well as a high quantity of bit-reproducible packages, making it the ideal initial testing ecosystem.
However, Trustix was designed to be system-independent, and is not strongly tied to Nix.&lt;/p&gt;
&lt;p&gt;The developmentent of &lt;a href=&quot;https://github.com/tweag/trustix&quot;&gt;Trustix&lt;/a&gt; is funded by &lt;a href=&quot;https://nlnet.nl/project/Trustix&quot;&gt;NLnet foundation&lt;/a&gt; and the European Commission’s &lt;a href=&quot;https://ngi.eu&quot;&gt;Next Generation Internet&lt;/a&gt; programme through the &lt;a href=&quot;https://nlnet.nl/PET&quot;&gt;NGI Zero PET&lt;/a&gt; (privacy and trust enhancing technologies) fund.
The tool is still in development, but I’m very excited to announce it already!&lt;/p&gt;
&lt;h2&gt;How Nix verifies binary cache results&lt;/h2&gt;
&lt;p&gt;Most Linux package managers use a very simple signature scheme to secure binary distribution to users.
Some use GPG keys, some use OpenSSL certificates, and others use some other kind of key, but the idea is essentially the same for all of them.
The general approach is that binaries are signed with a private key, and clients can use an associated public key to check that a binary was really signed by the trusted entity.&lt;/p&gt;
&lt;p&gt;Nix for example uses an ed25519-based key signature scheme and comes with a default hard-coded public key that corresponds to the default cache.
This key can be overridden or complemented by others, allowing the use of additional caches.
The list of signing keys can be found in &lt;code class=&quot;language-text&quot;&gt;/etc/nix/nix.conf&lt;/code&gt;.
The default base64-encoded ed25519 public key with a name as additional metadata looks like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;trusted-public-keys = cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY=&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, in Nix, software is addressed by the hash of all of its build inputs (sources, dependencies and build instructions).
This hash, or the output path is used to query a cache (like &lt;a href=&quot;https://cache.nixos.org&quot;&gt;https://cache.nixos.org&lt;/a&gt;) for a binary.&lt;/p&gt;
&lt;p&gt;Here is an example:
The hash of the &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; derivation can be obtained from a shell with &lt;code class=&quot;language-text&quot;&gt;nix-instantiate&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;$ nix-instantiate '&amp;lt;nixpkgs&amp;gt;' --eval -A hello.outPath
&quot;/nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, behind the scenes, we have evaluated and hashed all build inputs that the &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; derivation needs (&lt;code class=&quot;language-text&quot;&gt;.outPath&lt;/code&gt; is just a helper).
This hash can then be used to query the default Nix binary cache:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;$ curl https://cache.nixos.org/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1.narinfo
StorePath: /nix/store/w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10
URL: nar/15zk4zszw9lgkdkkwy7w11m5vag11n5dhv2i6hj308qpxczvdddx.nar.xz
Compression: xz
FileHash: sha256:15zk4zszw9lgkdkkwy7w11m5vag11n5dhv2i6hj308qpxczvdddx
FileSize: 41232
NarHash: sha256:1mi14cqk363wv368ffiiy01knardmnlyphi6h9xv6dkjz44hk30i
NarSize: 205968
References: 9df65igwjmf2wbw0gbrrgair6piqjgmi-glibc-2.31 w9yy7v61ipb5rx6i35zq1mvc2iqfmps1-hello-2.10
Sig: cache.nixos.org-1:uP5KU8MCmyRnKGlN5oEv6xWJBI5EO/Pf5aFztZuLSz8BpCcZ1fdBnJkVXhBAlxkdm/CemsgQskhwvyd2yghTAg==&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Besides links to the archive that contains the compressed binaries, this response includes two relevant pieces of information which are used to verify binaries from the binary cache(s):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code class=&quot;language-text&quot;&gt;NarHash&lt;/code&gt; is a hash over all Nix store directory contents&lt;/li&gt;
&lt;li&gt;The &lt;code class=&quot;language-text&quot;&gt;Sig&lt;/code&gt; is a cryptographic signature over the &lt;code class=&quot;language-text&quot;&gt;NarHash&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With this information, the client can check that this binary really comes from the provider’s Nix store.&lt;/p&gt;
&lt;h2&gt;What are the limitations of this model?&lt;/h2&gt;
&lt;p&gt;While this model has served Nix and others well for many years it suffers from a few problems.
All of these problems can be traced back to a &lt;a href=&quot;https://en.wikipedia.org/wiki/Single_point_of_failure&quot;&gt;single point of failure&lt;/a&gt; in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Chain_of_trust&quot;&gt;chain of trust&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, if the key used by cache.nixos.org is ever compromised, all builds that were ever added to the cache can be considered tainted.&lt;/li&gt;
&lt;li&gt;Second, one needs to put either full trust or no trust at all in the build machines of a binary cache — there is no middle ground.&lt;/li&gt;
&lt;li&gt;Finally, there is no inherent guarantee that the build inputs described in the Nix expressions were actually used to build what’s in the cache.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Trustix&lt;/h2&gt;
&lt;p&gt;Trustix aims to solve these problems by assembling a mapping from build inputs to (hashes of) build outputs provided by many build machines.&lt;/p&gt;
&lt;p&gt;Instead of relying on verifying packages signatures, like the traditional Nix model does, Trustix only exposes packages that it considers trustworthy.
Concretely, Trustix is configured as a proxy for a binary cache, and hides the packages which are not trustworthy.
As far as Nix is concerned, the package not being trustworthy is exactly as if the package wasn’t stored in the binary cache to begin with.
If such a package is required, Nix will therefore build it from source.&lt;/p&gt;
&lt;p&gt;Trustix doesn’t define what a trustworthy package is.
What your Trustix considers trustworthy is up to you.
The rules for accepting packages are entirely configurable.
In fact, in the current prototype, there isn’t a default rule for packages to count as trustworthy: you need to configure trustworthiness yourself.&lt;/p&gt;
&lt;p&gt;With this in mind, let’s revisit the above issues&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In Trustix, if an entity is compromised, you can rely on all
other entities in the network to establish that a binary artefact is
trustworthy. Maybe a few hashes are wrong in the Trustix mapping,
but if an overwhelming majority of the outputs are the same, you can
trust that the corresponding artefact is indeed what you would have
built yourself.&lt;/p&gt;
&lt;p&gt;Therefore you never need to invalidate an entire binary cache: you
can still verify the trustworthiness of old packages, even if newer
packages are built by a malicious actor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In Trustix, you never typically consider any build machine to be
fully trusted. You always check their results against the other
build machines. You can further configure this by considering some
machines as more trusted (maybe because it is a community-operated
machine, and you trust said community) or less trusted (for instance,
because it has been compromised in the past, and you fear it may be
compromised again).&lt;/p&gt;
&lt;p&gt;Moreover, in the spirit of having no single point of failure,
Trustix’s mapping is not kept in a central database. Instead every
builder keeps a log of its builds; these logs are aggregated on your
machine by your instance of the Trustix daemon. Therefore even the
mapping itself doesn’t have to be fully trusted.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;In Trustix, package validity is not ensured by a signature scheme.
Instead Trustix relies on the consistency of the input to output
mapping. As a consequence, the validity criterion, contrary to a
signature scheme, links the output to the input. It makes it
infeasible to pass the build result of input &lt;code class=&quot;language-text&quot;&gt;I&lt;/code&gt; as a build result for
input &lt;code class=&quot;language-text&quot;&gt;J&lt;/code&gt;: it would require corrupting the entire network.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Limitations: reproducibility tracking and non-reproducible builds&lt;/h2&gt;
&lt;p&gt;A system like Trustix will not work well with builds that are non-reproducible, which is a limitation of this model.
After all, you cannot reach consensus if everyone’s opinions differ.&lt;/p&gt;
&lt;p&gt;However, Trustix can still be useful, even for non-reproducible builds!
By accumulating all the data in the various logs and aggregating them, we can track which derivations are non-reproducible over all of Nixpkgs, in a way that is easier than previously possible.
Whereas the &lt;a href=&quot;https://r13y.com/&quot;&gt;r13y project&lt;/a&gt; builds a single closure
on a single machine, Trustix will index &lt;em&gt;everything ever built&lt;/em&gt; on every
architecture.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I am very excited to be working on the next generation of tooling for trust and reproducibility, and for the purely functional software packaging model pioneered by Nix to keep enabling new use cases.
I hope that this work can be a foundation for many other applications other than improving trust — for example, by enabling the Nix community to support new CPU architectures with community binary caches.&lt;/p&gt;
&lt;p&gt;Please check out the code at the &lt;a href=&quot;https://github.com/tweag/trustix&quot;&gt;repo&lt;/a&gt; or join us for a chat over in &lt;code class=&quot;language-text&quot;&gt;#untrustix&lt;/code&gt; on &lt;a href=&quot;https://webchat.freenode.net/&quot;&gt;Freenode&lt;/a&gt;.
And stay tuned — in the next blog post, we will talk more about Merkle trees and how they are used in Trustix.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://nlnet.nl/&quot;&gt;&lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;display: block; margin-left: auto; margin-right: auto;&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;display: block;&quot;&gt;&lt;/span&gt;
  &lt;img alt=&quot;NLNet&quot; class=&quot;gatsby-resp-image-image&quot; src=&quot;https://www.tweag.io/static/efbf832b18623ce0246865138f7e61e9/fc2a6/nlnet-banner.png&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle;&quot; title=&quot;NLNet&quot; /&gt;
    &lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://nlnet.nl/NGI0&quot;&gt;&lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;display: block; margin-left: auto; margin-right: auto;&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;display: block;&quot;&gt;&lt;/span&gt;
  &lt;img alt=&quot;NGI0&quot; class=&quot;gatsby-resp-image-image&quot; src=&quot;https://www.tweag.io/static/b817c1323bb0eb39e2cace92a3e9a410/9b7bd/NGI0_tag.png&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle;&quot; title=&quot;NGI0&quot; /&gt;
    &lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description>
	<pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Sander van der Burg: Constructing a simple alerting system with well-known open source projects</title>
	<guid isPermaLink="false">tag:blogger.com,1999:blog-1397115249631682228.post-4494119753037170735</guid>
	<link>http://sandervanderburg.blogspot.com/2020/11/constructing-simple-alerting-system.html</link>
	<description>&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-wzgx4PBmw8o/X7qaNhtolbI/AAAAAAAAK8o/GaTnTpQwqwIV6IH3pqJRKNh6tFa33mSHQCLcBGAsYHQ/s0/alertingexperiment.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-wzgx4PBmw8o/X7qaNhtolbI/AAAAAAAAK8o/GaTnTpQwqwIV6IH3pqJRKNh6tFa33mSHQCLcBGAsYHQ/s0/alertingexperiment.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Some time ago, I have been experimenting with all kinds of monitoring and alerting technologies. For example, with the following technologies, I can develop a simple alerting system with relative ease:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/time-series-platform/telegraf/&quot;&gt;Telegraf&lt;/a&gt; is an agent that can be used to gather measurements and transfer the corresponding data to all kinds of storage solutions.&lt;/li&gt;  &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/&quot;&gt;InfluxDB&lt;/a&gt; is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_series_database&quot;&gt;time series&lt;/a&gt; database platform that can store, manage and analyze timestamped data.&lt;/li&gt;  &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/time-series-platform/kapacitor/&quot;&gt;Kapacitor&lt;/a&gt; is a real-time streaming data process engine, that can be used for a variety of purposes. I can use Kapacitor to analyze measurements and see if a threshold has been exceeded so that an alert can be triggered.&lt;/li&gt;  &lt;li&gt;&lt;a href=&quot;https://alerta.io&quot;&gt;Alerta&lt;/a&gt; is a monitoring system that can store, de-duplicate alerts, and arrange black outs.&lt;/li&gt;  &lt;li&gt;&lt;a href=&quot;https://grafana.com&quot;&gt;Grafana&lt;/a&gt; is a multi-platform open source analytics and interactive visualization web application.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;These technologies appear to be quite straight forward to use. However, as I was learning more about them, I discovered a number of oddities, that may have big implications.&lt;br /&gt;&lt;br /&gt;Furthermore, testing and making incremental changes also turns out to be much more challenging than expected, making it very hard to diagnose and fix problems.&lt;br /&gt;&lt;br /&gt;In this blog post, I will describe how I built a simple monitoring and alerting system, and elaborate about my learning experiences.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Building the alerting system&lt;/h2&gt;&lt;br /&gt;As described in the introduction, I can combine several technologies to create an alerting system. I will explain them more in detail in the upcoming sections.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Telegraf&lt;/h3&gt;&lt;br /&gt;Telegraf is a pluggable agent that gathers measurements from a variety of &lt;strong&gt;inputs&lt;/strong&gt; (such as system metrics, platform metrics, database metrics etc.) and sends them to a variety of &lt;strong&gt;outputs&lt;/strong&gt;, typically storage solutions (database management systems such as InfluxDB, PostgreSQL or MongoDB). Telegraf has a large &lt;a href=&quot;https://docs.influxdata.com/telegraf/v1.14/plugins/plugin-list/&quot;&gt;plugin eco-system&lt;/a&gt; that provides all kinds integrations.&lt;br /&gt;&lt;br /&gt;In this blog post, I will use InfluxDB as an output storage backend. For the inputs, I will restrict myself to capturing a sub set of system metrics only.&lt;br /&gt;&lt;br /&gt;With the following &lt;i&gt;telegraf.conf&lt;/i&gt; configuration file, I can capture a variety of system metrics every 10 seconds:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;[agent]&lt;br /&gt;  interval = &quot;10s&quot;&lt;br /&gt;&lt;br /&gt;[[outputs.influxdb]]&lt;br /&gt;  urls = [ &quot;http://test1:8086&quot; ]&lt;br /&gt;  database = &quot;sysmetricsdb&quot;&lt;br /&gt;  username = &quot;sysmetricsdb&quot;&lt;br /&gt;  password = &quot;sysmetricsdb&quot;&lt;br /&gt;&lt;br /&gt;[[inputs.system]]&lt;br /&gt;  # no configuration&lt;br /&gt;&lt;br /&gt;[[inputs.cpu]]&lt;br /&gt;  ## Whether to report per-cpu stats or not&lt;br /&gt;  percpu = true&lt;br /&gt;  ## Whether to report total system cpu stats or not&lt;br /&gt;  totalcpu = true&lt;br /&gt;  ## If true, collect raw CPU time metrics.&lt;br /&gt;  collect_cpu_time = false&lt;br /&gt;  ## If true, compute and report the sum of all non-idle CPU states.&lt;br /&gt;  report_active = true&lt;br /&gt;&lt;br /&gt;[[inputs.mem]]&lt;br /&gt;  # no configuration&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With the above configuration file, I can collect the following metrics:&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;System metrics, such as the hostname and system load.&lt;/li&gt;  &lt;li&gt;CPU metrics, such as how much the CPU cores on a machine are utilized, including the total CPU activity.&lt;/li&gt;  &lt;li&gt;Memory (RAM) metrics.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;The data will be stored in an InfluxDB database name: &lt;i&gt;sysmetricsdb&lt;/i&gt; hosted on a remote machine with host name: &lt;i&gt;test1&lt;/i&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;InfluxDB&lt;/h3&gt;&lt;br /&gt;As explained earlier, InfluxDB is a timeseries platform that can store, manage and analyze timestamped data. In many ways, InfluxDB resembles relational databases, but there are also some notable differences.&lt;br /&gt;&lt;br /&gt;The query language that InfluxDB uses is called &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/query_language/&quot;&gt;InfluxQL&lt;/a&gt; (that shares many similarities with SQL).&lt;br /&gt;&lt;br /&gt;For example, with the following query I can retrieve the first three data points from the &lt;i&gt;cpu&lt;/i&gt; measurement, that contains the CPU-related measurements collected by Telegraf:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt; precision rfc3339&lt;br /&gt;&amp;gt; select * from &quot;cpu&quot; limit 3&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;providing me the following result set:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;name: cpu&lt;br /&gt;time                 cpu       host  usage_active       usage_guest usage_guest_nice usage_idle        usage_iowait        usage_irq usage_nice usage_softirq       usage_steal usage_system      usage_user&lt;br /&gt;----                 ---       ----  ------------       ----------- ---------------- ----------        ------------        --------- ---------- -------------       ----------- ------------      ----------&lt;br /&gt;2020-11-16T15:36:00Z cpu-total test2 10.665258711721098 0           0                89.3347412882789  0.10559662090813073 0         0          0.10559662090813073 0           8.658922914466714 1.79514255543822&lt;br /&gt;2020-11-16T15:36:00Z cpu0      test2 10.665258711721098 0           0                89.3347412882789  0.10559662090813073 0         0          0.10559662090813073 0           8.658922914466714 1.79514255543822&lt;br /&gt;2020-11-16T15:36:10Z cpu-total test2 0.1055966209080346 0           0                99.89440337909197 0                   0         0          0.10559662090813073 0           0                 0&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;As you may probably notice by looking at the output above, every data point has a timestamp and a number of fields capturing CPU metrics:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;&lt;i&gt;cpu&lt;/i&gt; identifies the CPU core.&lt;/li&gt;  &lt;li&gt;&lt;i&gt;host&lt;/i&gt; contains the host name of the machine.&lt;/li&gt;  &lt;li&gt;The remainder of the fields contain all kinds of CPU metrics, e.g. how much CPU time is consumed by the system (&lt;i&gt;usage_system&lt;/i&gt;), the user (&lt;i&gt;usage_user&lt;/i&gt;), by waiting for IO (&lt;i&gt;usage_iowait&lt;/i&gt;) etc.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;usage_active&lt;/i&gt; field contains the total CPU activity percentage, which is going to be useful to develop an alert that will warn us if there is too much CPU activity for a long period of time.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Aside from the fact that all data is timestamp based, data in InfluxDB has another notable difference compared to relational databases: an InfluxDB database is &lt;strong&gt;schemaless&lt;/strong&gt;. You can add an arbitrary number of fields and tags to a data point without having to adjust the database structure (and migrating existing data to the new database structure).&lt;br /&gt;&lt;br /&gt;Fields and tags can contain arbitrary data, such as numeric values or strings. Tags are also &lt;strong&gt;indexed&lt;/strong&gt; so that you can search for these values more efficiently. Furthermore, tags can be used to group data.&lt;br /&gt;&lt;br /&gt;For example, the &lt;i&gt;cpu&lt;/i&gt; measurement collection has the following tags:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;&amp;gt; SHOW TAG KEYS ON &quot;sysmetricsdb&quot; FROM &quot;cpu&quot;;&lt;br /&gt;name: cpu&lt;br /&gt;tagKey&lt;br /&gt;------&lt;br /&gt;cpu&lt;br /&gt;host&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;As shown in the above output, the &lt;i&gt;cpu&lt;/i&gt; and &lt;i&gt;host&lt;/i&gt; fields are tags in the &lt;i&gt;cpu&lt;/i&gt; measurement.&lt;br /&gt;&lt;br /&gt;We can use these tags to search for all data points related to a CPU core and/or host machine. Moreover, we can use these tags for grouping allowing us to compute aggregate values, sch as the mean value per CPU core and host.&lt;br /&gt;&lt;br /&gt;Beyond storing and retrieving data, InfluxDB has many useful additional features:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;You can also automatically &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/query_language/sample-data/&quot;&gt;&lt;strong&gt;sample&lt;/strong&gt; data&lt;/a&gt; and run &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/query_language/continuous_queries/&quot;&gt;&lt;strong&gt;continuous queries&lt;/strong&gt;&lt;/a&gt; that generate and store sampled data in the background.&lt;/li&gt;  &lt;li&gt;Configure &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.8/guides/downsample_and_retain/&quot;&gt;&lt;strong&gt;retention policies&lt;/strong&gt;&lt;/a&gt; so that data is no longer stored for an indefinite amount of time. For example, you can configure a retention policy to drop raw data after a certain amount of time, but retain the corresponding sampled data.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;InfluxDB has a &quot;open core&quot; development model. The free and open source edition (FOSS) of InfluxDB server (that is &lt;a href=&quot;https://opensource.org/licenses/MIT&quot;&gt;MIT licensed&lt;/a&gt;) allows you to host multiple databases on a multiple servers.&lt;br /&gt;&lt;br /&gt;However, if you also want &lt;strong&gt;horizontal scalability&lt;/strong&gt; and/or &lt;strong&gt;high assurance&lt;/strong&gt;, then you need to switch to the hosted InfluxDB versions -- data in InfluxDB is partitioned into so-called &lt;strong&gt;shards&lt;/strong&gt; of a fixed size (the default shard size is 168 hours).&lt;br /&gt;&lt;br /&gt;These shards can be distributed over multiple InfluxDB servers. It is also possible to deploy multiple &lt;strong&gt;read replicas&lt;/strong&gt; of the same shard to multiple InfluxDB servers improving read speed.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Kapacitor&lt;/h3&gt;&lt;br /&gt;Kapacitor is a real-time streaming data process engine developed by InfluxData -- the same company that also develops InfluxDB and Telegraf.&lt;br /&gt;&lt;br /&gt;It can be used for all kinds of purposes. In my example cases, I will only use it to determine whether some threshold has been exceeded and an alert needs to be triggered.&lt;br /&gt;&lt;br /&gt;Kapacitor works with customly implemented &lt;strong&gt;tasks&lt;/strong&gt; that are written in a domain-specific language called the &lt;a href=&quot;https://docs.influxdata.com/kapacitor/v1.5/tick/introduction/&quot;&gt;TICK script language&lt;/a&gt;. There are two kinds of tasks: &lt;strong&gt;stream&lt;/strong&gt; and &lt;strong&gt;batch&lt;/strong&gt; tasks. &lt;a href=&quot;https://www.influxdata.com/blog/batch-processing-vs-stream-processing/&quot;&gt;Both task types have advantages and disadvantages&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;We can easily develop an alert that gets triggered if the CPU activity level is high for a relatively long period of time (more than 75% on average over 1 minute).&lt;br /&gt;&lt;br /&gt;To implement this alert as a stream job, we can write the following TICK script:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;dbrp &quot;sysmetricsdb&quot;.&quot;autogen&quot;&lt;br /&gt;&lt;br /&gt;stream&lt;br /&gt;    |from()&lt;br /&gt;        .measurement('cpu')&lt;br /&gt;        .groupBy('host', 'cpu')&lt;br /&gt;        .where(lambda: &quot;cpu&quot; != 'cpu-total')&lt;br /&gt;    |window()&lt;br /&gt;        .period(1m)&lt;br /&gt;        .every(1m)&lt;br /&gt;    |mean('usage_active')&lt;br /&gt;    |alert()&lt;br /&gt;        .message('Host: {{ index .Tags &quot;host&quot; }} has high cpu usage: {{ index .Fields &quot;mean&quot; }}')&lt;br /&gt;        .warn(lambda: &quot;mean&quot; &amp;gt; 75.0)&lt;br /&gt;        .crit(lambda: &quot;mean&quot; &amp;gt; 85.0)&lt;br /&gt;        .alerta()&lt;br /&gt;            .resource('{{ index .Tags &quot;host&quot; }}/{{ index .Tags &quot;cpu&quot; }}')&lt;br /&gt;            .event('cpu overload')&lt;br /&gt;            .value('{{ index .Fields &quot;mean&quot; }}')&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;A stream job is built around the following principles:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;A stream task does not execute queries on an InfluxDB server. Instead, it creates a &lt;strong&gt;subscription&lt;/strong&gt; to InfluxDB -- whenever a data point gets inserted into InfluxDB, the data points gets forwarded to Kapacitor as well.&lt;br /&gt;    &lt;br /&gt;    To make subscriptions work, both InfluxDB and Kapacitor need to be able to connect to each other with a public IP address.&lt;/li&gt;  &lt;li&gt;A stream task defines a &lt;strong&gt;pipeline&lt;/strong&gt; consisting of a number of &lt;strong&gt;nodes&lt;/strong&gt; (connected with the &lt;i&gt;|&lt;/i&gt; operator). Each node can &lt;strong&gt;consume&lt;/strong&gt; data points, filter, transform, aggregate, or execute arbitrary operations (such as calling an external service), and &lt;strong&gt;produce&lt;/strong&gt; new data points that can be propagated to the next node in the pipeline.&lt;/li&gt;  &lt;li&gt;Every node also has &lt;strong&gt;property methods&lt;/strong&gt; (such as &lt;i&gt;.measurement('cpu')&lt;/i&gt;) making it possible to configure parameters.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;The TICK script example shown above does the following:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The &lt;i&gt;from&lt;/i&gt; node consumes &lt;i&gt;cpu&lt;/i&gt; data points from the InfluxDB subscription, groups them by &lt;i&gt;host&lt;/i&gt; and &lt;i&gt;cpu&lt;/i&gt; and filters out data points with the the &lt;i&gt;cpu-total&lt;/i&gt; label, because we are only interested in the CPU consumption per core, not the total amount.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;window&lt;/i&gt; node states that we should aggregate data points over the last 1 minute and pass the resulting (aggregated) data points to the next node after one minute in time has elapsed. To aggregate data, Kapacitor will buffer data points in memory.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;mean&lt;/i&gt; node computes the mean value for &lt;i&gt;usage_active&lt;/i&gt; for the aggregated data points.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;alert&lt;/i&gt; node is used to trigger an alert of a specific severity level (WARNING if the mean activity percentage is bigger than 75%) and (CRITICAL if the mean activity percentage is bigger than 85%). In the remainder of the case, the status is considered OK. The alert is sent to Alerta.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;It is also possible to write a similar kind of alerting script as a batch task:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;dbrp &quot;sysmetricsdb&quot;.&quot;autogen&quot;&lt;br /&gt;&lt;br /&gt;batch&lt;br /&gt;    |query('''&lt;br /&gt;        SELECT mean(&quot;usage_active&quot;)&lt;br /&gt;        FROM &quot;sysmetricsdb&quot;.&quot;autogen&quot;.&quot;cpu&quot;&lt;br /&gt;        WHERE &quot;cpu&quot; != 'cpu-total'&lt;br /&gt;    ''')&lt;br /&gt;        .period(1m)&lt;br /&gt;        .every(1m)&lt;br /&gt;        .groupBy('host', 'cpu')&lt;br /&gt;    |alert()&lt;br /&gt;        .message('Host: {{ index .Tags &quot;host&quot; }} has high cpu usage: {{ index .Fields &quot;mean&quot; }}')&lt;br /&gt;        .warn(lambda: &quot;mean&quot; &amp;gt; 75.0)&lt;br /&gt;        .crit(lambda: &quot;mean&quot; &amp;gt; 85.0)&lt;br /&gt;        .alerta()&lt;br /&gt;            .resource('{{ index .Tags &quot;host&quot; }}/{{ index .Tags &quot;cpu&quot; }}')&lt;br /&gt;            .event('cpu overload')&lt;br /&gt;            .value('{{ index .Fields &quot;mean&quot; }}')&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above TICK script looks similar to the stream task shown earlier, but instead of using a subscription, the script queries the InfluxDB database (with an InfluxQL query) for data points over the last minute with a &lt;i&gt;query&lt;/i&gt; node.&lt;br /&gt;&lt;br /&gt;Which approach for writing a CPU alert is best, you may wonder? Each of these two approaches have their pros and cons:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;Stream tasks offer &lt;strong&gt;low latency&lt;/strong&gt; responses -- when a data point appears, a stream task can immediately respond, whereas a batch task needs to query every minute all the data points to compute the mean percentage over the last minute.&lt;/li&gt;  &lt;li&gt;Stream tasks maintain a buffer for aggregating the data points making it possible to only send &lt;strong&gt;incremental&lt;/strong&gt; updates to Alerta. Batch tasks are stateless. As a result, they need to update the status of all hosts and CPUs every minute.&lt;/li&gt;  &lt;li&gt;Processing data points is done synchronously and in sequential order -- if an update round to Alerta takes too long (which is more likely to happen with a batch task), then the next processing run may overlap with the previous, causing all kinds of unpredictable results.&lt;br /&gt;    &lt;br /&gt;    It may also cause Kapacitor to eventually crash due to growing resource consumption.&lt;/li&gt;  &lt;li&gt;Batch tasks may also &lt;strong&gt;miss&lt;/strong&gt; data points -- while querying data over a certain time window, it may happen that a new data point gets inserted in that time window (that is being queried). This new data point will not be picked up by Kapacitor.&lt;br /&gt;    &lt;br /&gt;    A subscription made by a stream task, however, will never miss any data points.&lt;/li&gt;  &lt;li&gt;Stream tasks can only work with data points that appear from the moment Kapacitor is started -- it &lt;strong&gt;cannot work&lt;/strong&gt; with data points in the &lt;strong&gt;past&lt;/strong&gt;.&lt;br /&gt;    &lt;br /&gt;    For example, if Kapacitor is restarted and some important event is triggered in the restart time window, Kapacitor will not notice that event, causing the alert to remain in its previous state.&lt;br /&gt;    &lt;br /&gt;    To work effectively with stream tasks, a &lt;strong&gt;continuous&lt;/strong&gt; data stream is required that frequently reports on the status of a resource. Batch tasks, on the other hand, can work with historical data.&lt;/li&gt;  &lt;li&gt;The fact that nodes maintain a buffer may also cause the &lt;strong&gt;RAM consumption&lt;/strong&gt; of Kapacitor to grow considerably, if the data volumes are big.&lt;br /&gt;    &lt;br /&gt;    A batch task on the other hand, does not buffer any data and is more memory efficient.&lt;br /&gt;    &lt;br /&gt;    Another compelling advantage of batch tasks over stream tasks is that InfluxDB does all the work. The hosted version of InfluxDB can also horizontally scale.&lt;/li&gt;  &lt;li&gt;Batch tasks can also &lt;strong&gt;aggregate&lt;/strong&gt; data more efficiently (e.g. computing the mean value or sum of values over a certain time period).&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;I consider neither of these script types the optimal solution. However, for implementing the alerts I tend to have a slight preference for stream jobs, because of its low latency, and incremental update properties.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Alerta&lt;/h3&gt;&lt;br /&gt;As explained in the introduction, Alerta is a monitoring system that can store and de-duplicate alerts, and arrange black outs.&lt;br /&gt;&lt;br /&gt;The Alerta server provides a REST API that can be used to query and modify alerting data and uses MongoDB or PostgreSQL as a storage database.&lt;br /&gt;&lt;br /&gt;There are also a variety of Alerta clients: there is the &lt;i&gt;alerta-cli&lt;/i&gt; allows you to control the service from the command-line. There is also a web user interface that I will show later in this blog post.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Running experiments&lt;/h2&gt;&lt;br /&gt;With all the components described above in place, we can start running experiments to see if the CPU alert will work as expected. To gain better insights in the process, I can install Grafana that allows me to visualize the measurements that are stored in InfluxDB.&lt;br /&gt;&lt;br /&gt;Configuring a dashboard and panel for visualizing the CPU activity rate was straight forward. I configured a new dashboard, with the following variables:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-OI_oK-F6Ssw/X7qOAHzov2I/AAAAAAAAK70/Sr45f8w_y54TJYJSpXyVuERJ5YxwOdPOwCLcBGAsYHQ/s0/variables.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-OI_oK-F6Ssw/X7qOAHzov2I/AAAAAAAAK70/Sr45f8w_y54TJYJSpXyVuERJ5YxwOdPOwCLcBGAsYHQ/s0/variables.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;The above variables allow me to select for each machine in the network, which CPU core's activity percentage I want to visualize.&lt;br /&gt;&lt;br /&gt;I have configured the CPU panel as follows:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-gCFtPGKnpO0/X7qOh5GNpNI/AAAAAAAAK78/kPTUis2B9fsUEPKPEek47v2gWbGM7zm2gCLcBGAsYHQ/s0/panelconfig.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-gCFtPGKnpO0/X7qOh5GNpNI/AAAAAAAAK78/kPTUis2B9fsUEPKPEek47v2gWbGM7zm2gCLcBGAsYHQ/s0/panelconfig.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;In the above configuration, I query the &lt;i&gt;usage_activity&lt;/i&gt; from the &lt;i&gt;cpu&lt;/i&gt; measurement collection, using the dashboard variables: &lt;i&gt;cpu&lt;/i&gt; and &lt;i&gt;host&lt;/i&gt; to filter for the right target machine and CPU core.&lt;br /&gt;&lt;br /&gt;I have also configured the field unit to be a percentage value (between 0 and 100).&lt;br /&gt;&lt;br /&gt;When running the following command-line instruction on a test machine that runs Telegraf (&lt;i&gt;test2&lt;/i&gt;), &lt;a href=&quot;https://stackoverflow.com/questions/2925606/how-to-create-a-cpu-spike-with-a-bash-command&quot;&gt;I can deliberately hog the CPU&lt;/a&gt;:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ dd if=/dev/zero of=/dev/null&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above command reads zero bytes (one-by-one) and discards them by sending them to &lt;i&gt;/dev/null&lt;/i&gt;, causing the CPU to remain utilized at a high level:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-BD7i2SDkQ5E/X7qRKdrRGQI/AAAAAAAAK8I/Ln-YzVHdJq09aB19gwaMWfsZKhh_6O40QCLcBGAsYHQ/s0/hogcpu.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BD7i2SDkQ5E/X7qRKdrRGQI/AAAAAAAAK8I/Ln-YzVHdJq09aB19gwaMWfsZKhh_6O40QCLcBGAsYHQ/s0/hogcpu.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;In the graph shown above, it is clearly visible that CPU core 0 on the &lt;i&gt;test2&lt;/i&gt; machine remains utilized at 100% for several minutes.&lt;br /&gt;&lt;br /&gt;(As a sidenote, we can also &lt;a href=&quot;https://stackoverflow.com/questions/20200982/how-to-generate-a-memory-shortage-using-bash-script/34755981&quot;&gt;hog both the CPU and consume RAM at the same time&lt;/a&gt; with a simple command line instruction).&lt;br /&gt;&lt;br /&gt;If we keep hogging the CPU and wait for at least a minute, the Alerta web interface dashboard will show a CRITICAL alert:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-1NXCeS1q1gc/X7qRm_4UYzI/AAAAAAAAK8Q/qKqJZBYJsdMDHj6C70zZphyIncLxLeMuwCLcBGAsYHQ/s0/criticalalert.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-1NXCeS1q1gc/X7qRm_4UYzI/AAAAAAAAK8Q/qKqJZBYJsdMDHj6C70zZphyIncLxLeMuwCLcBGAsYHQ/s0/criticalalert.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;If we stop the &lt;i&gt;dd&lt;/i&gt; command, then the TICK script should eventually notice that the mean percentage drops below the WARNING threshold causing the alert to go back into the &lt;i&gt;OK&lt;/i&gt; state and disappearing from the Alerta dashboard.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Developing test cases&lt;/h2&gt;&lt;br /&gt;Being able to trigger an alert with a simple command-line instruction is useful, but not always convenient or effective -- one of the inconveniences is that we always have to wait at least one minute to get feedback.&lt;br /&gt;&lt;br /&gt;Moreover, when an alert does not work, it is not always easy to find the root cause. I have encountered the following problems that contribute to a failing alert:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;Telegraf may not be running and, as a result, not capturing the data points that need to be analyzed by the TICK script.&lt;/li&gt;  &lt;li&gt;A subscription cannot be established between InfluxDB and Kapacitor. This may happen when Kapacitor cannot be reached through a public IP address.&lt;/li&gt;  &lt;li&gt;There are data points collected, but only the wrong kinds of measurements.&lt;/li&gt;  &lt;li&gt;The TICK script is functionally incorrect.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Fortunately, for stream tasks it is relatively easy to quickly find out whether an alert is functionally correct or not -- we can generate test cases that almost instantly trigger each possible outcome with a minimal amount of data points.&lt;br /&gt;&lt;br /&gt;An interesting property of stream tasks is that they have no notion of time -- the &lt;i&gt;.window(1m)&lt;/i&gt; property may suggest that Kapacitor computes the mean value of the data points every minute, but that is not what it actually does. Instead, Kapacitor only looks at the timestamps of the data points that it receives.&lt;br /&gt;&lt;br /&gt;When Kapacitor sees that the timestamps of the data points fit in the 1 minute time window, then it keeps buffering. As soon as a data point appears that is outside this time window, the &lt;i&gt;window&lt;/i&gt; node relays an aggregated data point to the next node (that computes the mean value, than in turn is consumed by the alert node deciding whether an alert needs to be raised or not).&lt;br /&gt;&lt;br /&gt;We can exploit that knowledge, to create a very minimal bash test script that triggers every possible outcome: OK, WARNING and CRITICAL:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;font-size: 90%; overflow: auto;&quot;&gt;&lt;br /&gt;influxCmd=&quot;influx -database sysmetricsdb -host test1&quot;&lt;br /&gt;&lt;br /&gt;export ALERTA_ENDPOINT=&quot;http://test1&quot;&lt;br /&gt;&lt;br /&gt;### Trigger CRITICAL alert&lt;br /&gt;&lt;br /&gt;# Force the average CPU consumption to be 100%&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=100   0000000000&quot;&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=100  60000000000&quot;&lt;br /&gt;# This data point triggers the alert&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=100 120000000000&quot;&lt;br /&gt;&lt;br /&gt;sleep 1&lt;br /&gt;actualSeverity=$(alerta --output json query | jq '.[0].severity')&lt;br /&gt;&lt;br /&gt;if [ &quot;$actualSeverity&quot; != &quot;critical&quot; ]&lt;br /&gt;then&lt;br /&gt;     echo &quot;Expected severity: critical, but we got: $actualSeverity&quot; &amp;gt;&amp;amp;2&lt;br /&gt;     false&lt;br /&gt;fi&lt;br /&gt;      &lt;br /&gt;### Trigger WARNING alert&lt;br /&gt;&lt;br /&gt;# Force the average CPU consumption to be 80%&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=80 180000000000&quot;&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=80 240000000000&quot;&lt;br /&gt;# This data point triggers the alert&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=80 300000000000&quot;&lt;br /&gt;&lt;br /&gt;sleep 1&lt;br /&gt;actualSeverity=$(alerta --output json query | jq '.[0].severity')&lt;br /&gt;&lt;br /&gt;if [ &quot;$actualSeverity&quot; != &quot;warning&quot; ]&lt;br /&gt;then&lt;br /&gt;     echo &quot;Expected severity: warning, but we got: $actualSeverity&quot; &amp;gt;&amp;amp;2&lt;br /&gt;     false&lt;br /&gt;fi&lt;br /&gt;&lt;br /&gt;### Trigger OK alert&lt;br /&gt;&lt;br /&gt;# Force the average CPU consumption to be 0%&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=0 300000000000&quot;&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=0 360000000000&quot;&lt;br /&gt;# This data point triggers the alert&lt;br /&gt;$influxCmd -execute &quot;INSERT cpu,cpu=cpu0,host=test2 usage_active=0 420000000000&quot;&lt;br /&gt;&lt;br /&gt;sleep 1&lt;br /&gt;actualSeverity=$(alerta --output json query | jq '.[0].severity')&lt;br /&gt;&lt;br /&gt;if [ &quot;$actualSeverity&quot; != &quot;ok&quot; ]&lt;br /&gt;then&lt;br /&gt;     echo &quot;Expected severity: ok, but we got: $actualSeverity&quot; &amp;gt;&amp;amp;2&lt;br /&gt;     false&lt;br /&gt;fi&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The shell script shown above automatically triggers all three possible outcomes of the CPU alert:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;CRITICAL is triggered by generating data points that force a mean activity percentage of 100%.&lt;/li&gt;  &lt;li&gt;WARNING is triggered by a mean activity percentage of 80%.&lt;/li&gt;  &lt;li&gt;OK is triggered by a mean activity percentage of 0%.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;It uses the Alerta CLI to connect to the Alerta server to check whether the alert's severity level has the expected value.&lt;br /&gt;&lt;br /&gt;We need three data points to trigger each alert type -- the first two data points are on the boundaries of the 1 minute window (0 seconds and 60 seconds), forcing the mean value to become the specified CPU activity percentage.&lt;br /&gt;&lt;br /&gt;The third data point is deliberately outside the time window (of 1 minute), forcing the alert node to be triggered with a mean value over the previous two data points.&lt;br /&gt;&lt;br /&gt;Although the above test strategy works to quickly validate all possible outcomes, one impractical aspect is that the timestamps in the above example start with 0 (meaning 0 seconds after the epoch: January 1st 1970 00:00 UTC).&lt;br /&gt;&lt;br /&gt;If we also want to observe the data points generated by the above script in Grafana, we need to configure the panel to go back in time 50 years.&lt;br /&gt;&lt;br /&gt;Fortunately, I can also easily adjust the script to start with a base timestamp, that is 1 hour in the past:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;offset=&quot;$(($(date +%s) - 3600))&quot;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With this tiny adjustment, we should see the following CPU graph (displaying data points from the last hour) after running the test script:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-t3M4esdM-Z0/X7qU-Yd1vQI/AAAAAAAAK8c/4scLqSS2TmYkyw62P54mLMUP3VDJM97_wCLcBGAsYHQ/s0/testcpugraph.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-t3M4esdM-Z0/X7qU-Yd1vQI/AAAAAAAAK8c/4scLqSS2TmYkyw62P54mLMUP3VDJM97_wCLcBGAsYHQ/s0/testcpugraph.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;As you may notice, we can see that the CPU activity level quickly goes from 100%, to 80%, to 0%, using only 9 data points.&lt;br /&gt;&lt;br /&gt;Although testing stream tasks (from a functional perspective) is quick and convenient, testing batch tasks in a similar way is difficult. Contrary to the stream task implementation, the &lt;i&gt;query&lt;/i&gt; node in the batch task does have a notion of time (because of the &lt;i&gt;WHERE&lt;/i&gt; clause that includes the &lt;i&gt;now()&lt;/i&gt; expression).&lt;br /&gt;&lt;br /&gt;Moreover, the embedded InfluxQL query evaluates the mean values every minute, but the test script does not exactly know when this event triggers.&lt;br /&gt;&lt;br /&gt;The only way I could think of to (somewhat reliably) validate the outcomes is by creating a test script that continuously inserts data points for at least double the time window size (2 minutes) until Alerta reports the right alert status (if it does not after a while, I can conclude that the alert is incorrectly implemented).&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Automating the deployment&lt;/h2&gt;&lt;br /&gt;As you may probably have already guessed, to be able to conveniently experiment with all these services, and to reliably run tests in isolation, some form of &lt;strong&gt;deployment automation&lt;/strong&gt; is an absolute must-have.&lt;br /&gt;&lt;br /&gt;Most people who do not know anything about my deployment technology preferences, will probably go for &lt;a href=&quot;https://docker.com&quot;&gt;Docker&lt;/a&gt; or &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;docker-compose&lt;/a&gt;, but I have decided to use a variety of solutions from the &lt;a href=&quot;https://nixos.org&quot;&gt;Nix project&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;https://sandervanderburg.blogspot.com/2015/03/on-nixops-disnix-service-deployment-and.html&quot;&gt;NixOps&lt;/a&gt; is used to automatically deploy a network of &lt;a href=&quot;https://sandervanderburg.blogspot.com/2011/01/nixos-purely-functional-linux.html&quot;&gt;NixOS&lt;/a&gt; machines -- I have created a logical and physical NixOps configuration that deploys two VirtualBox virtual machines.&lt;br /&gt;&lt;br /&gt;With the following command I can create and deploy the virtual machines:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nixops create network.nix network-virtualbox.nix -d test&lt;br /&gt;$ nixops deploy -d test&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The first machine: &lt;i&gt;test1&lt;/i&gt; is responsible for hosting the entire monitoring infrastructure (InfluxDB, Kapacitor, Alerta, Grafana), and the second machine (&lt;i&gt;test2&lt;/i&gt;) runs Telegraf and the load tests.&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;https://sandervanderburg.blogspot.com/2011/02/disnix-toolset-for-distributed.html&quot;&gt;Disnix&lt;/a&gt; (my own deployment tool) is responsible for deploying all services, such as InfluxDB, Kapacitor, Alarta, and the database storage backends. Contrary to docker-compose, Disnix does not work with containers (or other Docker objects, such as networks or volumes), but with arbitrary deployment units that are managed with a plugin system called &lt;a href=&quot;https://sandervanderburg.blogspot.com/2012/03/deployment-of-mutable-components.html&quot;&gt;Dysnomia&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Moreover, Disnix can also be used for distributed deployment in a network of machines.&lt;br /&gt;&lt;br /&gt;I have packaged all the services and captured them in a Disnix services model that specifies all deployable services, their types, and their inter-dependencies.&lt;br /&gt;&lt;br /&gt;If I combine the services model with the NixOps network models, and a distribution model (that maps Telegraf and the test scripts to the &lt;i&gt;test2&lt;/i&gt; machine and the remainder of the services to the first: &lt;i&gt;test1&lt;/i&gt;), I can deploy the entire system:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ export NIXOPS_DEPLOYMENT=test&lt;br /&gt;$ export NIXOPS_USE_NIXOPS=1&lt;br /&gt;&lt;br /&gt;$ disnixos-env -s services.nix \&lt;br /&gt;  -n network.nix \&lt;br /&gt;  -n network-virtualbox.nix \&lt;br /&gt;  -d distribution.nix&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The following diagram shows a possible deployment scenario of the system:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-msgwGl1X5Ew/X7qgRW1KUxI/AAAAAAAAK80/5YeTvSqj5XE21TmSUmH9e8OQ_vuPYwcEQCLcBGAsYHQ/s0/deploymentarch.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-msgwGl1X5Ew/X7qgRW1KUxI/AAAAAAAAK80/5YeTvSqj5XE21TmSUmH9e8OQ_vuPYwcEQCLcBGAsYHQ/s0/deploymentarch.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;The above diagram describes the following properties:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The light-grey colored boxes denote &lt;strong&gt;machines&lt;/strong&gt;. In the above diagram, we have two of them: &lt;i&gt;test1&lt;/i&gt; and &lt;i&gt;test2&lt;/i&gt; that correspond to the VirtualBox machines deployed by NixOps.&lt;/li&gt;  &lt;li&gt;The dark-grey colored boxes denote &lt;a href=&quot;https://sandervanderburg.blogspot.com/2016/05/mapping-services-to-containers-with.html&quot;&gt;&lt;strong&gt;containers&lt;/strong&gt; in a Disnix-context&lt;/a&gt; (not to be confused with Linux or Docker containers). These are environments that manage other services.&lt;br /&gt;    &lt;br /&gt;    For example, a container service could be the PostgreSQL DBMS managing a number of PostgreSQL databases or the Apache HTTP server managing web applications.&lt;/li&gt;  &lt;li&gt;The ovals denote &lt;strong&gt;services&lt;/strong&gt; that could be any kind of deployment unit. In the above example, we have services that are running processes (managed by systemd), databases and web applications.&lt;/li&gt;  &lt;li&gt;The arrows denote &lt;strong&gt;inter-dependencies&lt;/strong&gt; between services. When a service has an inter-dependency on another service (i.e. the arrow points from the former to the latter), then the latter service needs to be activated first. Moreover, the former service also needs to know how the latter can be reached.&lt;/li&gt;  &lt;li&gt;Services can also be &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/04/deploying-container-and-application.html&quot;&gt;&lt;strong&gt;container providers&lt;/strong&gt;&lt;/a&gt; (as denoted by the arrows in the labels), stating that other services can be embedded inside this service.&lt;br /&gt;    &lt;br /&gt;    As already explained, the PostgreSQL DBMS is an example of such a service, because it can host multiple PostgreSQL databases.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;Although the process components in the diagram above can also be conveniently deployed with Docker-based solutions (i.e. as I have explained in an earlier blog post, &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/07/on-using-nix-and-docker-as-deployment.html&quot;&gt;containers are somewhat confined and restricted processes&lt;/a&gt;), the non-process integrations need to be managed by other means, such as writing extra shell instructions in Dockerfiles.&lt;br /&gt;&lt;br /&gt;In addition to deploying the system to machines managed by NixOps, it is also possible to use the &lt;a href=&quot;https://sandervanderburg.blogspot.com/2011/02/using-nixos-for-declarative-deployment.html&quot;&gt;NixOS test driver&lt;/a&gt; -- the NixOS test driver automatically generates QEMU virtual machines with a shared Nix store, so that no disk images need to be created, making it possible to quickly spawn networks of virtual machines, with very small storage footprints.&lt;br /&gt;&lt;br /&gt;I can also create a minimal distribution model that only deploys the services required to run the test scripts -- Telegraf, Grafana and the front-end applications are not required, resulting in a much smaller deployment:&lt;br /&gt;&lt;br /&gt;&lt;div class=&quot;separator&quot; style=&quot;clear: both;&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-4MacumbX_Fc/X7qga1Xh-OI/AAAAAAAAK84/EFGw7HLktt4aaYFwkPjKLqLlfXDmQqOhwCLcBGAsYHQ/s0/deploymentarch-minimal.png&quot; style=&quot;display: block; padding: 1em 0; text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-4MacumbX_Fc/X7qga1Xh-OI/AAAAAAAAK84/EFGw7HLktt4aaYFwkPjKLqLlfXDmQqOhwCLcBGAsYHQ/s0/deploymentarch-minimal.png&quot; width=&quot;520&quot; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;As can be seen in the above diagram, there are far fewer components required.&lt;br /&gt;&lt;br /&gt;In this virtual network that runs a minimal system, we can run automated tests for rapid feedback. For example, the following test driver script (implemented in Python) will run my test shell script shown earlier:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;test2.succeed(&quot;test-cpu-alerts&quot;)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;With the following command I can automatically run the tests on the terminal:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-build release.nix -A tests&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;Availability&lt;/h2&gt;&lt;br /&gt;The deployment recipes, test scripts and documentation describing the configuration steps are stored in the &lt;a href=&quot;https://github.com/svanderburg/monitoring-playground&quot;&gt;monitoring playground repository&lt;/a&gt; that can be obtained from my GitHub page.&lt;br /&gt;&lt;br /&gt;Besides the CPU activity alert described in this blog post, I have also developed a memory alert that triggers if too much RAM is consumed for a longer period of time.&lt;br /&gt;&lt;br /&gt;In addition to virtual machines and services, there is also deployment automation in place allowing you also easily deploy Kapacitor TICK scripts and Grafana dashboards.&lt;br /&gt;&lt;br /&gt;To deploy the system, you need to use the very latest version of Disnix (version 0.10) that was released very recently.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Acknowledgements&lt;/h2&gt;&lt;br /&gt;I would like to thank my employer: &lt;a href=&quot;https://mendix.com&quot;&gt;Mendix&lt;/a&gt; for writing this blog post. Mendix allows developers to work two days per month on research projects, making projects like these possible.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Presentation&lt;/h2&gt;&lt;br /&gt;I have given a presentation about this subject at Mendix. For convienence, I have embedded the slides:&lt;br /&gt;&lt;br /&gt;  &lt;div style=&quot;margin-bottom: 5px;&quot;&gt; &lt;strong&gt; &lt;a href=&quot;http://www.slideshare.net/sandervanderburg/the-monitoring-playground&quot; target=&quot;_blank&quot; title=&quot;The Monitoring Playground&quot;&gt;The Monitoring Playground&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&quot;https://www.slideshare.net/sandervanderburg&quot; target=&quot;_blank&quot;&gt;Sander van der Burg&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;</description>
	<pubDate>Sun, 29 Nov 2020 20:57:00 +0000</pubDate>
	<author>noreply@blogger.com (Sander van der Burg)</author>
</item>
<item>
	<title>Tweag I/O: Self-references in a content-addressed Nix</title>
	<guid isPermaLink="true">https://tweag.io/blog/2020-11-18-nix-cas-self-references/</guid>
	<link>https://tweag.io/blog/2020-11-18-nix-cas-self-references/</link>
	<description>&lt;p&gt;In a &lt;a href=&quot;https://www.tweag.io/blog/2020-09-10-nix-cas/&quot;&gt;previous post&lt;/a&gt; I explained why we were eagerly trying to change the Nix store model to allow for content-addressed derivations.
I also handwaved that this was a real challenge, but without giving any hint at &lt;strong&gt;why&lt;/strong&gt; this could be tricky.
So let’s dive a bit into the gory details and understand some of the conceptual pain points with content-addressability in Nix, which forced us to some trade-offs in how we handle content-addressed paths.&lt;/p&gt;
&lt;h1&gt;What are self-references?&lt;/h1&gt;
&lt;p&gt;&lt;a name=&quot;self&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is a self-reference&lt;/p&gt;
&lt;p&gt;— &lt;cite&gt;Théophane Hufschmitt, &lt;a href=&quot;https://www.tweag.io/rss-nix.xml#self&quot;&gt;This very article&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A very trivial Nix derivation might look like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-nix&quot;&gt;&lt;code class=&quot;language-nix&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;nixpkgs&lt;span class=&quot;token operator&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
writeScript &lt;span class=&quot;token string&quot;&gt;&quot;hello&quot;&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;''
#!&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token antiquotation variable&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;bash&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;/bin/bash

${hello}/bin/hello
''&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The result of this derivation will be an executable file containing a script that will run the &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; program.
It will depend on the &lt;code class=&quot;language-text&quot;&gt;bash&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; derivations as we refer to them in the file.&lt;/p&gt;
&lt;p&gt;We can build this derivation and execute it:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-console&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ nix-build hello.nix
$ ./result
Hello, world!&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So far, so good.
Let’s now change our derivation to change the prompt of &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; to something more personalized:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-nix&quot;&gt;&lt;code class=&quot;language-nix&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;nixpkgs&lt;span class=&quot;token operator&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
writeScript &lt;span class=&quot;token string&quot;&gt;&quot;hello-its-me&quot;&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;''
#!&lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token antiquotation variable&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;bash&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;/bin/bash

echo &quot;Hello, world! This is &lt;span class=&quot;token interpolation&quot;&gt;&lt;span class=&quot;token antiquotation variable&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;placeholder &lt;span class=&quot;token string&quot;&gt;&quot;out&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&quot;
''&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;language-text&quot;&gt;${placeholder &quot;out&quot;}&lt;/code&gt; is a magic value that will be replaced by the output path of the derivation during the build.&lt;/p&gt;
&lt;p&gt;We can build this and run the result just fine&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-console&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ nix-build hello-its-me.nix
$ ./result
Hello, world! This is /nix/store/c0qw0gbp7rfyzm7x7ih279pmnzazg86p-hello-its-me&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And we can check that the file is indeed who it claims to be:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-console&quot;&gt;&lt;code class=&quot;language-console&quot;&gt;$ /nix/store/c0qw0gbp7rfyzm7x7ih279pmnzazg86p-hello-its-me
Hello, world! This is /nix/store/c0qw0gbp7rfyzm7x7ih279pmnzazg86p-hello-its-me&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While the &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt; derivation depends on &lt;code class=&quot;language-text&quot;&gt;bash&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;hello&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;hello-its-me&lt;/code&gt; depends on &lt;code class=&quot;language-text&quot;&gt;bash&lt;/code&gt; and… itself.
This is something rather common in Nix.
For example, it’s rather natural for a C program to have &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-foo/bin/foo&lt;/code&gt; depend of &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-foo/lib/libfoo.so&lt;/code&gt;.&lt;/p&gt;
&lt;h1&gt;Self references and content-addressed paths&lt;/h1&gt;
&lt;p&gt;How do we build a content-addressed derivation &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt; in Nix? The recipe is rather simple:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build the derivation in a temporary directory &lt;code class=&quot;language-text&quot;&gt;/some/where/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Compute the hash &lt;code class=&quot;language-text&quot;&gt;xxx&lt;/code&gt; of that &lt;code class=&quot;language-text&quot;&gt;/some/where/&lt;/code&gt; directory&lt;/li&gt;
&lt;li&gt;Move the directory under &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-foo/&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You might see where things will go wrong with self-references: the reference will point to &lt;code class=&quot;language-text&quot;&gt;/some/where&lt;/code&gt; rather than &lt;code class=&quot;language-text&quot;&gt;/nix/store/xxx-foo&lt;/code&gt;, and so will be wrong (in addition to leak a path to what should just be a temporary directory).&lt;/p&gt;
&lt;p&gt;To work around that, we would need to compute this &lt;code class=&quot;language-text&quot;&gt;xxx&lt;/code&gt; hash before the build, but that’s quite impossible as the hash depends on the content of the directory, including the value of the self-references.&lt;/p&gt;
&lt;p&gt;However, we can hack our way around it in most cases by allowing ourselves a bit of heuristic.
The only assumption that we need to make is that all the
self-references will appear textually (&lt;em&gt;i.e.&lt;/em&gt; running &lt;code class=&quot;language-text&quot;&gt;strings&lt;/code&gt; on a
file that contains self-references will print all the self-references out).&lt;/p&gt;
&lt;p&gt;Under that assumption, we can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build the derivation in our &lt;code class=&quot;language-text&quot;&gt;/some/where&lt;/code&gt; directory&lt;/li&gt;
&lt;li&gt;Replace all the occurrences of a self-reference by a magic value&lt;/li&gt;
&lt;li&gt;Compute the hash of the resulting path to determine the final path&lt;/li&gt;
&lt;li&gt;Replace all the occurrences of the magic value by the final path&lt;/li&gt;
&lt;li&gt;Move the resulting store path to its final path&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now you might think that this is a crazy hack − there’s so many ways it could break.
And in theory you’ll be right.
But, surprisingly, this works remarkably well in practice.
You might also notice that &lt;em&gt;pedantically speaking&lt;/em&gt; this scheme isn’t exactly content-addressing because of the “modulo the final hash” part.
But this is close-enough to keep all the desirable properties of proper content addressing, while also enabling self-references, which wouldn’t be possible otherwise.
For example, the Fugue cloud deployment system used &lt;a href=&quot;https://www.fugue.co/blog/2016-05-18-cryptographic-hashes-and-dependency-cycles.html&quot;&gt;a generalisation
of this technique&lt;/a&gt; which not only deals with
self-references, but with reference cycles of arbitrary length.&lt;/p&gt;
&lt;p&gt;However, there’s a key thing that’s required for this to work: patching strings in binaries is generally benign, but the final string must have the same length as the original one.
But we can do that: we don’t know what the final &lt;code class=&quot;language-text&quot;&gt;xxx&lt;/code&gt; hash will be, but we know its length (because it’s a fixed-length hash), so we can just choose a temporary directory that has the right length (like a temporary store path with the same name), and we’re all set!&lt;/p&gt;
&lt;p&gt;The annoying thing is that there’s no guarantee that there are no self-references hidden in such a way that a textual replacement won’t catch it (for example inside a compressed zip file).
This is the main reason why content-addressability will not be the default in Nix, at first at least.&lt;/p&gt;
&lt;h1&gt;Non-deterministic builds − the diamond problem strikes back&lt;/h1&gt;
&lt;p&gt;No matter how hard Nix tries to isolate the build environment, some actions will remain inherently non-deterministic − anything that can yield a different output depending on the order in which concurrent tasks will be executed for example.
This is an annoyance as it might prevent &lt;em&gt;early cutoff&lt;/em&gt; (see &lt;a href=&quot;https://www.tweag.io/blog/2020-09-10-nix-cas/&quot;&gt;our previous article on the subject&lt;/a&gt; in case you missed it).&lt;/p&gt;
&lt;p&gt;But more than limiting the efficiency of the cache, this could also
hurt the correctness of Nix if we’re not careful enough.&lt;/p&gt;
&lt;p&gt;For example, consider the following dependency graph:&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;Dependency graph for foo&quot; src=&quot;https://www.tweag.io/ed2e0194aec593229aefb7d515af8dea/foo-dependency-graph.svg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Alice wants to get &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt; installed.
She already built &lt;code class=&quot;language-text&quot;&gt;lib0&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;lib1&lt;/code&gt; locally.
Let’s call them &lt;code class=&quot;language-text&quot;&gt;lib0_a&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;lib1_a&lt;/code&gt;.
The binary cache contains builds of &lt;code class=&quot;language-text&quot;&gt;lib0&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;lib2&lt;/code&gt;.
Let’s call them &lt;code class=&quot;language-text&quot;&gt;lib0_b&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;lib2_b&lt;/code&gt;.
Because the build of &lt;code class=&quot;language-text&quot;&gt;lib0&lt;/code&gt; is not deterministic, &lt;code class=&quot;language-text&quot;&gt;lib0_a&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;lib0_b&lt;/code&gt; are different — and so have a different hash.
In a content-addressed word, that means they will be stored in different paths.&lt;/p&gt;
&lt;p&gt;A simple cache implementation would want to fetch &lt;code class=&quot;language-text&quot;&gt;lib2_b&lt;/code&gt; from the cache and use it to build &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt;.
This would also pull &lt;code class=&quot;language-text&quot;&gt;lib0_b&lt;/code&gt;, because it’s a dependency of &lt;code class=&quot;language-text&quot;&gt;lib2_b&lt;/code&gt;.
But that would mean that &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt; would depend on both &lt;code class=&quot;language-text&quot;&gt;lib0_a&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;lib0_b&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;Buggy runtime dependency graph for foo&quot; src=&quot;https://www.tweag.io/1c4871115391af30e3309771a32df899/foo-runtime-dependency-graph.svg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In the happy case this would just be a waste of space − the dependency is duplicated, so we use twice as much memory to store it.
But in many cases this would simply blow-up at some point — for example if &lt;code class=&quot;language-text&quot;&gt;lib0&lt;/code&gt; is a shared library, the C linker will fail because of the duplicated symbols.
Besides that, this breaks down the purity of the build as we get a different behavior depending on what’s already in the store at the start of the build.&lt;/p&gt;
&lt;h2&gt;Getting out of this&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://edolstra.github.io/pubs/phd-thesis.pdf&quot;&gt;Nix’s foundational paper&lt;/a&gt; shows a way out of this by rewriting hashes in substituted paths.
This is however quite complex to implement for a first version, so the current implementation settles down on a simpler (though not optimal) behavior where we only allow one build for each derivation.
In the example above, &lt;code class=&quot;language-text&quot;&gt;lib0&lt;/code&gt; has already been instantiated (as &lt;code class=&quot;language-text&quot;&gt;lib0_a&lt;/code&gt;), so we don’t allow pulling in &lt;code class=&quot;language-text&quot;&gt;lib0_b&lt;/code&gt; (nor &lt;code class=&quot;language-text&quot;&gt;lib1_b&lt;/code&gt;) and we rebuild both &lt;code class=&quot;language-text&quot;&gt;lib1&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;While not optimal − we’ll end-up rebuilding &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt; even if it’s already in the binary cache − this solution has the advantage of preserving correctness while staying conceptually and technically simple.&lt;/p&gt;
&lt;h1&gt;What now?&lt;/h1&gt;
&lt;p&gt;Part of this &lt;a href=&quot;https://github.com/NixOS/nix/pulls?q=is%3Apr+label%3Aca-derivations+is%3Aclosed&quot;&gt;has already been implemented&lt;/a&gt; but there’s still &lt;a href=&quot;https://github.com/NixOS/nix/issues?q=is%3Aopen+is%3Aissue+label%3Aca-derivations&quot;&gt;quite a long way forward&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I hope for it to be usable (though maybe still experimental) for Nix 3.0.&lt;/p&gt;
&lt;p&gt;And in the meantime stay tuned with &lt;a href=&quot;https://discourse.nixos.org/t/tweag-nix-dev-update-4/9862&quot;&gt;our regular updates on discourse&lt;/a&gt;.
Or wait for the next blog post that will explain another change that will be necessary — one that is less fundamental, but more user-facing.&lt;/p&gt;</description>
	<pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
</item>
<item>
	<title>Cachix: Write access control for binary caches</title>
	<guid isPermaLink="true">https://blog.cachix.org/posts/2020-11-09-write-access-control-for-binary-caches/</guid>
	<link>https://blog.cachix.org/posts/2020-11-09-write-access-control-for-binary-caches/</link>
	<description>As Cachix is growing, I have noticed a few issues along the way: Signing keys are still the best way to upload content and not delegate trust to Cachix, but users have also found that they can be difficult to manage, particularly if the secret key needs to be rotated.
At this point, the best option is to clear out the cache completely, and re-sign everything with a newly generated key.</description>
	<pubDate>Tue, 10 Nov 2020 11:00:00 +0000</pubDate>
	<author>support@cachix.org (Domen Kožar)</author>
</item>
<item>
	<title>Sander van der Burg: Building multi-process Docker images with the Nix process management framework</title>
	<guid isPermaLink="false">tag:blogger.com,1999:blog-1397115249631682228.post-5601957671436536281</guid>
	<link>http://sandervanderburg.blogspot.com/2020/10/building-multi-process-docker-images.html</link>
	<description>Some time ago, I have described &lt;a href=&quot;https://sandervanderburg.blogspot.com/2019/11/a-nix-based-functional-organization-for.html&quot;&gt;my experimental Nix-based process management framework&lt;/a&gt; that makes it possible to automatically &lt;strong&gt;deploy&lt;/strong&gt; running &lt;strong&gt;processes&lt;/strong&gt; (sometimes also ambiguously called services) from declarative specifications written in the &lt;a href=&quot;https://sandervanderburg.blogspot.com/2012/11/an-alternative-explaination-of-nix.html&quot;&gt;Nix expression language&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;The framework is built around two concepts. As its name implies, the &lt;a href=&quot;https://sandervanderburg.blogspot.com/2011/01/nix-package-manager.html&quot;&gt;&lt;strong&gt;Nix package manager&lt;/strong&gt;&lt;/a&gt; is used to deploy all required packages and static artifacts, and a &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/02/a-declarative-process-manager-agnostic.html&quot;&gt;&lt;strong&gt;process manager&lt;/strong&gt; of choice&lt;/a&gt; (e.g. sysvinit, systemd, supervisord and others) is used to manage the life-cycles of the processes.&lt;br /&gt;&lt;br /&gt;Moreover, it is built around &lt;strong&gt;flexible concepts&lt;/strong&gt; allowing integration with solutions that are not qualified as process managers (but can still be used as such), such as &lt;a href=&quot;https://docker.com&quot;&gt;Docker&lt;/a&gt; -- &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/08/experimenting-with-nix-and-service.html&quot;&gt;each process instance can be deployed as a Docker container&lt;/a&gt; with a shared Nix store using the host system's network.&lt;br /&gt;&lt;br /&gt;As explained in &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/07/on-using-nix-and-docker-as-deployment.html&quot;&gt;an earlier blog post&lt;/a&gt;, Docker has become such a popular solution that it has become a standard for deploying (micro)services (often as a utility in the &lt;a href=&quot;https://kubernetes.io&quot;&gt;Kubernetes&lt;/a&gt; solution stack).&lt;br /&gt;&lt;br /&gt;When deploying a system that consists of multiple services with Docker, a typical strategy (and recommended practice) is to use multiple containers that have &lt;a href=&quot;https://runnable.com/docker/rails/run-multiple-processes-in-a-container&quot;&gt;only one root application process&lt;/a&gt;. Advantages of this approach is that Docker can control the life-cycles of the applications, and that each process is (somewhat) isolated/protected from other processes and the host system.&lt;br /&gt;&lt;br /&gt;By default, containers are isolated, but if they need to interact with other processes, then they can use all kinds of &lt;strong&gt;integration&lt;/strong&gt; facilities -- for example, they can share namespaces, or use shared volumes.&lt;br /&gt;&lt;br /&gt;In some situations, it may also be desirable to &lt;strong&gt;deviate&lt;/strong&gt; from the one root process per container practice -- for some systems, processes may need to interact quite intensively (e.g. with IPC mechanisms, shared files or shared memory, or a combination these) in which the container boundaries introduce more inconveniences than benefits.&lt;br /&gt;&lt;br /&gt;Moreover, when running multiple processes in a single container, common dependencies can also typically be more efficiently shared leading to lower disk and RAM consumption.&lt;br /&gt;&lt;br /&gt;As explained in my previous blog post (that explores various Docker concepts), sharing dependencies between containers only works if containers are constructed from images that share the same layers with the same shared libraries. In practice, this form of sharing is not always as efficient as we want it to be.&lt;br /&gt;&lt;br /&gt;Configuring a Docker image to run multiple application processes is somewhat cumbersome -- &lt;a href=&quot;https://docs.docker.com/config/containers/multi-service_container/&quot;&gt;the official Docker documentation&lt;/a&gt; describes two solutions: one that relies on a &lt;strong&gt;wrapper&lt;/strong&gt; script that starts multiple processes in the background and a loop that waits for the &quot;main process&quot; to terminate, and the other is to use a &lt;strong&gt;process manager&lt;/strong&gt;, such as supervisord.&lt;br /&gt;&lt;br /&gt;I realised that I could solve this problem much more conveniently by combining the &lt;i&gt;dockerTools.buildImage {}&lt;/i&gt; function in Nixpkgs (that builds Docker images with the Nix package manager) with the Nix process management abstractions.&lt;br /&gt;&lt;br /&gt;I have created my own abstraction function: &lt;i&gt;createMultiProcessImage&lt;/i&gt; that builds multi-process Docker images, managed by any supported process manager that works in a Docker container.&lt;br /&gt;&lt;br /&gt;In this blog post, I will describe how this function is implemented and how it can be used.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Creating images for single root process containers&lt;/h2&gt;&lt;br /&gt;As shown in earlier blog posts, creating a Docker image with Nix for a single root application process is very straight forward.&lt;br /&gt;&lt;br /&gt;For example, we can build an image that launches a trivial web application service with an embedded HTTP server (as shown in many of my previous blog posts), as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;{dockerTools, webapp}:  &lt;br /&gt;&lt;br /&gt;dockerTools.buildImage {&lt;br /&gt;  name = &quot;webapp&quot;;&lt;br /&gt;  tag = &quot;test&quot;;&lt;br /&gt;&lt;br /&gt;  runAsRoot = ''&lt;br /&gt;    ${dockerTools.shadowSetup}&lt;br /&gt;    groupadd webapp&lt;br /&gt;    useradd webapp -g webapp -d /dev/null&lt;br /&gt;  '';&lt;br /&gt;&lt;br /&gt;  config = {&lt;br /&gt;    Env = [ &quot;PORT=5000&quot; ];&lt;br /&gt;    Cmd = [ &quot;${webapp}/bin/webapp&quot; ];&lt;br /&gt;    Expose = {&lt;br /&gt;      &quot;5000/tcp&quot; = {};&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above Nix expression (&lt;i&gt;default.nix&lt;/i&gt;) invokes the &lt;i&gt;dockerTools.buildImage&lt;/i&gt; function to automatically construct an image with the following properties:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The image has the following name: &lt;i&gt;webapp&lt;/i&gt; and the following version tag: &lt;i&gt;test&lt;/i&gt;.&lt;/li&gt;  &lt;li&gt;The web application service requires some &lt;strong&gt;state&lt;/strong&gt; to be initialized before it can be used. To configure state, we can run instructions in a QEMU virual machine with root privileges (&lt;i&gt;runAsRoot&lt;/i&gt;).&lt;br /&gt;    &lt;br /&gt;    In the above deployment Nix expression, we create an unprivileged user and group named: &lt;i&gt;webapp&lt;/i&gt;. For production deployments, it is typically recommended to drop root privileges, for security reasons.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;Env&lt;/i&gt; directive is used to configure environment variables. The &lt;i&gt;PORT&lt;/i&gt; environment variable is used to configure the TCP port where the service should bind to.&lt;/li&gt;  &lt;li&gt;The &lt;i&gt;Cmd&lt;/i&gt; directive starts the &lt;i&gt;webapp&lt;/i&gt; process in foreground mode. The life-cycle of the container is bound to this application process.&lt;/li&gt;  &lt;li&gt;&lt;i&gt;Expose&lt;/i&gt; exposes TCP port 5000 to the public so that the service can respond to requests made by clients.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;We can build the Docker image as follows:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-build&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;load it into Docker with the following command:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker load -i result&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and launch a container instance using the image as a template:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker run -it -p 5000:5000 webapp:test&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;If the deployment of the container succeeded, we should get a response from the &lt;i&gt;webapp&lt;/i&gt; process, by running:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ curl http://localhost:5000&lt;br /&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;br /&gt;&amp;lt;html&amp;gt;&lt;br /&gt;  &amp;lt;head&amp;gt;&lt;br /&gt;    &amp;lt;title&amp;gt;Simple test webapp&amp;lt;/title&amp;gt;&lt;br /&gt;  &amp;lt;/head&amp;gt;&lt;br /&gt;  &amp;lt;body&amp;gt;&lt;br /&gt;    Simple test webapp listening on port: 5000&lt;br /&gt;  &amp;lt;/body&amp;gt;&lt;br /&gt;&amp;lt;/html&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;Creating multi-process images&lt;/h2&gt;&lt;br /&gt;As shown in previous blog posts, the &lt;i&gt;webapp&lt;/i&gt; process is part of a bigger system, namely: a web application system with an Nginx reverse proxy forwarding requests to multiple &lt;i&gt;webapp&lt;/i&gt; instances:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;{ pkgs ? import &amp;lt;nixpkgs&amp;gt; { inherit system; }&lt;br /&gt;, system ? builtins.currentSystem&lt;br /&gt;, stateDir ? &quot;/var&quot;&lt;br /&gt;, runtimeDir ? &quot;${stateDir}/run&quot;&lt;br /&gt;, logDir ? &quot;${stateDir}/log&quot;&lt;br /&gt;, cacheDir ? &quot;${stateDir}/cache&quot;&lt;br /&gt;, tmpDir ? (if stateDir == &quot;/var&quot; then &quot;/tmp&quot; else &quot;${stateDir}/tmp&quot;)&lt;br /&gt;, forceDisableUserChange ? false&lt;br /&gt;, processManager&lt;br /&gt;}:&lt;br /&gt;&lt;br /&gt;let&lt;br /&gt;  sharedConstructors = import ../services-agnostic/constructors.nix {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir cacheDir tmpDir forceDisableUserChange processManager;&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  constructors = import ./constructors.nix {&lt;br /&gt;    inherit pkgs stateDir runtimeDir logDir tmpDir forceDisableUserChange processManager;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;rec {&lt;br /&gt;  webapp = rec {&lt;br /&gt;    port = 5000;&lt;br /&gt;    dnsName = &quot;webapp.local&quot;;&lt;br /&gt;&lt;br /&gt;    pkg = constructors.webapp {&lt;br /&gt;      inherit port;&lt;br /&gt;    };&lt;br /&gt;  };&lt;br /&gt;&lt;br /&gt;  nginx = rec {&lt;br /&gt;    port = 8080;&lt;br /&gt;&lt;br /&gt;    pkg = sharedConstructors.nginxReverseProxyHostBased {&lt;br /&gt;      webapps = [ webapp ];&lt;br /&gt;      inherit port;&lt;br /&gt;    } {};&lt;br /&gt;  };&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The Nix expression above shows a simple &lt;strong&gt;processes model&lt;/strong&gt; variant of that system, that consists of only two process instances:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;The &lt;i&gt;webapp&lt;/i&gt; process is (as shown earlier) an application that returns a static HTML page.&lt;/li&gt;  &lt;li&gt;&lt;i&gt;nginx&lt;/i&gt; is configured as a reverse proxy to forward incoming connections to multiple &lt;i&gt;webapp&lt;/i&gt; instances using the virtual host header property (&lt;i&gt;dnsName&lt;/i&gt;).&lt;br /&gt;    &lt;br /&gt;    If somebody connects to the &lt;i&gt;nginx&lt;/i&gt; server with the following host name: &lt;i&gt;webapp.local&lt;/i&gt; then the request is forwarded to the &lt;i&gt;webapp&lt;/i&gt; service.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h3&gt;Configuration steps&lt;/h3&gt;&lt;br /&gt;To allow all processes in the process model shown to be deployed to a single container, we need to execute the following steps in the construction of an image:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;Instead of deploying a single package, such as &lt;i&gt;webapp&lt;/i&gt;, we need to refer to a collection of packages and/or configuration files that can be managed with a process manager, such as sysvinit, systemd or supervisord.&lt;br /&gt;    &lt;br /&gt;    The Nix process management framework provides all kinds of Nix function abstractions to accomplish this.&lt;br /&gt;    &lt;br /&gt;    For example, the following function invocation builds a configuration profile for the sysvinit process manager, containing a collection of &lt;i&gt;sysvinit&lt;/i&gt; scripts (also known as &lt;a href=&quot;https://wiki.debian.org/LSBInitScripts&quot;&gt;LSB Init&lt;/a&gt; compliant scripts):&lt;br /&gt;    &lt;br /&gt;    &lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;profile = import ../create-managed-process/sysvinit/build-sysvinit-env.nix {&lt;br /&gt;  exprFile = ./processes.nix;&lt;br /&gt;  stateDir = &quot;/var&quot;;&lt;br /&gt;};&lt;br /&gt;    &lt;/pre&gt;    &lt;br /&gt;  &lt;/li&gt;  &lt;li&gt;Similar to single root process containers, we may also need to initialize state. For example, we need to create common FHS state directories (e.g. &lt;i&gt;/tmp&lt;/i&gt;, &lt;i&gt;/var&lt;/i&gt; etc.) in which services can store their relevant state files (e.g. log files, temp files).&lt;br /&gt;    &lt;br /&gt;    This can be done by running the following command:&lt;br /&gt;    &lt;br /&gt;    &lt;pre&gt;&lt;br /&gt;nixproc-init-state --state-dir /var&lt;br /&gt;    &lt;/pre&gt;  &lt;/li&gt;  &lt;li&gt;Another property that multiple process containers have in common is that they may also require the presence of unprivileged users and groups, for security reasons.&lt;br /&gt;    &lt;br /&gt;    With the following commands, we can automatically generate all required users and groups specified in a deployment profile:&lt;br /&gt;    &lt;br /&gt;    &lt;pre&gt;&lt;br /&gt;${dysnomia}/bin/dysnomia-addgroups ${profile}&lt;br /&gt;${dysnomia}/bin/dysnomia-addusers ${profile}&lt;br /&gt;    &lt;/pre&gt;  &lt;/li&gt;  &lt;li&gt;Instead of starting a (single root) application process, we need to start a process manager that manages the processes that we want to deploy. As already explained, the framework allows you to pick multiple options.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h3&gt;Starting a process manager as a root process&lt;/h3&gt;&lt;br /&gt;From all process managers that the framework currently supports, the most straight forward option to use in a Docker container is: supervisord.&lt;br /&gt;&lt;br /&gt;To use it, we can create a symlink to the supervisord configuration in the deployment profile:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;ln -s ${profile} /etc/supervisor&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;and then start supervisord as a root process with the following command directive:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Cmd = [&lt;br /&gt;  &quot;${pkgs.pythonPackages.supervisor}/bin/supervisord&quot;&lt;br /&gt;  &quot;--nodaemon&quot;&lt;br /&gt;  &quot;--configuration&quot; &quot;/etc/supervisor/supervisord.conf&quot;&lt;br /&gt;  &quot;--logfile&quot; &quot;/var/log/supervisord.log&quot;&lt;br /&gt;  &quot;--pidfile&quot; &quot;/var/run/supervisord.pid&quot;&lt;br /&gt;];&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;(As a sidenote: creating a symlink is not strictly required, but makes it possible to control running services with the &lt;i&gt;supervisorctl&lt;/i&gt; command-line tool).&lt;br /&gt;&lt;br /&gt;Supervisord is not the only option. We can also use sysvinit scripts, but doing so is a bit tricky. As explained earlier, the life-cycle of container is bound to a running root process (in foreground mode).&lt;br /&gt;&lt;br /&gt;sysvinit scripts do not run in the foreground, but start processes that daemonize and terminate immediately, leaving daemon processes behind that remain running in the background.&lt;br /&gt;&lt;br /&gt;As described in an earlier blog post about translating high-level process management concepts, it is also possible to run &quot;daemons in the foreground&quot; by creating a proxy script. We can also make a similar foreground proxy for a collection of daemons:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;#!/bin/bash -e&lt;br /&gt;&lt;br /&gt;_term()&lt;br /&gt;{&lt;br /&gt;    nixproc-sysvinit-runactivity -r stop ${profile}&lt;br /&gt;    kill &quot;$pid&quot;&lt;br /&gt;    exit 0&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;nixproc-sysvinit-runactivity start ${profile}&lt;br /&gt;&lt;br /&gt;# Keep process running, but allow it to respond to the TERM and INT&lt;br /&gt;# signals so that all scripts are stopped properly&lt;br /&gt;&lt;br /&gt;trap _term TERM&lt;br /&gt;trap _term INT&lt;br /&gt;&lt;br /&gt;tail -f /dev/null &amp;amp; pid=$!&lt;br /&gt;wait &quot;$pid&quot;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;The above proxy script does the following:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;It first starts all sysvinit scripts by invoking the &lt;i&gt;nixproc-sysvinit-runactivity start&lt;/i&gt; command.&lt;/li&gt;  &lt;li&gt;Then it registers a signal handler for the &lt;i&gt;TERM&lt;/i&gt; and &lt;i&gt;INT&lt;/i&gt; signals. The corresponding callback triggers a shutdown procedure.&lt;/li&gt;  &lt;li&gt;We invoke a dummy command that keeps running in the foreground without consuming too many system resources (&lt;i&gt;tail -f /dev/null&lt;/i&gt;) and we wait for it to terminate.&lt;/li&gt;  &lt;li&gt;The signal handler properly deactivates all processes in reverse order (with the &lt;i&gt;nixproc-sysvinit-runactivity -r stop&lt;/i&gt; command), and finally terminates the dummy command causing the script (and the container) to stop.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;In addition supervisord and sysvinit, we can also use &lt;a href=&quot;https://sandervanderburg.blogspot.com/2020/06/using-disnix-as-simple-and-minimalistic.html&quot;&gt;Disnix as a process manager&lt;/a&gt; by using a similar strategy with a foreground proxy.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Other configuration properties&lt;/h3&gt;&lt;br /&gt;The above configuration properties suffice to get a multi-process container running. However, to make working with such containers more practical from a user perspective, we may also want to:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;  &lt;li&gt;Add basic shell utilities to the image, so that you can control the processes, investigate log files (in case of errors), and do other maintenance tasks.&lt;/li&gt;  &lt;li&gt;Add a &lt;i&gt;.bashrc&lt;/i&gt; configuration file to make file coloring working for the &lt;i&gt;ls&lt;/i&gt; command, and to provide a decent prompt in a shell session.&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;h2&gt;Usage&lt;/h2&gt;&lt;br /&gt;The configuration steps described in the previous section are wrapped into a function named: &lt;i&gt;createMultiProcessImage&lt;/i&gt;, which itself is a thin wrapper around the &lt;i&gt;dockerTools.buildImage&lt;/i&gt; function in Nixpkgs -- it accepts the same parameters with a number of additional parameters that are specific to multi-process configurations.&lt;br /&gt;&lt;br /&gt;The following function invocation builds a multi-process container deploying our example system, using supervisord as a process manager:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;let&lt;br /&gt;  pkgs = import &amp;lt;nixpkgs&amp;gt; {};&lt;br /&gt;&lt;br /&gt;  createMultiProcessImage = import ../../nixproc/create-multi-process-image/create-multi-process-image.nix {&lt;br /&gt;    inherit pkgs system;&lt;br /&gt;    inherit (pkgs) dockerTools stdenv;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;createMultiProcessImage {&lt;br /&gt;  name = &quot;multiprocess&quot;;&lt;br /&gt;  tag = &quot;test&quot;;&lt;br /&gt;  exprFile = ./processes.nix;&lt;br /&gt;  stateDir = &quot;/var&quot;;&lt;br /&gt;  processManager = &quot;supervisord&quot;;&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;After building the image, and deploying a container, with the following commands:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ nix-build&lt;br /&gt;$ docker load -i result&lt;br /&gt;$ docker run -it --network host multiprocessimage:test&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;we should be able to connect to the &lt;i&gt;webapp&lt;/i&gt; instance via the &lt;i&gt;nginx&lt;/i&gt; reverse proxy:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ curl -H 'Host: webapp.local' http://localhost:8080&lt;br /&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;br /&gt;&amp;lt;html&amp;gt;&lt;br /&gt;  &amp;lt;head&amp;gt;&lt;br /&gt;    &amp;lt;title&amp;gt;Simple test webapp&amp;lt;/title&amp;gt;&lt;br /&gt;  &amp;lt;/head&amp;gt;&lt;br /&gt;  &amp;lt;body&amp;gt;&lt;br /&gt;    Simple test webapp listening on port: 5000&lt;br /&gt;  &amp;lt;/body&amp;gt;&lt;br /&gt;&amp;lt;/html&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;As explained earlier, the constructed image also provides extra command-line utilities to do maintenance tasks, and control the life-cycle of the individual processes.&lt;br /&gt;&lt;br /&gt;For example, we can &quot;connect&quot; to the running container, and check which processes are running:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker exec -it mycontainer /bin/bash&lt;br /&gt;# supervisorctl&lt;br /&gt;nginx                            RUNNING   pid 11, uptime 0:00:38&lt;br /&gt;webapp                           RUNNING   pid 10, uptime 0:00:38&lt;br /&gt;supervisor&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;If we change the &lt;i&gt;processManager&lt;/i&gt; parameter to &lt;i&gt;sysvinit&lt;/i&gt;, we can deploy a multi-process image in which the foreground proxy script is used as a root process (that starts and stops sysvinit scripts).&lt;br /&gt;&lt;br /&gt;We can control the life-cycle of each individual process by directly invoking the sysvinit scripts in the container:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;$ docker exec -it mycontainer /bin/bash&lt;br /&gt;$ /etc/rc.d/init.d/webapp status&lt;br /&gt;webapp is running with Process ID(s) 33.&lt;br /&gt;&lt;br /&gt;$ /etc/rc.d/init.d/nginx status&lt;br /&gt;nginx is running with Process ID(s) 51.&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;Although having extra command-line utilities to do administration tasks is useful, a disadvantage is that they considerably increase the size of the image.&lt;br /&gt;&lt;br /&gt;To save storage costs, it is also possible to disable &lt;i&gt;interactive&lt;/i&gt; mode to exclude these packages:&lt;br /&gt;&lt;br /&gt;&lt;pre style=&quot;overflow: auto;&quot;&gt;&lt;br /&gt;let&lt;br /&gt;  pkgs = import &amp;lt;nixpkgs&amp;gt; {};&lt;br /&gt;&lt;br /&gt;  createMultiProcessImage = import ../../nixproc/create-multi-process-image/create-multi-process-image.nix {&lt;br /&gt;    inherit pkgs system;&lt;br /&gt;    inherit (pkgs) dockerTools stdenv;&lt;br /&gt;  };&lt;br /&gt;in&lt;br /&gt;createMultiProcessImage {&lt;br /&gt;  name = &quot;multiprocess&quot;;&lt;br /&gt;  tag = &quot;test&quot;;&lt;br /&gt;  exprFile = ./processes.nix;&lt;br /&gt;  stateDir = &quot;/var&quot;;&lt;br /&gt;  processManager = &quot;supervisord&quot;;&lt;br /&gt;  interactive = false; # Do not install any additional shell utilities&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h2&gt;Discussion&lt;/h2&gt;&lt;br /&gt;In this blog post, I have described a new utility function in the Nix process management framework: &lt;i&gt;createMultiProcessImage&lt;/i&gt; -- a thin wrapper around the &lt;i&gt;dockerTools.buildImage&lt;/i&gt; function that can be used to convienently build multi-process Docker images, using any Docker-capable process manager that the Nix process management framework supports.&lt;br /&gt;&lt;br /&gt;Besides the fact that we can convienently construct multi-process images, this function also has the advantage (similar to the &lt;i&gt;dockerTools.buildImage&lt;/i&gt; function) that Nix is only required for the construction of the image. To deploy containers from a multi-process image, Nix is not a requirement.&lt;br /&gt;&lt;br /&gt;There is also a drawback: similar to &quot;ordinary&quot; multi-process container deployments, when it is desired to upgrade a process, the entire container needs to be redeployed, also requiring a user to terminate all other running processes.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;Availability&lt;/h2&gt;&lt;br /&gt;The &lt;i&gt;createMultiProcessImage&lt;/i&gt; function is part of the current development version of the &lt;a href=&quot;https://github.com/svanderburg/nix-processmgmt&quot;&gt;Nix process management framework&lt;/a&gt; that can be obtained from my GitHub page.&lt;br /&gt;&lt;br /&gt;</description>
	<pubDate>Sat, 31 Oct 2020 15:05:00 +0000</pubDate>
	<author>noreply@blogger.com (Sander van der Burg)</author>
</item>
<item>
	<title>Tweag I/O: Nickel: better configuration for less</title>
	<guid isPermaLink="true">https://tweag.io/blog/2020-10-22-nickel-open-sourcing/</guid>
	<link>https://tweag.io/blog/2020-10-22-nickel-open-sourcing/</link>
	<description>&lt;p&gt;We are making the &lt;a href=&quot;https://www.github.com/tweag/nickel&quot;&gt;Nickel&lt;/a&gt; repository public. Nickel is an experimental configuration
language developed at Tweag. While this is not the time for the first
release yet, it is an occasion to talk about this project. The goal of this
post is to give a high-level overview of the project. If your curiosity is tickled
but you are left wanting to learn more, fear not, as we will publish
more blog posts on specific aspects of the language in the future. But for
now, let’s have a tour!&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;Disclaimer&lt;/strong&gt;: the actual syntax of Nickel being still worked on, I’m freely
using as-of-yet non-existing syntax for illustrative purposes. The underlying
features are however already supported.]&lt;/p&gt;
&lt;h2&gt;The inception&lt;/h2&gt;
&lt;p&gt;We, at Tweag, are avid users of the &lt;a href=&quot;https://nixos.org/&quot;&gt;Nix&lt;/a&gt; package manager. As it
happens, the configuration language for Nix (also called Nix) is
a pretty good configuration language, and would be applicable to many
more things than just package management.&lt;/p&gt;
&lt;p&gt;All in all, the Nix language is a lazy JSON with functions. It is
simple yet powerful. It is used to generate Nix’s package descriptions
but would be well
suited to write any kind of configuration (&lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt;,
&lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;, etc…).&lt;/p&gt;
&lt;p&gt;The rub is that the interpreter for Nix-the-language is tightly
coupled with Nix-the-package manager. So, as it stands, using the
Nix language for anything else than package management is a rather
painful exercise.&lt;/p&gt;
&lt;p&gt;Nickel is our attempt at answering the question: what would
Nix-the-language look like if it was split from the package manager?
While taking the opportunity to improve the language a little,
building on the experience of the Nix community over the years.&lt;/p&gt;
&lt;h2&gt;What’s Nickel, exactly ?&lt;/h2&gt;
&lt;p&gt;Nickel is a lightweight generic configuration language. In that it can
replace YAML as your application’s configuration language. Unlike
YAML, though, it anticipates large configurations by being
programmable. Another way to use Nickel is to generate static
configuration files — &lt;em&gt;e.g.&lt;/em&gt; in JSON, YAML — that are then fed to another system. Like
Nix, it is designed to have a simple, well-understood core: at its
heart, it is JSON with functions.&lt;/p&gt;
&lt;p&gt;But past experience with Nix also brings some insights on which aspects of the
language could be improved. Whatever the initial scope of a language is, it will
almost surely be used in a way that deviates from the original plan: you create
a configuration language to describe software packages, and next thing you know,
somebody needs to implement a &lt;a href=&quot;https://github.com/NixOS/nixpkgs/pull/11484&quot;&gt;topological sort&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Nickel strives to retain the simplicity of Nix, while extending it
according to this feedback.
Though, you can do perfectly fine without the new features and just write Nix-like code.&lt;/p&gt;
&lt;h2&gt;Yet another configuration language&lt;/h2&gt;
&lt;p&gt;At this point you’re probably wondering if this hasn’t already been done elsewhere.
It seems that more and more languages are born every day, and surely there
already exist configuration languages with a similar purpose to Nickel:
&lt;a href=&quot;https://github.com/bazelbuild/starlark&quot;&gt;Starlark&lt;/a&gt;, &lt;a href=&quot;https://jsonnet.org/&quot;&gt;Jsonnet&lt;/a&gt;, &lt;a href=&quot;https://dhall-lang.org/&quot;&gt;Dhall&lt;/a&gt; or &lt;a href=&quot;https://cuelang.org/&quot;&gt;CUE&lt;/a&gt;, to name
a few. So why Nickel?&lt;/p&gt;
&lt;h2&gt;Typing&lt;/h2&gt;
&lt;p&gt;Perhaps the most important difference with other configuration languages is
Nickel’s approach to typing.&lt;/p&gt;
&lt;p&gt;Some languages, such as &lt;a href=&quot;https://jsonnet.org/&quot;&gt;Jsonnet&lt;/a&gt; or &lt;a href=&quot;https://github.com/bazelbuild/starlark&quot;&gt;Starlark&lt;/a&gt;, are not
statically typed. Indeed, static types can be seen as superflous in a configuration
language: if your program is only run once on fixed inputs, any type error will
be reported at run-time anyway. Why bother with a static type system?&lt;/p&gt;
&lt;p&gt;On the other hand, more and more systems rely on complex configurations, such as
cloud infrastructure (&lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt;, &lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; or
&lt;a href=&quot;https://github.com/NixOS/nixops&quot;&gt;NixOps&lt;/a&gt;), leading the corresponding programs to become increasingly
complex, to the point where static types are beneficial. For reusable code —
that is, library functions — static types add structure, serve as
documentation, and eliminate bugs early.&lt;/p&gt;
&lt;p&gt;Although less common, some configuration languages are statically typed,
including &lt;a href=&quot;https://dhall-lang.org/&quot;&gt;Dhall&lt;/a&gt; and &lt;a href=&quot;https://cuelang.org/&quot;&gt;CUE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Dhall features a powerful type system that is able to type a wide range of
idioms. But it is complex, requiring some experience to become fluent in.&lt;/p&gt;
&lt;p&gt;CUE is closer to what we are striving for. It has an optional and well-behaved
type system with strong guarantees. In exchange for which, one can’t write nor
type higher-order functions in general, even if some simple functions are
possible to encode.&lt;/p&gt;
&lt;h3&gt;Gradual typing&lt;/h3&gt;
&lt;p&gt;Nickel, features a &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradual_typing&quot;&gt;&lt;em&gt;gradual type system&lt;/em&gt;&lt;/a&gt;.
Gradual types are unobtrusive: they make it possible to statically
type reusable parts of your programs, but you are still free to write
configurations without any types. The
interpreter safely handles the interaction between the typed and untyped worlds.&lt;/p&gt;
&lt;p&gt;Concretely, typed library code like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;// file: mylib.ncl
{
  numToStr : Num -&amp;gt; Str = fun n =&amp;gt; ...;
  makeURL : Str -&amp;gt; Str -&amp;gt; Num -&amp;gt; Str = fun proto host port =&amp;gt;
    &quot;${proto}://${host}:${numToStr port}/&quot;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;can coexist with untyped configuration code like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;// file: server.ncl
let mylib = import &quot;mylib.ncl&quot; in
let host = &quot;myproject.com&quot; in
{
  host = host;
  port = 1;
  urls = [
    mylib.makeURL &quot;myproto&quot; host port,
    {protocol = &quot;proto2&quot;; server = &quot;sndserver.net&quot;; port = 4242}
  ];
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the first snippet, the body of &lt;code class=&quot;language-text&quot;&gt;numToStr&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;makeURL&lt;/code&gt; are statically
checked: wrongfully calling &lt;code class=&quot;language-text&quot;&gt;numToStr proto&lt;/code&gt; inside &lt;code class=&quot;language-text&quot;&gt;makeURL&lt;/code&gt; would raise an
error even if &lt;code class=&quot;language-text&quot;&gt;makeURL&lt;/code&gt; is never used. On the other hand, the second snippet is
not annotated, and thus not statically checked. In particular, we mix an URL
represented as a string together with one represented as a record in the same
list. The interpreter rather inserts run-time checks, or &lt;em&gt;contracts&lt;/em&gt;, such
that if &lt;code class=&quot;language-text&quot;&gt;makeURL&lt;/code&gt; is misused then the program fails with an
appropriate error.&lt;/p&gt;
&lt;p&gt;Gradual types also lets us keep the type system simple: even in
statically typed code if you want to write a component that the type
checker doesn’t know how to verify, you don’t have to type-check that
part.&lt;/p&gt;
&lt;h3&gt;Contracts&lt;/h3&gt;
&lt;p&gt;Complementary to the static type system, Nickel offers &lt;em&gt;contracts&lt;/em&gt;. Contracts
offer precise and accurate dynamic type error reporting, even in the
presence of function types. Contracts are used internally by
Nickel’s interpreter to insert guards at the boundary between typed and untyped
chunks. Contracts are available to the programmer as well, to give them the
ability to enforce type assertions at run-time in a simple way.&lt;/p&gt;
&lt;p&gt;One pleasant consequence of this design is that the exposure of the user to the
type system can be progressive:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users writing configurations can just write Nix-like code while ignoring
(almost) everything about typing, since you can seamlessly call a typed
function from untyped code.&lt;/li&gt;
&lt;li&gt;Users writing consumers or verifiers of these configurations would use
contracts to model data schemas.&lt;/li&gt;
&lt;li&gt;Users writing libraries would instead use the static type
system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of contract is given in the next section.&lt;/p&gt;
&lt;h2&gt;Schemas&lt;/h2&gt;
&lt;p&gt;While the basic computational blocks are functions, the basic data blocks in
Nickel are records (or objects in JSON). Nickel supports writing self-documenting
record schemas, such as:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;{
  host | type: Str
       | description: &quot;The host name of the server.&quot;
       | default: &quot;fallback.myserver.net&quot;
  ;

  port | type: Num
       | description: &quot;The port of the connection.&quot;
       | default: 4242
  ;

  url | type: Url
      | description: &quot;The host name of the server.&quot;
  ;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each field can contain metadata, such as a description or default
value. These aim at being displayed in documentation, or queried by
tools.&lt;/p&gt;
&lt;p&gt;The schema can then be used as a contract. Imagine that a function has
swapped two values in its output and returns:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;{
  host = &quot;myproject.com&quot;,
  port = &quot;myproto://myproject.com:1/&quot;,
  url = 1
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Without types, this is hard to catch. Surely, an error will eventually pop up
downstream in the pipeline, but how and when? Using the schema above
will make sure that, whenever the fields are actually evaluated, the
function will be blamed in the type error.&lt;/p&gt;
&lt;p&gt;Schemas are actually part of a bigger story involving merging records
together, which, in particular, lets the schema instantiate missing
fields with their default values. It is very much inspired by the
&lt;a href=&quot;https://nixos.org/manual/nixos/stable/index.html#sec-configuration-syntax&quot;&gt;NixOs module system&lt;/a&gt; and the &lt;a href=&quot;https://cuelang.org/&quot;&gt;CUE&lt;/a&gt; language, but
it is a story for another time.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope that I gave you a sense of what Nickel is trying to achieve. I
only presented its most salient aspects: its gradual type system with
contracts, and built-in record schemas. But there is more to explore!
The language is not ready to be used in real world applications yet, but a good
share of the design presented here is implemented. If you are curious about it,
&lt;a href=&quot;https://www.github.com/tweag/nickel&quot;&gt;check it out&lt;/a&gt;!&lt;/p&gt;</description>
	<pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
</item>

</channel>
</rss>
